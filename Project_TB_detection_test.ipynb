{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff1ede8c",
   "metadata": {},
   "source": [
    "# ECE 228 Project\n",
    "## Tuberculosis Detection | Team 26\n",
    "### Jianyu Tao\n",
    "### Shreyas Borse\n",
    "### Harshit Bhadani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89309d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version 1.11.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "## Importing modules for necessary operations\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pdb\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import argparse\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print('Using PyTorch version', torch.__version__)\n",
    "\n",
    "\n",
    "from os.path import isfile\n",
    "from os import rename\n",
    "SMOOTH=1\n",
    "import pdb\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from PIL.ImageFilter import GaussianBlur\n",
    "\n",
    "# import pdb\n",
    "from numpy import pi as PI\n",
    "from numpy import sqrt\n",
    "from scipy.special import comb\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0be2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscellaneous initialization\n",
    "torch.manual_seed(1)\n",
    "start_time = time.time()\n",
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0d5de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"\"\n",
    "test_dataset_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fc58232",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/Users/harshitb/Desktop/Studies/ECE 228/TB_dataset/TB_Chest_Radiography_Database\"\n",
    "class_names = ['Normal', 'Tuberculosis']\n",
    "source_dirs = ['Normal', 'Tuberculosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "930810b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.add_argument('--num_epochs', type=int, default=5, help='Number of training epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='Batch size')\n",
    "parser.add_argument('--lr', type=float, default=5e-4, help='Learning rate')\n",
    "parser.add_argument('--l2', type=float, default=0, help='L2 regularisation')\n",
    "parser.add_argument('--aug', action='store_true', default=False, help='Use data augmentation')\n",
    "parser.add_argument('--data_path', type=str, default=root_dir,help='Path to data.')\n",
    "parser.add_argument('--bond_dim', type=int, default=5, help='MPS Bond dimension')\n",
    "parser.add_argument('--nChannel', type=int, default=1, help='Number of input channels')\n",
    "parser.add_argument('--dense_net', action='store_true', default=False, help='Using Dense Net model')\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "684a5c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = args.batch_size\n",
    "\n",
    "# LoTeNet parameters\n",
    "adaptive_mode = False \n",
    "periodic_bc   = False\n",
    "\n",
    "kernel = 2 # Stride along spatial dimensions\n",
    "output_dim = 1 # output dimension\n",
    " \n",
    "feature_dim = 2\n",
    "\n",
    "normTensor = 0.5*torch.ones(args.nChannel)\n",
    "### Data processing and loading....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a61e98b",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc2837a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data processing and loading....\n",
    "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.Resize(size=(256,256)),\n",
    "                                      transforms.RandomVerticalFlip(),\n",
    "                                      transforms.RandomRotation(20),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=normTensor,std=normTensor)])\n",
    "\n",
    "valid_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size=(256,256)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(20),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=normTensor,std=normTensor)\n",
    "    #torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1abf12",
   "metadata": {},
   "source": [
    "### Creating Datasets classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a87dbe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXRayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_dirs,transform):\n",
    "        def get_images(class_name):\n",
    "            images = [x for x in os.listdir(image_dirs[class_name]) if x.lower().endswith('png')]\n",
    "            print(f'Found {len(images)}{class_name}')\n",
    "            return images\n",
    "        self.images={}\n",
    "        self.class_names=['Normal', 'Tuberculosis']\n",
    "        for c in self.class_names:\n",
    "            self.images[c]=get_images(c)\n",
    "        self.image_dirs=image_dirs\n",
    "        self.transform=transform\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return sum([len(self.images[c]) for c in self.class_names])\n",
    "    def __getitem__(self, index):\n",
    "        class_name=random.choice(self.class_names)\n",
    "        index=index%len(self.images[class_name])\n",
    "        image_name=self.images[class_name][index]\n",
    "        image_path =os.path.join(self.image_dirs[class_name], image_name)\n",
    "        image=Image.open(image_path).convert('L')\n",
    "        return self.transform(image), self.class_names.index(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56fa2063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3500Normal\n",
      "Found 700Tuberculosis\n"
     ]
    }
   ],
   "source": [
    "train_dirs = {\n",
    "    'Normal': root_dir + '/Normal',\n",
    "    'Tuberculosis': root_dir + '/Tuberculosis'\n",
    "}\n",
    "dataset = ChestXRayDataset(train_dirs, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbe34a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset, valset = random_split(dataset, [3300, 600, 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1288b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader =  torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader =  torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8fa93a",
   "metadata": {},
   "source": [
    "# Creating various architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "966057cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        #         xl = 1\n",
    "        #         for i in x.shape[1:]: xl *= i\n",
    "        #         self.fc1 = nn.Linear(13456, 120)\n",
    "        self.fc1 = nn.Linear(984064, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        #         x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
    "        #         x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv1(x))  # -> n, 6, 14, 14\n",
    "        x = F.relu(self.conv2(x))\n",
    "        xl = 1\n",
    "        for i in x.shape[1:]: xl *= i\n",
    "        x = x.view(-1, xl)            # \n",
    "        x = F.relu(self.fc1(x))               # -> n, 120\n",
    "        x = F.relu(self.fc2(x))               # -> n, 84\n",
    "        x = self.fc3(x)                       # -> n, 2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a40b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the convolutional neural network\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Linear(59536, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddf655a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.conv1_1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv4_1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv5_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(32768, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv5_1(x))\n",
    "        x = F.relu(self.conv5_2(x))\n",
    "        x = F.relu(self.conv5_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "#         print(\"HERE ... \", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, 0.5) #dropout was included to combat overfitting\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, 0.5)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88249028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising variable that will be used in the experiments in the project\n",
    "\n",
    "loss_data_of_model_epoch = {}\n",
    "acc_of_model_epoch = {}\n",
    "acc_of_model_batch = {}\n",
    "\n",
    "all_models = {}\n",
    "all_models['ConvNet'] = ConvNet()\n",
    "all_models['LeNet5']  = LeNet5()\n",
    "all_models['VGG16']   = VGG16()\n",
    "\n",
    "for model_name in all_models.keys():\n",
    "    loss_data_of_model_epoch[model_name] = {}\n",
    "    acc_of_model_epoch[model_name] = {}\n",
    "    acc_of_model_batch[model_name] = {}\n",
    "\n",
    "LeNet5_model_with_epoch = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab437e84",
   "metadata": {},
   "source": [
    "# Defining various functions to make the code modular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bd40115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_from_data(d_loader):\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        n_class_correct = [0 for i in range(2)]\n",
    "        n_class_samples = [0 for i in range(2)]\n",
    "        for images, labels in d_loader:\n",
    "            #         print(len(labels))\n",
    "            outputs = model(images)\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                pred = predicted[i]\n",
    "                if (label == pred):\n",
    "                    n_class_correct[label] += 1\n",
    "                n_class_samples[label] += 1\n",
    "\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network: {acc} %')\n",
    "        \n",
    "        all_acc = []\n",
    "        overall_accuracy = acc\n",
    "        all_acc.append(overall_accuracy)\n",
    "\n",
    "        for i in range(2):\n",
    "            acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "            print(f'Accuracy of {class_names[i]}: {acc} %')\n",
    "            all_acc.append(acc)\n",
    "                \n",
    "    #return all_acc\n",
    "    return overall_accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b1e415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_by_model(model, model_name, epo = 3, verbose = True):\n",
    "    args.num_epochs = epo\n",
    "    learning_rate = 0.001\n",
    "    all_loss = []\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    n_total_steps = len(train_loader)\n",
    "    for epoch in range(args.num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            all_loss.append(loss.item())\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if ((i+1) % 10 == 0) and verbose:\n",
    "                print (f'Epoch [{epoch+1}/{args.num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "        LeNet5_model_with_epoch[epoch+1] = copy.deepcopy(model)\n",
    "        \n",
    "    return all_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb0a14",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f57aec",
   "metadata": {},
   "source": [
    "### Experiment: Deciding Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5446561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [10/104], Loss: 0.6480\n",
      "Epoch [1/3], Step [20/104], Loss: 0.6886\n",
      "Epoch [1/3], Step [30/104], Loss: 0.6137\n",
      "Epoch [1/3], Step [40/104], Loss: 0.5863\n",
      "Epoch [1/3], Step [50/104], Loss: 0.5662\n",
      "Epoch [1/3], Step [60/104], Loss: 0.5802\n",
      "Epoch [1/3], Step [70/104], Loss: 0.5153\n",
      "Epoch [1/3], Step [80/104], Loss: 0.5824\n",
      "Epoch [1/3], Step [90/104], Loss: 0.4819\n",
      "Epoch [1/3], Step [100/104], Loss: 0.5105\n",
      "Epoch [2/3], Step [10/104], Loss: 0.4502\n",
      "Epoch [2/3], Step [20/104], Loss: 0.3972\n",
      "Epoch [2/3], Step [30/104], Loss: 0.4069\n",
      "Epoch [2/3], Step [40/104], Loss: 0.4233\n",
      "Epoch [2/3], Step [50/104], Loss: 0.4262\n",
      "Epoch [2/3], Step [60/104], Loss: 0.3951\n",
      "Epoch [2/3], Step [70/104], Loss: 0.5174\n",
      "Epoch [2/3], Step [80/104], Loss: 0.4019\n",
      "Epoch [2/3], Step [90/104], Loss: 0.3183\n",
      "Epoch [2/3], Step [100/104], Loss: 0.3372\n",
      "Epoch [3/3], Step [10/104], Loss: 0.5151\n",
      "Epoch [3/3], Step [20/104], Loss: 0.2521\n",
      "Epoch [3/3], Step [30/104], Loss: 0.3850\n",
      "Epoch [3/3], Step [40/104], Loss: 0.3334\n",
      "Epoch [3/3], Step [50/104], Loss: 0.3540\n",
      "Epoch [3/3], Step [60/104], Loss: 0.3461\n",
      "Epoch [3/3], Step [70/104], Loss: 0.3029\n",
      "Epoch [3/3], Step [80/104], Loss: 0.3445\n",
      "Epoch [3/3], Step [90/104], Loss: 0.3292\n",
      "Epoch [3/3], Step [100/104], Loss: 0.2746\n",
      "Accuracy of the network: 87.16666666666667 %\n",
      "Accuracy of Normal: 80.65573770491804 %\n",
      "Accuracy of Tuberculosis: 93.89830508474576 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87.16666666666667"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking various architectures above one by one with epoch = 3\n",
    "\n",
    "model_name = \"LeNet5\"\n",
    "model = all_models[model_name]\n",
    "\n",
    "train_by_model(model, model_name)\n",
    "get_acc_from_data(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e87e940",
   "metadata": {},
   "source": [
    "### Experiment: Deciding epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75599bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating accuracy of model with epoch:  1\n",
      "Accuracy of the network: 82.66666666666667 %\n",
      "Accuracy of Normal: 69.01408450704226 %\n",
      "Accuracy of Tuberculosis: 94.9367088607595 %\n",
      "Calculating accuracy of model with epoch:  2\n",
      "Accuracy of the network: 85.16666666666667 %\n",
      "Accuracy of Normal: 92.98245614035088 %\n",
      "Accuracy of Tuberculosis: 78.0952380952381 %\n",
      "Calculating accuracy of model with epoch:  3\n",
      "Accuracy of the network: 88.0 %\n",
      "Accuracy of Normal: 83.7748344370861 %\n",
      "Accuracy of Tuberculosis: 92.28187919463087 %\n",
      "Calculating accuracy of model with epoch:  4\n",
      "Accuracy of the network: 87.16666666666667 %\n",
      "Accuracy of Normal: 81.92771084337349 %\n",
      "Accuracy of Tuberculosis: 93.65671641791045 %\n",
      "Calculating accuracy of model with epoch:  5\n",
      "Accuracy of the network: 91.33333333333333 %\n",
      "Accuracy of Normal: 90.64516129032258 %\n",
      "Accuracy of Tuberculosis: 92.06896551724138 %\n",
      "Calculating accuracy of model with epoch:  6\n",
      "Accuracy of the network: 88.66666666666667 %\n",
      "Accuracy of Normal: 95.66666666666667 %\n",
      "Accuracy of Tuberculosis: 81.66666666666667 %\n",
      "Calculating accuracy of model with epoch:  7\n",
      "Accuracy of the network: 91.16666666666667 %\n",
      "Accuracy of Normal: 87.8594249201278 %\n",
      "Accuracy of Tuberculosis: 94.77351916376307 %\n",
      "Calculating accuracy of model with epoch:  8\n",
      "Accuracy of the network: 90.5 %\n",
      "Accuracy of Normal: 88.99371069182389 %\n",
      "Accuracy of Tuberculosis: 92.19858156028369 %\n",
      "Calculating accuracy of model with epoch:  9\n",
      "Accuracy of the network: 90.16666666666667 %\n",
      "Accuracy of Normal: 96.75324675324676 %\n",
      "Accuracy of Tuberculosis: 83.21917808219177 %\n",
      "Calculating accuracy of model with epoch:  10\n",
      "Accuracy of the network: 92.16666666666667 %\n",
      "Accuracy of Normal: 87.88927335640139 %\n",
      "Accuracy of Tuberculosis: 96.14147909967846 %\n",
      "Calculating accuracy of model with epoch:  11\n",
      "Accuracy of the network: 94.5 %\n",
      "Accuracy of Normal: 93.91891891891892 %\n",
      "Accuracy of Tuberculosis: 95.0657894736842 %\n",
      "Calculating accuracy of model with epoch:  12\n",
      "Accuracy of the network: 93.0 %\n",
      "Accuracy of Normal: 90.36544850498339 %\n",
      "Accuracy of Tuberculosis: 95.65217391304348 %\n",
      "Calculating accuracy of model with epoch:  13\n",
      "Accuracy of the network: 93.33333333333333 %\n",
      "Accuracy of Normal: 94.58483754512635 %\n",
      "Accuracy of Tuberculosis: 92.26006191950465 %\n",
      "Calculating accuracy of model with epoch:  14\n",
      "Accuracy of the network: 93.66666666666667 %\n",
      "Accuracy of Normal: 91.2751677852349 %\n",
      "Accuracy of Tuberculosis: 96.02649006622516 %\n",
      "Calculating accuracy of model with epoch:  15\n",
      "Accuracy of the network: 94.66666666666667 %\n",
      "Accuracy of Normal: 95.48387096774194 %\n",
      "Accuracy of Tuberculosis: 93.79310344827586 %\n",
      "Maximum accuracy is  94.66666666666667  with epoch as  15\n",
      "CPU times: user 27min 35s, sys: 16.7 s, total: 27min 51s\n",
      "Wall time: 22min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f97100826a0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "# Accuracy for LeNet5 with various epoch\n",
    "\n",
    "model = LeNet5()\n",
    "model_name = \"LeNet5\"\n",
    "\n",
    "losses = train_by_model(model, model_name, 15, verbose = False)\n",
    "\n",
    "accs = {}\n",
    "for epo in LeNet5_model_with_epoch:\n",
    "    print(\"Calculating accuracy of model with epoch: \", epo)\n",
    "    model = LeNet5_model_with_epoch[epo]\n",
    "    acc = get_acc_from_data(test_loader)\n",
    "    accs[epo] = acc\n",
    "\n",
    "acc_of_model_epoch[model_name] = accs\n",
    "\n",
    "# -----------------------------------------------------\n",
    "import json\n",
    "with open('loss_data_of_model_epoch.json', 'w') as fp:\n",
    "    json.dump(loss_data_of_model_epoch, fp)\n",
    "    \n",
    "with open('acc_of_model_epoch.json', 'w') as fp:\n",
    "    json.dump(acc_of_model_epoch, fp)\n",
    "# -----------------------------------------------------\n",
    "\n",
    "model_name = \"LeNet5\"\n",
    "max_acc_epo = 1\n",
    "max_acc = acc_of_model_epoch[model_name][max_acc_epo]\n",
    "for epo in acc_of_model_epoch[model_name]:\n",
    "    if max_acc < acc_of_model_epoch[model_name][epo]:\n",
    "        max_acc = acc_of_model_epoch[model_name][epo]\n",
    "        max_acc_epo = epo\n",
    "\n",
    "print(\"Maximum accuracy is \", max_acc, \" with epoch as \", max_acc_epo)\n",
    "\n",
    "plt.plot(list(accs.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5690e0e5",
   "metadata": {},
   "source": [
    "### Experiment: Deciding batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eadf4150",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size:  16\n",
      "Accuracy of the network: 92.33333333333333 %\n",
      "Accuracy of Normal: 87.27915194346289 %\n",
      "Accuracy of Tuberculosis: 96.84542586750788 %\n",
      "Batch Size:  32\n",
      "Accuracy of the network: 91.16666666666667 %\n",
      "Accuracy of Normal: 94.49838187702265 %\n",
      "Accuracy of Tuberculosis: 87.62886597938144 %\n",
      "Batch Size:  64\n",
      "Accuracy of the network: 85.5 %\n",
      "Accuracy of Normal: 80.85106382978724 %\n",
      "Accuracy of Tuberculosis: 89.62264150943396 %\n",
      "CPU times: user 25min 39s, sys: 23 s, total: 26min 2s\n",
      "Wall time: 21min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Experiment with various batch sizes for LeNet5 with epoch = 5\n",
    "\n",
    "\n",
    "for bs in [16, 32, 64]:\n",
    "    print(\"Batch Size: \", bs)\n",
    "    train_loader =  torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True)\n",
    "    test_loader =  torch.utils.data.DataLoader(testset, batch_size=bs, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(valset, batch_size=bs, shuffle=True)\n",
    "    model = LeNet5()\n",
    "    train_by_model(model, model_name, 5, verbose = False)\n",
    "    acc_of_model_batch[model_name][bs] = get_acc_from_data(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5503525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy is  92.33333333333333  with batch size as  16\n",
      "Upon analyzing the runtime and accuracy of data we took the following parameters forward\n",
      "Batch Size: 32\n",
      "32 was taken as it had lesser runtime\n"
     ]
    }
   ],
   "source": [
    "# Getting Batch Size that gives highest accuracy\n",
    "\n",
    "model_name = \"LeNet5\"\n",
    "max_acc_bat = 16\n",
    "max_acc = acc_of_model_batch[model_name][max_acc_bat]\n",
    "for bat in acc_of_model_batch[model_name]:\n",
    "    if max_acc < acc_of_model_batch[model_name][bat]:\n",
    "        max_acc = acc_of_model_batch[model_name][bat]\n",
    "        max_acc_bat = bat \n",
    "\n",
    "print(\"Maximum accuracy is \", max_acc, \" with batch size as \", max_acc_bat)\n",
    "\n",
    "print(\"Upon analyzing the runtime and accuracy of data we took the following parameters forward\")\n",
    "print(\"Batch Size: 32\")\n",
    "print(\"32 was taken as it had lesser runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77161340",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "454e917b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/12], Step [10/104], Loss: 0.6950\n",
      "Epoch [1/12], Step [20/104], Loss: 0.6530\n",
      "Epoch [1/12], Step [30/104], Loss: 0.6434\n",
      "Epoch [1/12], Step [40/104], Loss: 0.6155\n",
      "Epoch [1/12], Step [50/104], Loss: 0.6079\n",
      "Epoch [1/12], Step [60/104], Loss: 0.6001\n",
      "Epoch [1/12], Step [70/104], Loss: 0.5416\n",
      "Epoch [1/12], Step [80/104], Loss: 0.5198\n",
      "Epoch [1/12], Step [90/104], Loss: 0.5263\n",
      "Epoch [1/12], Step [100/104], Loss: 0.5246\n",
      "Epoch [2/12], Step [10/104], Loss: 0.4880\n",
      "Epoch [2/12], Step [20/104], Loss: 0.4697\n",
      "Epoch [2/12], Step [30/104], Loss: 0.4443\n",
      "Epoch [2/12], Step [40/104], Loss: 0.4804\n",
      "Epoch [2/12], Step [50/104], Loss: 0.4150\n",
      "Epoch [2/12], Step [60/104], Loss: 0.4457\n",
      "Epoch [2/12], Step [70/104], Loss: 0.4531\n",
      "Epoch [2/12], Step [80/104], Loss: 0.3649\n",
      "Epoch [2/12], Step [90/104], Loss: 0.3435\n",
      "Epoch [2/12], Step [100/104], Loss: 0.4396\n",
      "Epoch [3/12], Step [10/104], Loss: 0.3599\n",
      "Epoch [3/12], Step [20/104], Loss: 0.2382\n",
      "Epoch [3/12], Step [30/104], Loss: 0.3944\n",
      "Epoch [3/12], Step [40/104], Loss: 0.3646\n",
      "Epoch [3/12], Step [50/104], Loss: 0.3140\n",
      "Epoch [3/12], Step [60/104], Loss: 0.2776\n",
      "Epoch [3/12], Step [70/104], Loss: 0.3015\n",
      "Epoch [3/12], Step [80/104], Loss: 0.3040\n",
      "Epoch [3/12], Step [90/104], Loss: 0.3226\n",
      "Epoch [3/12], Step [100/104], Loss: 0.2876\n",
      "Epoch [4/12], Step [10/104], Loss: 0.1932\n",
      "Epoch [4/12], Step [20/104], Loss: 0.3371\n",
      "Epoch [4/12], Step [30/104], Loss: 0.2400\n",
      "Epoch [4/12], Step [40/104], Loss: 0.1941\n",
      "Epoch [4/12], Step [50/104], Loss: 0.2222\n",
      "Epoch [4/12], Step [60/104], Loss: 0.4686\n",
      "Epoch [4/12], Step [70/104], Loss: 0.3867\n",
      "Epoch [4/12], Step [80/104], Loss: 0.1602\n",
      "Epoch [4/12], Step [90/104], Loss: 0.2444\n",
      "Epoch [4/12], Step [100/104], Loss: 0.3164\n",
      "Epoch [5/12], Step [10/104], Loss: 0.2722\n",
      "Epoch [5/12], Step [20/104], Loss: 0.2706\n",
      "Epoch [5/12], Step [30/104], Loss: 0.1739\n",
      "Epoch [5/12], Step [40/104], Loss: 0.3226\n",
      "Epoch [5/12], Step [50/104], Loss: 0.3347\n",
      "Epoch [5/12], Step [60/104], Loss: 0.1821\n",
      "Epoch [5/12], Step [70/104], Loss: 0.3384\n",
      "Epoch [5/12], Step [80/104], Loss: 0.2150\n",
      "Epoch [5/12], Step [90/104], Loss: 0.1477\n",
      "Epoch [5/12], Step [100/104], Loss: 0.2408\n",
      "Epoch [6/12], Step [10/104], Loss: 0.3182\n",
      "Epoch [6/12], Step [20/104], Loss: 0.3731\n",
      "Epoch [6/12], Step [30/104], Loss: 0.2212\n",
      "Epoch [6/12], Step [40/104], Loss: 0.3495\n",
      "Epoch [6/12], Step [50/104], Loss: 0.2947\n",
      "Epoch [6/12], Step [60/104], Loss: 0.2190\n",
      "Epoch [6/12], Step [70/104], Loss: 0.1102\n",
      "Epoch [6/12], Step [80/104], Loss: 0.3243\n",
      "Epoch [6/12], Step [90/104], Loss: 0.3480\n",
      "Epoch [6/12], Step [100/104], Loss: 0.1878\n",
      "Epoch [7/12], Step [10/104], Loss: 0.3126\n",
      "Epoch [7/12], Step [20/104], Loss: 0.2283\n",
      "Epoch [7/12], Step [30/104], Loss: 0.3462\n",
      "Epoch [7/12], Step [40/104], Loss: 0.1816\n",
      "Epoch [7/12], Step [50/104], Loss: 0.2594\n",
      "Epoch [7/12], Step [60/104], Loss: 0.1930\n",
      "Epoch [7/12], Step [70/104], Loss: 0.2392\n",
      "Epoch [7/12], Step [80/104], Loss: 0.2456\n",
      "Epoch [7/12], Step [90/104], Loss: 0.1668\n",
      "Epoch [7/12], Step [100/104], Loss: 0.2028\n",
      "Epoch [8/12], Step [10/104], Loss: 0.2267\n",
      "Epoch [8/12], Step [20/104], Loss: 0.1551\n",
      "Epoch [8/12], Step [30/104], Loss: 0.1649\n",
      "Epoch [8/12], Step [40/104], Loss: 0.1953\n",
      "Epoch [8/12], Step [50/104], Loss: 0.1564\n",
      "Epoch [8/12], Step [60/104], Loss: 0.2128\n",
      "Epoch [8/12], Step [70/104], Loss: 0.2720\n",
      "Epoch [8/12], Step [80/104], Loss: 0.1628\n",
      "Epoch [8/12], Step [90/104], Loss: 0.2143\n",
      "Epoch [8/12], Step [100/104], Loss: 0.1759\n",
      "Epoch [9/12], Step [10/104], Loss: 0.2035\n",
      "Epoch [9/12], Step [20/104], Loss: 0.1418\n",
      "Epoch [9/12], Step [30/104], Loss: 0.1771\n",
      "Epoch [9/12], Step [40/104], Loss: 0.1269\n",
      "Epoch [9/12], Step [50/104], Loss: 0.1627\n",
      "Epoch [9/12], Step [60/104], Loss: 0.3605\n",
      "Epoch [9/12], Step [70/104], Loss: 0.2946\n",
      "Epoch [9/12], Step [80/104], Loss: 0.2632\n",
      "Epoch [9/12], Step [90/104], Loss: 0.1151\n",
      "Epoch [9/12], Step [100/104], Loss: 0.1332\n",
      "Epoch [10/12], Step [10/104], Loss: 0.2767\n",
      "Epoch [10/12], Step [20/104], Loss: 0.1673\n",
      "Epoch [10/12], Step [30/104], Loss: 0.3969\n",
      "Epoch [10/12], Step [40/104], Loss: 0.1245\n",
      "Epoch [10/12], Step [50/104], Loss: 0.3871\n",
      "Epoch [10/12], Step [60/104], Loss: 0.2271\n",
      "Epoch [10/12], Step [70/104], Loss: 0.1992\n",
      "Epoch [10/12], Step [80/104], Loss: 0.1949\n",
      "Epoch [10/12], Step [90/104], Loss: 0.1881\n",
      "Epoch [10/12], Step [100/104], Loss: 0.1445\n",
      "Epoch [11/12], Step [10/104], Loss: 0.3004\n",
      "Epoch [11/12], Step [20/104], Loss: 0.1445\n",
      "Epoch [11/12], Step [30/104], Loss: 0.1560\n",
      "Epoch [11/12], Step [40/104], Loss: 0.1608\n",
      "Epoch [11/12], Step [50/104], Loss: 0.1529\n",
      "Epoch [11/12], Step [60/104], Loss: 0.1147\n",
      "Epoch [11/12], Step [70/104], Loss: 0.2578\n",
      "Epoch [11/12], Step [80/104], Loss: 0.1182\n",
      "Epoch [11/12], Step [90/104], Loss: 0.1625\n",
      "Epoch [11/12], Step [100/104], Loss: 0.2260\n",
      "Epoch [12/12], Step [10/104], Loss: 0.2165\n",
      "Epoch [12/12], Step [20/104], Loss: 0.1562\n",
      "Epoch [12/12], Step [30/104], Loss: 0.0996\n",
      "Epoch [12/12], Step [40/104], Loss: 0.1074\n",
      "Epoch [12/12], Step [50/104], Loss: 0.1610\n",
      "Epoch [12/12], Step [60/104], Loss: 0.2966\n",
      "Epoch [12/12], Step [70/104], Loss: 0.1968\n",
      "Epoch [12/12], Step [80/104], Loss: 0.1750\n",
      "Epoch [12/12], Step [90/104], Loss: 0.1461\n",
      "Epoch [12/12], Step [100/104], Loss: 0.3190\n"
     ]
    }
   ],
   "source": [
    "args.num_epochs = 12\n",
    "batch_size = 32\n",
    "\n",
    "train_loader =  torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader =  torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = LeNet5()\n",
    "model_name = \"LeNet5\"\n",
    "\n",
    "losses = train_by_model(model, model_name, args.num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "085abeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 91.5 %\n",
      "Accuracy of Normal: 86.62207357859532 %\n",
      "Accuracy of Tuberculosis: 96.34551495016612 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_acc_from_data(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2363dbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 95.66666666666667 %\n",
      "Accuracy of Normal: 92.46575342465754 %\n",
      "Accuracy of Tuberculosis: 98.7012987012987 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95.66666666666667"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_acc_from_data(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c523b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
