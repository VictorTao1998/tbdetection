{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff1ede8c",
   "metadata": {},
   "source": [
    "# ECE 228 Project\n",
    "## Tuberculosis Detection | Team 26\n",
    "### Jianyu Tao\n",
    "### Shreyas Borse\n",
    "### Harshit Bhadani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89309d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version 1.11.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "## Importing modules for necessary operations\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pdb\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import argparse\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print('Using PyTorch version', torch.__version__)\n",
    "\n",
    "\n",
    "from os.path import isfile\n",
    "from os import rename\n",
    "SMOOTH=1\n",
    "import pdb\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from PIL.ImageFilter import GaussianBlur\n",
    "\n",
    "# import pdb\n",
    "from numpy import pi as PI\n",
    "from numpy import sqrt\n",
    "from scipy.special import comb\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0be2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscellaneous initialization\n",
    "torch.manual_seed(1)\n",
    "start_time = time.time()\n",
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0d5de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"\"\n",
    "test_dataset_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fc58232",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/Users/harshitb/Desktop/Studies/ECE 228/TB_dataset/TB_Chest_Radiography_Database\"\n",
    "class_names = ['Normal', 'Tuberculosis']\n",
    "source_dirs = ['Normal', 'Tuberculosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "930810b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.add_argument('--num_epochs', type=int, default=5, help='Number of training epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='Batch size')\n",
    "parser.add_argument('--lr', type=float, default=5e-4, help='Learning rate')\n",
    "parser.add_argument('--l2', type=float, default=0, help='L2 regularisation')\n",
    "parser.add_argument('--aug', action='store_true', default=False, help='Use data augmentation')\n",
    "parser.add_argument('--data_path', type=str, default=root_dir,help='Path to data.')\n",
    "parser.add_argument('--bond_dim', type=int, default=5, help='MPS Bond dimension')\n",
    "parser.add_argument('--nChannel', type=int, default=1, help='Number of input channels')\n",
    "parser.add_argument('--dense_net', action='store_true', default=False, help='Using Dense Net model')\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "684a5c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = args.batch_size\n",
    "\n",
    "# LoTeNet parameters\n",
    "adaptive_mode = False \n",
    "periodic_bc   = False\n",
    "\n",
    "kernel = 2 # Stride along spatial dimensions\n",
    "output_dim = 1 # output dimension\n",
    " \n",
    "feature_dim = 2\n",
    "\n",
    "normTensor = 0.5*torch.ones(args.nChannel)\n",
    "### Data processing and loading....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a61e98b",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc2837a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data processing and loading....\n",
    "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.Resize(size=(256,256)),\n",
    "#                                       transforms.RandomVerticalFlip(),\n",
    "#                                       transforms.RandomRotation(20),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=normTensor,std=normTensor)])\n",
    "\n",
    "valid_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size=(256,256)),\n",
    "#     torchvision.transforms.RandomHorizontalFlip(),\n",
    "#     torchvision.transforms.RandomRotation(20),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=normTensor,std=normTensor)\n",
    "    #torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1abf12",
   "metadata": {},
   "source": [
    "### Creating Datasets classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a87dbe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXRayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_dirs,transform):\n",
    "        def get_images(class_name):\n",
    "            images = [x for x in os.listdir(image_dirs[class_name]) if x.lower().endswith('png')]\n",
    "            print(f'Found {len(images)}{class_name}')\n",
    "            return images\n",
    "        self.images={}\n",
    "        self.class_names=['Normal', 'Tuberculosis']\n",
    "        for c in self.class_names:\n",
    "            self.images[c]=get_images(c)\n",
    "        self.image_dirs=image_dirs\n",
    "        self.transform=transform\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return sum([len(self.images[c]) for c in self.class_names])\n",
    "    def __getitem__(self, index):\n",
    "        class_name=random.choice(self.class_names)\n",
    "        index=index%len(self.images[class_name])\n",
    "        image_name=self.images[class_name][index]\n",
    "        image_path =os.path.join(self.image_dirs[class_name], image_name)\n",
    "        image=Image.open(image_path).convert('L')\n",
    "        return self.transform(image), self.class_names.index(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56fa2063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3500Normal\n",
      "Found 700Tuberculosis\n"
     ]
    }
   ],
   "source": [
    "train_dirs = {\n",
    "    'Normal': root_dir + '/Normal',\n",
    "    'Tuberculosis': root_dir + '/Tuberculosis'\n",
    "}\n",
    "dataset = ChestXRayDataset(train_dirs, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfaf2476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbe34a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset, valset = random_split(dataset, [3300, 600, 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1288b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader =  torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader =  torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8fa93a",
   "metadata": {},
   "source": [
    "# Creating various architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "966057cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        #         xl = 1\n",
    "        #         for i in x.shape[1:]: xl *= i\n",
    "        #         self.fc1 = nn.Linear(13456, 120)\n",
    "        self.fc1 = nn.Linear(984064, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        #         x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
    "        #         x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv1(x))  # -> n, 6, 14, 14\n",
    "        x = F.relu(self.conv2(x))\n",
    "        xl = 1\n",
    "        for i in x.shape[1:]: xl *= i\n",
    "        x = x.view(-1, xl)            # \n",
    "        x = F.relu(self.fc1(x))               # -> n, 120\n",
    "        x = F.relu(self.fc2(x))               # -> n, 84\n",
    "        x = self.fc3(x)                       # -> n, 2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a40b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the convolutional neural network\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Linear(59536, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddf655a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.conv1_1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv4_1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv5_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(32768, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv5_1(x))\n",
    "        x = F.relu(self.conv5_2(x))\n",
    "        x = F.relu(self.conv5_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "#         print(\"HERE ... \", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, 0.5) #dropout was included to combat overfitting\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, 0.5)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88249028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising variable that will be used in the experiments in the project\n",
    "\n",
    "loss_data_of_model_epoch = {}\n",
    "acc_of_model_epoch = {}\n",
    "acc_of_model_batch = {}\n",
    "\n",
    "all_models = {}\n",
    "all_models['ConvNet'] = ConvNet()\n",
    "all_models['LeNet5']  = LeNet5()\n",
    "all_models['VGG16']   = VGG16()\n",
    "\n",
    "for model_name in all_models.keys():\n",
    "    loss_data_of_model_epoch[model_name] = {}\n",
    "    acc_of_model_epoch[model_name] = {}\n",
    "    acc_of_model_batch[model_name] = {}\n",
    "\n",
    "LeNet5_model_with_epoch = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab437e84",
   "metadata": {},
   "source": [
    "# Defining various functions to make the code modular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bd40115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_from_data(d_loader):\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        n_class_correct = [0 for i in range(2)]\n",
    "        n_class_samples = [0 for i in range(2)]\n",
    "        for images, labels in d_loader:\n",
    "            #         print(len(labels))\n",
    "            outputs = model(images)\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                pred = predicted[i]\n",
    "                if (label == pred):\n",
    "                    n_class_correct[label] += 1\n",
    "                n_class_samples[label] += 1\n",
    "\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network: {acc} %')\n",
    "        \n",
    "        all_acc = []\n",
    "        overall_accuracy = acc\n",
    "        all_acc.append(overall_accuracy)\n",
    "\n",
    "        for i in range(2):\n",
    "            acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "            print(f'Accuracy of {class_names[i]}: {acc} %')\n",
    "            all_acc.append(acc)\n",
    "                \n",
    "    #return all_acc\n",
    "    return overall_accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b1e415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_by_model(model, model_name, epo = 3, verbose = True):\n",
    "    args.num_epochs = epo\n",
    "    learning_rate = 0.001\n",
    "    all_loss = []\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    n_total_steps = len(train_loader)\n",
    "    for epoch in range(args.num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            all_loss.append(loss.item())\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if ((i+1) % 10 == 0) and verbose:\n",
    "                print (f'Epoch [{epoch+1}/{args.num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "        LeNet5_model_with_epoch[epoch+1] = copy.deepcopy(model)\n",
    "        \n",
    "    return all_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb0a14",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f57aec",
   "metadata": {},
   "source": [
    "### Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5446561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [10/104], Loss: 0.6163\n",
      "Epoch [1/3], Step [20/104], Loss: 0.4975\n",
      "Epoch [1/3], Step [30/104], Loss: 0.4750\n",
      "Epoch [1/3], Step [40/104], Loss: 0.3723\n",
      "Epoch [1/3], Step [50/104], Loss: 0.3880\n",
      "Epoch [1/3], Step [60/104], Loss: 0.3325\n",
      "Epoch [1/3], Step [70/104], Loss: 0.4315\n",
      "Epoch [1/3], Step [80/104], Loss: 0.2642\n",
      "Epoch [1/3], Step [90/104], Loss: 0.2391\n",
      "Epoch [1/3], Step [100/104], Loss: 0.2983\n",
      "Epoch [2/3], Step [10/104], Loss: 0.1946\n",
      "Epoch [2/3], Step [20/104], Loss: 0.2744\n",
      "Epoch [2/3], Step [30/104], Loss: 0.2455\n",
      "Epoch [2/3], Step [40/104], Loss: 0.3258\n",
      "Epoch [2/3], Step [50/104], Loss: 0.2929\n",
      "Epoch [2/3], Step [60/104], Loss: 0.2203\n",
      "Epoch [2/3], Step [70/104], Loss: 0.1486\n",
      "Epoch [2/3], Step [80/104], Loss: 0.2196\n",
      "Epoch [2/3], Step [90/104], Loss: 0.1990\n",
      "Epoch [2/3], Step [100/104], Loss: 0.2819\n",
      "Epoch [3/3], Step [10/104], Loss: 0.2159\n",
      "Epoch [3/3], Step [20/104], Loss: 0.1289\n",
      "Epoch [3/3], Step [30/104], Loss: 0.1659\n",
      "Epoch [3/3], Step [40/104], Loss: 0.3647\n",
      "Epoch [3/3], Step [50/104], Loss: 0.2580\n",
      "Epoch [3/3], Step [60/104], Loss: 0.1721\n",
      "Epoch [3/3], Step [70/104], Loss: 0.2299\n",
      "Epoch [3/3], Step [80/104], Loss: 0.2010\n",
      "Epoch [3/3], Step [90/104], Loss: 0.2067\n",
      "Epoch [3/3], Step [100/104], Loss: 0.1802\n",
      "Accuracy of the network: 94.83333333333333 %\n",
      "Accuracy of Normal: 96.38157894736842 %\n",
      "Accuracy of Tuberculosis: 93.24324324324324 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94.83333333333333"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking various architectures above one by one with epoch = 3\n",
    "\n",
    "model_name = \"LeNet5\"\n",
    "model = all_models[model_name]\n",
    "\n",
    "train_by_model(model, model_name)\n",
    "get_acc_from_data(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e87e940",
   "metadata": {},
   "source": [
    "### Experiment 2: Deciding epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75599bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [10/104], Loss: 0.6082\n",
      "Epoch [1/1], Step [20/104], Loss: 0.5122\n",
      "Epoch [1/1], Step [30/104], Loss: 0.4848\n",
      "Epoch [1/1], Step [40/104], Loss: 0.4262\n",
      "Epoch [1/1], Step [50/104], Loss: 0.4130\n",
      "Epoch [1/1], Step [60/104], Loss: 0.3385\n",
      "Epoch [1/1], Step [70/104], Loss: 0.3497\n",
      "Epoch [1/1], Step [80/104], Loss: 0.2499\n",
      "Epoch [1/1], Step [90/104], Loss: 0.3179\n",
      "Epoch [1/1], Step [100/104], Loss: 0.2311\n",
      "Epoch done:  2  Calculating accuracy\n",
      "Accuracy of the network: 88.16666666666667 %\n",
      "Accuracy of Normal: 98.3108108108108 %\n",
      "Accuracy of Tuberculosis: 78.28947368421052 %\n",
      "Epoch [1/2], Step [10/104], Loss: 0.6190\n",
      "Epoch [1/2], Step [20/104], Loss: 0.5681\n",
      "Epoch [1/2], Step [30/104], Loss: 0.4744\n",
      "Epoch [1/2], Step [40/104], Loss: 0.4226\n",
      "Epoch [1/2], Step [50/104], Loss: 0.4325\n",
      "Epoch [1/2], Step [60/104], Loss: 0.3075\n",
      "Epoch [1/2], Step [70/104], Loss: 0.3921\n",
      "Epoch [1/2], Step [80/104], Loss: 0.2532\n",
      "Epoch [1/2], Step [90/104], Loss: 0.2425\n",
      "Epoch [1/2], Step [100/104], Loss: 0.2697\n",
      "Epoch [2/2], Step [10/104], Loss: 0.4929\n",
      "Epoch [2/2], Step [20/104], Loss: 0.3193\n",
      "Epoch [2/2], Step [30/104], Loss: 0.3806\n",
      "Epoch [2/2], Step [40/104], Loss: 0.2186\n",
      "Epoch [2/2], Step [50/104], Loss: 0.2635\n",
      "Epoch [2/2], Step [60/104], Loss: 0.2395\n",
      "Epoch [2/2], Step [70/104], Loss: 0.2110\n",
      "Epoch [2/2], Step [80/104], Loss: 0.2922\n",
      "Epoch [2/2], Step [90/104], Loss: 0.2047\n",
      "Epoch [2/2], Step [100/104], Loss: 0.2445\n",
      "Epoch done:  3  Calculating accuracy\n",
      "Accuracy of the network: 88.66666666666667 %\n",
      "Accuracy of Normal: 100.0 %\n",
      "Accuracy of Tuberculosis: 78.06451612903226 %\n",
      "Epoch [1/3], Step [10/104], Loss: 0.6554\n",
      "Epoch [1/3], Step [20/104], Loss: 0.6244\n",
      "Epoch [1/3], Step [30/104], Loss: 0.5317\n",
      "Epoch [1/3], Step [40/104], Loss: 0.4843\n",
      "Epoch [1/3], Step [50/104], Loss: 0.4136\n",
      "Epoch [1/3], Step [60/104], Loss: 0.4090\n",
      "Epoch [1/3], Step [70/104], Loss: 0.3292\n",
      "Epoch [1/3], Step [80/104], Loss: 0.3754\n",
      "Epoch [1/3], Step [90/104], Loss: 0.3149\n",
      "Epoch [1/3], Step [100/104], Loss: 0.2879\n",
      "Epoch [2/3], Step [10/104], Loss: 0.3205\n",
      "Epoch [2/3], Step [20/104], Loss: 0.3782\n",
      "Epoch [2/3], Step [30/104], Loss: 0.3022\n",
      "Epoch [2/3], Step [40/104], Loss: 0.3556\n",
      "Epoch [2/3], Step [50/104], Loss: 0.2435\n",
      "Epoch [2/3], Step [60/104], Loss: 0.1958\n",
      "Epoch [2/3], Step [70/104], Loss: 0.1713\n",
      "Epoch [2/3], Step [80/104], Loss: 0.1933\n",
      "Epoch [2/3], Step [90/104], Loss: 0.2911\n",
      "Epoch [2/3], Step [100/104], Loss: 0.1633\n",
      "Epoch [3/3], Step [10/104], Loss: 0.1861\n",
      "Epoch [3/3], Step [20/104], Loss: 0.1209\n",
      "Epoch [3/3], Step [30/104], Loss: 0.1792\n",
      "Epoch [3/3], Step [40/104], Loss: 0.2410\n",
      "Epoch [3/3], Step [50/104], Loss: 0.1695\n",
      "Epoch [3/3], Step [60/104], Loss: 0.2018\n",
      "Epoch [3/3], Step [70/104], Loss: 0.1348\n",
      "Epoch [3/3], Step [80/104], Loss: 0.3395\n",
      "Epoch [3/3], Step [90/104], Loss: 0.1958\n",
      "Epoch [3/3], Step [100/104], Loss: 0.2087\n",
      "Epoch done:  4  Calculating accuracy\n",
      "Accuracy of the network: 94.83333333333333 %\n",
      "Accuracy of Normal: 96.34551495016612 %\n",
      "Accuracy of Tuberculosis: 93.31103678929766 %\n",
      "Epoch [1/4], Step [10/104], Loss: 0.6490\n",
      "Epoch [1/4], Step [20/104], Loss: 0.5485\n",
      "Epoch [1/4], Step [30/104], Loss: 0.5482\n",
      "Epoch [1/4], Step [40/104], Loss: 0.4581\n",
      "Epoch [1/4], Step [50/104], Loss: 0.4184\n",
      "Epoch [1/4], Step [60/104], Loss: 0.4254\n",
      "Epoch [1/4], Step [70/104], Loss: 0.2885\n",
      "Epoch [1/4], Step [80/104], Loss: 0.3819\n",
      "Epoch [1/4], Step [90/104], Loss: 0.3523\n",
      "Epoch [1/4], Step [100/104], Loss: 0.4110\n",
      "Epoch [2/4], Step [10/104], Loss: 0.3651\n",
      "Epoch [2/4], Step [20/104], Loss: 0.3495\n",
      "Epoch [2/4], Step [30/104], Loss: 0.2489\n",
      "Epoch [2/4], Step [40/104], Loss: 0.2316\n",
      "Epoch [2/4], Step [50/104], Loss: 0.1420\n",
      "Epoch [2/4], Step [60/104], Loss: 0.1432\n",
      "Epoch [2/4], Step [70/104], Loss: 0.1848\n",
      "Epoch [2/4], Step [80/104], Loss: 0.1417\n",
      "Epoch [2/4], Step [90/104], Loss: 0.3948\n",
      "Epoch [2/4], Step [100/104], Loss: 0.2322\n",
      "Epoch [3/4], Step [10/104], Loss: 0.2232\n",
      "Epoch [3/4], Step [20/104], Loss: 0.1369\n",
      "Epoch [3/4], Step [30/104], Loss: 0.1216\n",
      "Epoch [3/4], Step [40/104], Loss: 0.1501\n",
      "Epoch [3/4], Step [50/104], Loss: 0.1938\n",
      "Epoch [3/4], Step [60/104], Loss: 0.1534\n",
      "Epoch [3/4], Step [70/104], Loss: 0.0974\n",
      "Epoch [3/4], Step [80/104], Loss: 0.1377\n",
      "Epoch [3/4], Step [90/104], Loss: 0.2162\n",
      "Epoch [3/4], Step [100/104], Loss: 0.1932\n",
      "Epoch [4/4], Step [10/104], Loss: 0.1952\n",
      "Epoch [4/4], Step [20/104], Loss: 0.1907\n",
      "Epoch [4/4], Step [30/104], Loss: 0.1495\n",
      "Epoch [4/4], Step [40/104], Loss: 0.1408\n",
      "Epoch [4/4], Step [50/104], Loss: 0.2109\n",
      "Epoch [4/4], Step [60/104], Loss: 0.1725\n",
      "Epoch [4/4], Step [70/104], Loss: 0.2002\n",
      "Epoch [4/4], Step [80/104], Loss: 0.3027\n",
      "Epoch [4/4], Step [90/104], Loss: 0.0980\n",
      "Epoch [4/4], Step [100/104], Loss: 0.2116\n",
      "Epoch done:  5  Calculating accuracy\n",
      "Accuracy of the network: 95.83333333333333 %\n",
      "Accuracy of Normal: 94.71947194719472 %\n",
      "Accuracy of Tuberculosis: 96.96969696969697 %\n",
      "Epoch [1/5], Step [10/104], Loss: 0.6395\n",
      "Epoch [1/5], Step [20/104], Loss: 0.6217\n",
      "Epoch [1/5], Step [30/104], Loss: 0.4796\n",
      "Epoch [1/5], Step [40/104], Loss: 0.4119\n",
      "Epoch [1/5], Step [50/104], Loss: 0.5399\n",
      "Epoch [1/5], Step [60/104], Loss: 0.3708\n",
      "Epoch [1/5], Step [70/104], Loss: 0.4189\n",
      "Epoch [1/5], Step [80/104], Loss: 0.3001\n",
      "Epoch [1/5], Step [90/104], Loss: 0.2975\n",
      "Epoch [1/5], Step [100/104], Loss: 0.3924\n",
      "Epoch [2/5], Step [10/104], Loss: 0.2063\n",
      "Epoch [2/5], Step [20/104], Loss: 0.2833\n",
      "Epoch [2/5], Step [30/104], Loss: 0.2252\n",
      "Epoch [2/5], Step [40/104], Loss: 0.2176\n",
      "Epoch [2/5], Step [50/104], Loss: 0.2568\n",
      "Epoch [2/5], Step [60/104], Loss: 0.2527\n",
      "Epoch [2/5], Step [70/104], Loss: 0.2056\n",
      "Epoch [2/5], Step [80/104], Loss: 0.2676\n",
      "Epoch [2/5], Step [90/104], Loss: 0.4026\n",
      "Epoch [2/5], Step [100/104], Loss: 0.1497\n",
      "Epoch [3/5], Step [10/104], Loss: 0.1796\n",
      "Epoch [3/5], Step [20/104], Loss: 0.2054\n",
      "Epoch [3/5], Step [30/104], Loss: 0.0856\n",
      "Epoch [3/5], Step [40/104], Loss: 0.1671\n",
      "Epoch [3/5], Step [50/104], Loss: 0.2632\n",
      "Epoch [3/5], Step [60/104], Loss: 0.1292\n",
      "Epoch [3/5], Step [70/104], Loss: 0.1200\n",
      "Epoch [3/5], Step [80/104], Loss: 0.0528\n",
      "Epoch [3/5], Step [90/104], Loss: 0.1868\n",
      "Epoch [3/5], Step [100/104], Loss: 0.1044\n",
      "Epoch [4/5], Step [10/104], Loss: 0.0954\n",
      "Epoch [4/5], Step [20/104], Loss: 0.1196\n",
      "Epoch [4/5], Step [30/104], Loss: 0.1586\n",
      "Epoch [4/5], Step [40/104], Loss: 0.1941\n",
      "Epoch [4/5], Step [50/104], Loss: 0.1163\n",
      "Epoch [4/5], Step [60/104], Loss: 0.1130\n",
      "Epoch [4/5], Step [70/104], Loss: 0.0799\n",
      "Epoch [4/5], Step [80/104], Loss: 0.3381\n",
      "Epoch [4/5], Step [90/104], Loss: 0.1468\n",
      "Epoch [4/5], Step [100/104], Loss: 0.1047\n",
      "Epoch [5/5], Step [10/104], Loss: 0.1043\n",
      "Epoch [5/5], Step [20/104], Loss: 0.1582\n",
      "Epoch [5/5], Step [30/104], Loss: 0.0923\n",
      "Epoch [5/5], Step [40/104], Loss: 0.1811\n",
      "Epoch [5/5], Step [50/104], Loss: 0.0562\n",
      "Epoch [5/5], Step [60/104], Loss: 0.0724\n",
      "Epoch [5/5], Step [70/104], Loss: 0.1339\n",
      "Epoch [5/5], Step [80/104], Loss: 0.1976\n",
      "Epoch [5/5], Step [90/104], Loss: 0.1241\n",
      "Epoch [5/5], Step [100/104], Loss: 0.1716\n",
      "Epoch done:  6  Calculating accuracy\n",
      "Accuracy of the network: 94.83333333333333 %\n",
      "Accuracy of Normal: 92.40924092409242 %\n",
      "Accuracy of Tuberculosis: 97.3063973063973 %\n",
      "Epoch [1/6], Step [10/104], Loss: 0.6049\n",
      "Epoch [1/6], Step [20/104], Loss: 0.5376\n",
      "Epoch [1/6], Step [30/104], Loss: 0.4686\n",
      "Epoch [1/6], Step [40/104], Loss: 0.3868\n",
      "Epoch [1/6], Step [50/104], Loss: 0.3028\n",
      "Epoch [1/6], Step [60/104], Loss: 0.3816\n",
      "Epoch [1/6], Step [70/104], Loss: 0.2660\n",
      "Epoch [1/6], Step [80/104], Loss: 0.3493\n",
      "Epoch [1/6], Step [90/104], Loss: 0.3519\n",
      "Epoch [1/6], Step [100/104], Loss: 0.3142\n",
      "Epoch [2/6], Step [10/104], Loss: 0.2914\n",
      "Epoch [2/6], Step [20/104], Loss: 0.2162\n",
      "Epoch [2/6], Step [30/104], Loss: 0.1824\n",
      "Epoch [2/6], Step [40/104], Loss: 0.2344\n",
      "Epoch [2/6], Step [50/104], Loss: 0.2601\n",
      "Epoch [2/6], Step [60/104], Loss: 0.2601\n",
      "Epoch [2/6], Step [70/104], Loss: 0.2413\n",
      "Epoch [2/6], Step [80/104], Loss: 0.1475\n",
      "Epoch [2/6], Step [90/104], Loss: 0.2792\n",
      "Epoch [2/6], Step [100/104], Loss: 0.2336\n",
      "Epoch [3/6], Step [10/104], Loss: 0.1225\n",
      "Epoch [3/6], Step [20/104], Loss: 0.1845\n",
      "Epoch [3/6], Step [30/104], Loss: 0.0972\n",
      "Epoch [3/6], Step [40/104], Loss: 0.2295\n",
      "Epoch [3/6], Step [50/104], Loss: 0.1069\n",
      "Epoch [3/6], Step [60/104], Loss: 0.1434\n",
      "Epoch [3/6], Step [70/104], Loss: 0.3555\n",
      "Epoch [3/6], Step [80/104], Loss: 0.1246\n",
      "Epoch [3/6], Step [90/104], Loss: 0.2211\n",
      "Epoch [3/6], Step [100/104], Loss: 0.1037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/6], Step [10/104], Loss: 0.1710\n",
      "Epoch [4/6], Step [20/104], Loss: 0.1091\n",
      "Epoch [4/6], Step [30/104], Loss: 0.1400\n",
      "Epoch [4/6], Step [40/104], Loss: 0.1090\n",
      "Epoch [4/6], Step [50/104], Loss: 0.0962\n",
      "Epoch [4/6], Step [60/104], Loss: 0.0496\n",
      "Epoch [4/6], Step [70/104], Loss: 0.1665\n",
      "Epoch [4/6], Step [80/104], Loss: 0.1442\n",
      "Epoch [4/6], Step [90/104], Loss: 0.1813\n",
      "Epoch [4/6], Step [100/104], Loss: 0.1368\n",
      "Epoch [5/6], Step [10/104], Loss: 0.1683\n",
      "Epoch [5/6], Step [20/104], Loss: 0.1574\n",
      "Epoch [5/6], Step [30/104], Loss: 0.2239\n",
      "Epoch [5/6], Step [40/104], Loss: 0.0563\n",
      "Epoch [5/6], Step [50/104], Loss: 0.1144\n",
      "Epoch [5/6], Step [60/104], Loss: 0.0465\n",
      "Epoch [5/6], Step [70/104], Loss: 0.2355\n",
      "Epoch [5/6], Step [80/104], Loss: 0.0667\n",
      "Epoch [5/6], Step [90/104], Loss: 0.1396\n",
      "Epoch [5/6], Step [100/104], Loss: 0.0487\n",
      "Epoch [6/6], Step [10/104], Loss: 0.1074\n",
      "Epoch [6/6], Step [20/104], Loss: 0.0562\n",
      "Epoch [6/6], Step [30/104], Loss: 0.2129\n",
      "Epoch [6/6], Step [40/104], Loss: 0.0882\n",
      "Epoch [6/6], Step [50/104], Loss: 0.0769\n",
      "Epoch [6/6], Step [60/104], Loss: 0.0733\n",
      "Epoch [6/6], Step [70/104], Loss: 0.0331\n",
      "Epoch [6/6], Step [80/104], Loss: 0.1547\n",
      "Epoch [6/6], Step [90/104], Loss: 0.0389\n",
      "Epoch [6/6], Step [100/104], Loss: 0.1428\n",
      "Epoch done:  7  Calculating accuracy\n",
      "Accuracy of the network: 97.0 %\n",
      "Accuracy of Normal: 96.45161290322581 %\n",
      "Accuracy of Tuberculosis: 97.58620689655173 %\n",
      "Epoch [1/7], Step [10/104], Loss: 0.6227\n",
      "Epoch [1/7], Step [20/104], Loss: 0.5632\n",
      "Epoch [1/7], Step [30/104], Loss: 0.4235\n",
      "Epoch [1/7], Step [40/104], Loss: 0.3610\n",
      "Epoch [1/7], Step [50/104], Loss: 0.3750\n",
      "Epoch [1/7], Step [60/104], Loss: 0.3631\n",
      "Epoch [1/7], Step [70/104], Loss: 0.3008\n",
      "Epoch [1/7], Step [80/104], Loss: 0.3017\n",
      "Epoch [1/7], Step [90/104], Loss: 0.3618\n",
      "Epoch [1/7], Step [100/104], Loss: 0.1462\n",
      "Epoch [2/7], Step [10/104], Loss: 0.2627\n",
      "Epoch [2/7], Step [20/104], Loss: 0.2746\n",
      "Epoch [2/7], Step [30/104], Loss: 0.2718\n",
      "Epoch [2/7], Step [40/104], Loss: 0.2154\n",
      "Epoch [2/7], Step [50/104], Loss: 0.1587\n",
      "Epoch [2/7], Step [60/104], Loss: 0.2092\n",
      "Epoch [2/7], Step [70/104], Loss: 0.1531\n",
      "Epoch [2/7], Step [80/104], Loss: 0.1630\n",
      "Epoch [2/7], Step [90/104], Loss: 0.2014\n",
      "Epoch [2/7], Step [100/104], Loss: 0.1616\n",
      "Epoch [3/7], Step [10/104], Loss: 0.2899\n",
      "Epoch [3/7], Step [20/104], Loss: 0.0919\n",
      "Epoch [3/7], Step [30/104], Loss: 0.1939\n",
      "Epoch [3/7], Step [40/104], Loss: 0.0821\n",
      "Epoch [3/7], Step [50/104], Loss: 0.2121\n",
      "Epoch [3/7], Step [60/104], Loss: 0.1466\n",
      "Epoch [3/7], Step [70/104], Loss: 0.1333\n",
      "Epoch [3/7], Step [80/104], Loss: 0.0724\n",
      "Epoch [3/7], Step [90/104], Loss: 0.1398\n",
      "Epoch [3/7], Step [100/104], Loss: 0.1186\n",
      "Epoch [4/7], Step [10/104], Loss: 0.0685\n",
      "Epoch [4/7], Step [20/104], Loss: 0.0593\n",
      "Epoch [4/7], Step [30/104], Loss: 0.0980\n",
      "Epoch [4/7], Step [40/104], Loss: 0.1336\n",
      "Epoch [4/7], Step [50/104], Loss: 0.1261\n",
      "Epoch [4/7], Step [60/104], Loss: 0.0949\n",
      "Epoch [4/7], Step [70/104], Loss: 0.1458\n",
      "Epoch [4/7], Step [80/104], Loss: 0.1317\n",
      "Epoch [4/7], Step [90/104], Loss: 0.0596\n",
      "Epoch [4/7], Step [100/104], Loss: 0.1143\n",
      "Epoch [5/7], Step [10/104], Loss: 0.1206\n",
      "Epoch [5/7], Step [20/104], Loss: 0.1662\n",
      "Epoch [5/7], Step [30/104], Loss: 0.1141\n",
      "Epoch [5/7], Step [40/104], Loss: 0.0480\n",
      "Epoch [5/7], Step [50/104], Loss: 0.0370\n",
      "Epoch [5/7], Step [60/104], Loss: 0.1813\n",
      "Epoch [5/7], Step [70/104], Loss: 0.0493\n",
      "Epoch [5/7], Step [80/104], Loss: 0.0372\n",
      "Epoch [5/7], Step [90/104], Loss: 0.1114\n",
      "Epoch [5/7], Step [100/104], Loss: 0.2040\n",
      "Epoch [6/7], Step [10/104], Loss: 0.0870\n",
      "Epoch [6/7], Step [20/104], Loss: 0.2230\n",
      "Epoch [6/7], Step [30/104], Loss: 0.0449\n",
      "Epoch [6/7], Step [40/104], Loss: 0.1135\n",
      "Epoch [6/7], Step [50/104], Loss: 0.1547\n",
      "Epoch [6/7], Step [60/104], Loss: 0.0627\n",
      "Epoch [6/7], Step [70/104], Loss: 0.1145\n",
      "Epoch [6/7], Step [80/104], Loss: 0.1139\n",
      "Epoch [6/7], Step [90/104], Loss: 0.1049\n",
      "Epoch [6/7], Step [100/104], Loss: 0.1080\n",
      "Epoch [7/7], Step [10/104], Loss: 0.1444\n",
      "Epoch [7/7], Step [20/104], Loss: 0.0996\n",
      "Epoch [7/7], Step [30/104], Loss: 0.1562\n",
      "Epoch [7/7], Step [40/104], Loss: 0.0697\n",
      "Epoch [7/7], Step [50/104], Loss: 0.0233\n",
      "Epoch [7/7], Step [60/104], Loss: 0.0915\n",
      "Epoch [7/7], Step [70/104], Loss: 0.1250\n",
      "Epoch [7/7], Step [80/104], Loss: 0.0912\n",
      "Epoch [7/7], Step [90/104], Loss: 0.0747\n",
      "Epoch [7/7], Step [100/104], Loss: 0.0895\n",
      "Epoch done:  8  Calculating accuracy\n",
      "Accuracy of the network: 96.16666666666667 %\n",
      "Accuracy of Normal: 97.95918367346938 %\n",
      "Accuracy of Tuberculosis: 94.44444444444444 %\n",
      "Epoch [1/8], Step [10/104], Loss: 0.6338\n",
      "Epoch [1/8], Step [20/104], Loss: 0.5343\n",
      "Epoch [1/8], Step [30/104], Loss: 0.5033\n",
      "Epoch [1/8], Step [40/104], Loss: 0.3591\n",
      "Epoch [1/8], Step [50/104], Loss: 0.3792\n",
      "Epoch [1/8], Step [60/104], Loss: 0.4570\n",
      "Epoch [1/8], Step [70/104], Loss: 0.3795\n",
      "Epoch [1/8], Step [80/104], Loss: 0.2500\n",
      "Epoch [1/8], Step [90/104], Loss: 0.2199\n",
      "Epoch [1/8], Step [100/104], Loss: 0.4283\n",
      "Epoch [2/8], Step [10/104], Loss: 0.2178\n",
      "Epoch [2/8], Step [20/104], Loss: 0.2986\n",
      "Epoch [2/8], Step [30/104], Loss: 0.2644\n",
      "Epoch [2/8], Step [40/104], Loss: 0.2614\n",
      "Epoch [2/8], Step [50/104], Loss: 0.3081\n",
      "Epoch [2/8], Step [60/104], Loss: 0.3090\n",
      "Epoch [2/8], Step [70/104], Loss: 0.1740\n",
      "Epoch [2/8], Step [80/104], Loss: 0.3088\n",
      "Epoch [2/8], Step [90/104], Loss: 0.2776\n",
      "Epoch [2/8], Step [100/104], Loss: 0.1434\n",
      "Epoch [3/8], Step [10/104], Loss: 0.1982\n",
      "Epoch [3/8], Step [20/104], Loss: 0.1958\n",
      "Epoch [3/8], Step [30/104], Loss: 0.2736\n",
      "Epoch [3/8], Step [40/104], Loss: 0.2878\n",
      "Epoch [3/8], Step [50/104], Loss: 0.1612\n",
      "Epoch [3/8], Step [60/104], Loss: 0.1367\n",
      "Epoch [3/8], Step [70/104], Loss: 0.2284\n",
      "Epoch [3/8], Step [80/104], Loss: 0.2417\n",
      "Epoch [3/8], Step [90/104], Loss: 0.0955\n",
      "Epoch [3/8], Step [100/104], Loss: 0.2104\n",
      "Epoch [4/8], Step [10/104], Loss: 0.2395\n",
      "Epoch [4/8], Step [20/104], Loss: 0.0807\n",
      "Epoch [4/8], Step [30/104], Loss: 0.1536\n",
      "Epoch [4/8], Step [40/104], Loss: 0.1076\n",
      "Epoch [4/8], Step [50/104], Loss: 0.0858\n",
      "Epoch [4/8], Step [60/104], Loss: 0.2464\n",
      "Epoch [4/8], Step [70/104], Loss: 0.0984\n",
      "Epoch [4/8], Step [80/104], Loss: 0.2686\n",
      "Epoch [4/8], Step [90/104], Loss: 0.0855\n",
      "Epoch [4/8], Step [100/104], Loss: 0.3692\n",
      "Epoch [5/8], Step [10/104], Loss: 0.1663\n",
      "Epoch [5/8], Step [20/104], Loss: 0.1294\n",
      "Epoch [5/8], Step [30/104], Loss: 0.0643\n",
      "Epoch [5/8], Step [40/104], Loss: 0.1563\n",
      "Epoch [5/8], Step [50/104], Loss: 0.1692\n",
      "Epoch [5/8], Step [60/104], Loss: 0.1957\n",
      "Epoch [5/8], Step [70/104], Loss: 0.1990\n",
      "Epoch [5/8], Step [80/104], Loss: 0.0801\n",
      "Epoch [5/8], Step [90/104], Loss: 0.1253\n",
      "Epoch [5/8], Step [100/104], Loss: 0.1394\n",
      "Epoch [6/8], Step [10/104], Loss: 0.0676\n",
      "Epoch [6/8], Step [20/104], Loss: 0.0941\n",
      "Epoch [6/8], Step [30/104], Loss: 0.0888\n",
      "Epoch [6/8], Step [40/104], Loss: 0.1096\n",
      "Epoch [6/8], Step [50/104], Loss: 0.0864\n",
      "Epoch [6/8], Step [60/104], Loss: 0.1094\n",
      "Epoch [6/8], Step [70/104], Loss: 0.2057\n",
      "Epoch [6/8], Step [80/104], Loss: 0.1739\n",
      "Epoch [6/8], Step [90/104], Loss: 0.2385\n",
      "Epoch [6/8], Step [100/104], Loss: 0.0419\n",
      "Epoch [7/8], Step [10/104], Loss: 0.0936\n",
      "Epoch [7/8], Step [20/104], Loss: 0.0389\n",
      "Epoch [7/8], Step [30/104], Loss: 0.2471\n",
      "Epoch [7/8], Step [40/104], Loss: 0.1431\n",
      "Epoch [7/8], Step [50/104], Loss: 0.0916\n",
      "Epoch [7/8], Step [60/104], Loss: 0.1791\n",
      "Epoch [7/8], Step [70/104], Loss: 0.0650\n",
      "Epoch [7/8], Step [80/104], Loss: 0.1516\n",
      "Epoch [7/8], Step [90/104], Loss: 0.0899\n",
      "Epoch [7/8], Step [100/104], Loss: 0.0619\n",
      "Epoch [8/8], Step [10/104], Loss: 0.1537\n",
      "Epoch [8/8], Step [20/104], Loss: 0.0297\n",
      "Epoch [8/8], Step [30/104], Loss: 0.0495\n",
      "Epoch [8/8], Step [40/104], Loss: 0.0471\n",
      "Epoch [8/8], Step [50/104], Loss: 0.0503\n",
      "Epoch [8/8], Step [60/104], Loss: 0.0804\n",
      "Epoch [8/8], Step [70/104], Loss: 0.1627\n",
      "Epoch [8/8], Step [80/104], Loss: 0.0899\n",
      "Epoch [8/8], Step [90/104], Loss: 0.0397\n",
      "Epoch [8/8], Step [100/104], Loss: 0.0904\n",
      "Epoch done:  9  Calculating accuracy\n",
      "Accuracy of the network: 96.83333333333333 %\n",
      "Accuracy of Normal: 97.57785467128028 %\n",
      "Accuracy of Tuberculosis: 96.14147909967846 %\n",
      "Epoch [1/9], Step [10/104], Loss: 0.6365\n",
      "Epoch [1/9], Step [20/104], Loss: 0.5265\n",
      "Epoch [1/9], Step [30/104], Loss: 0.5763\n",
      "Epoch [1/9], Step [40/104], Loss: 0.4328\n",
      "Epoch [1/9], Step [50/104], Loss: 0.3557\n",
      "Epoch [1/9], Step [60/104], Loss: 0.4402\n",
      "Epoch [1/9], Step [70/104], Loss: 0.3361\n",
      "Epoch [1/9], Step [80/104], Loss: 0.2797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/9], Step [90/104], Loss: 0.3875\n",
      "Epoch [1/9], Step [100/104], Loss: 0.2248\n",
      "Epoch [2/9], Step [10/104], Loss: 0.3553\n",
      "Epoch [2/9], Step [20/104], Loss: 0.2129\n",
      "Epoch [2/9], Step [30/104], Loss: 0.2798\n",
      "Epoch [2/9], Step [40/104], Loss: 0.4043\n",
      "Epoch [2/9], Step [50/104], Loss: 0.1830\n",
      "Epoch [2/9], Step [60/104], Loss: 0.1796\n",
      "Epoch [2/9], Step [70/104], Loss: 0.2241\n",
      "Epoch [2/9], Step [80/104], Loss: 0.2589\n",
      "Epoch [2/9], Step [90/104], Loss: 0.2366\n",
      "Epoch [2/9], Step [100/104], Loss: 0.1459\n",
      "Epoch [3/9], Step [10/104], Loss: 0.1677\n",
      "Epoch [3/9], Step [20/104], Loss: 0.3145\n",
      "Epoch [3/9], Step [30/104], Loss: 0.1928\n",
      "Epoch [3/9], Step [40/104], Loss: 0.1562\n",
      "Epoch [3/9], Step [50/104], Loss: 0.1981\n",
      "Epoch [3/9], Step [60/104], Loss: 0.1411\n",
      "Epoch [3/9], Step [70/104], Loss: 0.1594\n",
      "Epoch [3/9], Step [80/104], Loss: 0.1500\n",
      "Epoch [3/9], Step [90/104], Loss: 0.1112\n",
      "Epoch [3/9], Step [100/104], Loss: 0.2703\n",
      "Epoch [4/9], Step [10/104], Loss: 0.1498\n",
      "Epoch [4/9], Step [20/104], Loss: 0.1893\n",
      "Epoch [4/9], Step [30/104], Loss: 0.1536\n",
      "Epoch [4/9], Step [40/104], Loss: 0.0818\n",
      "Epoch [4/9], Step [50/104], Loss: 0.1750\n",
      "Epoch [4/9], Step [60/104], Loss: 0.1416\n",
      "Epoch [4/9], Step [70/104], Loss: 0.1716\n",
      "Epoch [4/9], Step [80/104], Loss: 0.1149\n",
      "Epoch [4/9], Step [90/104], Loss: 0.3702\n",
      "Epoch [4/9], Step [100/104], Loss: 0.1347\n",
      "Epoch [5/9], Step [10/104], Loss: 0.2002\n",
      "Epoch [5/9], Step [20/104], Loss: 0.0582\n",
      "Epoch [5/9], Step [30/104], Loss: 0.1067\n",
      "Epoch [5/9], Step [40/104], Loss: 0.1111\n",
      "Epoch [5/9], Step [50/104], Loss: 0.2278\n",
      "Epoch [5/9], Step [60/104], Loss: 0.0464\n",
      "Epoch [5/9], Step [70/104], Loss: 0.0774\n",
      "Epoch [5/9], Step [80/104], Loss: 0.0703\n",
      "Epoch [5/9], Step [90/104], Loss: 0.1356\n",
      "Epoch [5/9], Step [100/104], Loss: 0.0476\n",
      "Epoch [6/9], Step [10/104], Loss: 0.1422\n",
      "Epoch [6/9], Step [20/104], Loss: 0.1009\n",
      "Epoch [6/9], Step [30/104], Loss: 0.0507\n",
      "Epoch [6/9], Step [40/104], Loss: 0.1086\n",
      "Epoch [6/9], Step [50/104], Loss: 0.0970\n",
      "Epoch [6/9], Step [60/104], Loss: 0.0652\n",
      "Epoch [6/9], Step [70/104], Loss: 0.0802\n",
      "Epoch [6/9], Step [80/104], Loss: 0.0427\n",
      "Epoch [6/9], Step [90/104], Loss: 0.0552\n",
      "Epoch [6/9], Step [100/104], Loss: 0.1027\n",
      "Epoch [7/9], Step [10/104], Loss: 0.0524\n",
      "Epoch [7/9], Step [20/104], Loss: 0.0471\n",
      "Epoch [7/9], Step [30/104], Loss: 0.0358\n",
      "Epoch [7/9], Step [40/104], Loss: 0.1103\n",
      "Epoch [7/9], Step [50/104], Loss: 0.1019\n",
      "Epoch [7/9], Step [60/104], Loss: 0.1051\n",
      "Epoch [7/9], Step [70/104], Loss: 0.1335\n",
      "Epoch [7/9], Step [80/104], Loss: 0.1360\n",
      "Epoch [7/9], Step [90/104], Loss: 0.0989\n",
      "Epoch [7/9], Step [100/104], Loss: 0.0961\n",
      "Epoch [8/9], Step [10/104], Loss: 0.0492\n",
      "Epoch [8/9], Step [20/104], Loss: 0.1678\n",
      "Epoch [8/9], Step [30/104], Loss: 0.0903\n",
      "Epoch [8/9], Step [40/104], Loss: 0.0620\n",
      "Epoch [8/9], Step [50/104], Loss: 0.0877\n",
      "Epoch [8/9], Step [60/104], Loss: 0.0624\n",
      "Epoch [8/9], Step [70/104], Loss: 0.0748\n",
      "Epoch [8/9], Step [80/104], Loss: 0.0616\n",
      "Epoch [8/9], Step [90/104], Loss: 0.1398\n",
      "Epoch [8/9], Step [100/104], Loss: 0.1247\n",
      "Epoch [9/9], Step [10/104], Loss: 0.0671\n",
      "Epoch [9/9], Step [20/104], Loss: 0.0649\n",
      "Epoch [9/9], Step [30/104], Loss: 0.2204\n",
      "Epoch [9/9], Step [40/104], Loss: 0.1499\n",
      "Epoch [9/9], Step [50/104], Loss: 0.0428\n",
      "Epoch [9/9], Step [60/104], Loss: 0.0618\n",
      "Epoch [9/9], Step [70/104], Loss: 0.0696\n",
      "Epoch [9/9], Step [80/104], Loss: 0.0712\n",
      "Epoch [9/9], Step [90/104], Loss: 0.0588\n",
      "Epoch [9/9], Step [100/104], Loss: 0.0557\n",
      "Epoch done:  10  Calculating accuracy\n",
      "Accuracy of the network: 96.66666666666667 %\n",
      "Accuracy of Normal: 94.56869009584665 %\n",
      "Accuracy of Tuberculosis: 98.95470383275261 %\n",
      "Epoch [1/10], Step [10/104], Loss: 0.6345\n",
      "Epoch [1/10], Step [20/104], Loss: 0.5657\n",
      "Epoch [1/10], Step [30/104], Loss: 0.4572\n",
      "Epoch [1/10], Step [40/104], Loss: 0.3906\n",
      "Epoch [1/10], Step [50/104], Loss: 0.3799\n",
      "Epoch [1/10], Step [60/104], Loss: 0.4007\n",
      "Epoch [1/10], Step [70/104], Loss: 0.3353\n",
      "Epoch [1/10], Step [80/104], Loss: 0.3549\n",
      "Epoch [1/10], Step [90/104], Loss: 0.2925\n",
      "Epoch [1/10], Step [100/104], Loss: 0.3586\n",
      "Epoch [2/10], Step [10/104], Loss: 0.2987\n",
      "Epoch [2/10], Step [20/104], Loss: 0.2670\n",
      "Epoch [2/10], Step [30/104], Loss: 0.3073\n",
      "Epoch [2/10], Step [40/104], Loss: 0.2246\n",
      "Epoch [2/10], Step [50/104], Loss: 0.1819\n",
      "Epoch [2/10], Step [60/104], Loss: 0.1890\n",
      "Epoch [2/10], Step [70/104], Loss: 0.2426\n",
      "Epoch [2/10], Step [80/104], Loss: 0.1401\n",
      "Epoch [2/10], Step [90/104], Loss: 0.4549\n",
      "Epoch [2/10], Step [100/104], Loss: 0.2454\n",
      "Epoch [3/10], Step [10/104], Loss: 0.1563\n",
      "Epoch [3/10], Step [20/104], Loss: 0.2489\n",
      "Epoch [3/10], Step [30/104], Loss: 0.1605\n",
      "Epoch [3/10], Step [40/104], Loss: 0.1625\n",
      "Epoch [3/10], Step [50/104], Loss: 0.1426\n",
      "Epoch [3/10], Step [60/104], Loss: 0.1951\n",
      "Epoch [3/10], Step [70/104], Loss: 0.0778\n",
      "Epoch [3/10], Step [80/104], Loss: 0.2012\n",
      "Epoch [3/10], Step [90/104], Loss: 0.1257\n",
      "Epoch [3/10], Step [100/104], Loss: 0.0823\n",
      "Epoch [4/10], Step [10/104], Loss: 0.3413\n",
      "Epoch [4/10], Step [20/104], Loss: 0.2941\n",
      "Epoch [4/10], Step [30/104], Loss: 0.1026\n",
      "Epoch [4/10], Step [40/104], Loss: 0.1738\n",
      "Epoch [4/10], Step [50/104], Loss: 0.1462\n",
      "Epoch [4/10], Step [60/104], Loss: 0.1227\n",
      "Epoch [4/10], Step [70/104], Loss: 0.1169\n",
      "Epoch [4/10], Step [80/104], Loss: 0.0707\n",
      "Epoch [4/10], Step [90/104], Loss: 0.1322\n",
      "Epoch [4/10], Step [100/104], Loss: 0.2083\n",
      "Epoch [5/10], Step [10/104], Loss: 0.1180\n",
      "Epoch [5/10], Step [20/104], Loss: 0.1793\n",
      "Epoch [5/10], Step [30/104], Loss: 0.1827\n",
      "Epoch [5/10], Step [40/104], Loss: 0.0525\n",
      "Epoch [5/10], Step [50/104], Loss: 0.0712\n",
      "Epoch [5/10], Step [60/104], Loss: 0.0957\n",
      "Epoch [5/10], Step [70/104], Loss: 0.1797\n",
      "Epoch [5/10], Step [80/104], Loss: 0.1292\n",
      "Epoch [5/10], Step [90/104], Loss: 0.0740\n",
      "Epoch [5/10], Step [100/104], Loss: 0.1697\n",
      "Epoch [6/10], Step [10/104], Loss: 0.3483\n",
      "Epoch [6/10], Step [20/104], Loss: 0.1258\n",
      "Epoch [6/10], Step [30/104], Loss: 0.1465\n",
      "Epoch [6/10], Step [40/104], Loss: 0.1224\n",
      "Epoch [6/10], Step [50/104], Loss: 0.0662\n",
      "Epoch [6/10], Step [60/104], Loss: 0.1062\n",
      "Epoch [6/10], Step [70/104], Loss: 0.0597\n",
      "Epoch [6/10], Step [80/104], Loss: 0.0604\n",
      "Epoch [6/10], Step [90/104], Loss: 0.0814\n",
      "Epoch [6/10], Step [100/104], Loss: 0.0853\n",
      "Epoch [7/10], Step [10/104], Loss: 0.0803\n",
      "Epoch [7/10], Step [20/104], Loss: 0.0728\n",
      "Epoch [7/10], Step [30/104], Loss: 0.1786\n",
      "Epoch [7/10], Step [40/104], Loss: 0.1408\n",
      "Epoch [7/10], Step [50/104], Loss: 0.1235\n",
      "Epoch [7/10], Step [60/104], Loss: 0.0805\n",
      "Epoch [7/10], Step [70/104], Loss: 0.0473\n",
      "Epoch [7/10], Step [80/104], Loss: 0.1051\n",
      "Epoch [7/10], Step [90/104], Loss: 0.0551\n",
      "Epoch [7/10], Step [100/104], Loss: 0.1569\n",
      "Epoch [8/10], Step [10/104], Loss: 0.0404\n",
      "Epoch [8/10], Step [20/104], Loss: 0.0515\n",
      "Epoch [8/10], Step [30/104], Loss: 0.0766\n",
      "Epoch [8/10], Step [40/104], Loss: 0.0475\n",
      "Epoch [8/10], Step [50/104], Loss: 0.0654\n",
      "Epoch [8/10], Step [60/104], Loss: 0.0566\n",
      "Epoch [8/10], Step [70/104], Loss: 0.0298\n",
      "Epoch [8/10], Step [80/104], Loss: 0.0852\n",
      "Epoch [8/10], Step [90/104], Loss: 0.1123\n",
      "Epoch [8/10], Step [100/104], Loss: 0.0676\n",
      "Epoch [9/10], Step [10/104], Loss: 0.0656\n",
      "Epoch [9/10], Step [20/104], Loss: 0.0770\n",
      "Epoch [9/10], Step [30/104], Loss: 0.0950\n",
      "Epoch [9/10], Step [40/104], Loss: 0.0386\n",
      "Epoch [9/10], Step [50/104], Loss: 0.0708\n",
      "Epoch [9/10], Step [60/104], Loss: 0.0516\n",
      "Epoch [9/10], Step [70/104], Loss: 0.0230\n",
      "Epoch [9/10], Step [80/104], Loss: 0.0977\n",
      "Epoch [9/10], Step [90/104], Loss: 0.1335\n",
      "Epoch [9/10], Step [100/104], Loss: 0.0579\n",
      "Epoch [10/10], Step [10/104], Loss: 0.0288\n",
      "Epoch [10/10], Step [20/104], Loss: 0.0522\n",
      "Epoch [10/10], Step [30/104], Loss: 0.0230\n",
      "Epoch [10/10], Step [40/104], Loss: 0.1208\n",
      "Epoch [10/10], Step [50/104], Loss: 0.0484\n",
      "Epoch [10/10], Step [60/104], Loss: 0.0455\n",
      "Epoch [10/10], Step [70/104], Loss: 0.0594\n",
      "Epoch [10/10], Step [80/104], Loss: 0.1020\n",
      "Epoch [10/10], Step [90/104], Loss: 0.2158\n",
      "Epoch [10/10], Step [100/104], Loss: 0.0729\n",
      "Epoch done:  11  Calculating accuracy\n",
      "Accuracy of the network: 98.33333333333333 %\n",
      "Accuracy of Normal: 98.67109634551495 %\n",
      "Accuracy of Tuberculosis: 97.9933110367893 %\n",
      "Epoch [1/11], Step [10/104], Loss: 0.6343\n",
      "Epoch [1/11], Step [20/104], Loss: 0.5690\n",
      "Epoch [1/11], Step [30/104], Loss: 0.5024\n",
      "Epoch [1/11], Step [40/104], Loss: 0.4377\n",
      "Epoch [1/11], Step [50/104], Loss: 0.3676\n",
      "Epoch [1/11], Step [60/104], Loss: 0.3216\n",
      "Epoch [1/11], Step [70/104], Loss: 0.3970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/11], Step [80/104], Loss: 0.3277\n",
      "Epoch [1/11], Step [90/104], Loss: 0.3142\n",
      "Epoch [1/11], Step [100/104], Loss: 0.1977\n",
      "Epoch [2/11], Step [10/104], Loss: 0.1948\n",
      "Epoch [2/11], Step [20/104], Loss: 0.2951\n",
      "Epoch [2/11], Step [30/104], Loss: 0.2702\n",
      "Epoch [2/11], Step [40/104], Loss: 0.2449\n",
      "Epoch [2/11], Step [50/104], Loss: 0.4054\n",
      "Epoch [2/11], Step [60/104], Loss: 0.2365\n",
      "Epoch [2/11], Step [70/104], Loss: 0.1144\n",
      "Epoch [2/11], Step [80/104], Loss: 0.2089\n",
      "Epoch [2/11], Step [90/104], Loss: 0.2323\n",
      "Epoch [2/11], Step [100/104], Loss: 0.1744\n",
      "Epoch [3/11], Step [10/104], Loss: 0.1862\n",
      "Epoch [3/11], Step [20/104], Loss: 0.1583\n",
      "Epoch [3/11], Step [30/104], Loss: 0.1454\n",
      "Epoch [3/11], Step [40/104], Loss: 0.1584\n",
      "Epoch [3/11], Step [50/104], Loss: 0.1149\n",
      "Epoch [3/11], Step [60/104], Loss: 0.1338\n",
      "Epoch [3/11], Step [70/104], Loss: 0.1940\n",
      "Epoch [3/11], Step [80/104], Loss: 0.1335\n",
      "Epoch [3/11], Step [90/104], Loss: 0.1458\n",
      "Epoch [3/11], Step [100/104], Loss: 0.1160\n",
      "Epoch [4/11], Step [10/104], Loss: 0.1637\n",
      "Epoch [4/11], Step [20/104], Loss: 0.0625\n",
      "Epoch [4/11], Step [30/104], Loss: 0.0451\n",
      "Epoch [4/11], Step [40/104], Loss: 0.2334\n",
      "Epoch [4/11], Step [50/104], Loss: 0.1572\n",
      "Epoch [4/11], Step [60/104], Loss: 0.1496\n",
      "Epoch [4/11], Step [70/104], Loss: 0.1676\n",
      "Epoch [4/11], Step [80/104], Loss: 0.0962\n",
      "Epoch [4/11], Step [90/104], Loss: 0.0854\n",
      "Epoch [4/11], Step [100/104], Loss: 0.1552\n",
      "Epoch [5/11], Step [10/104], Loss: 0.0862\n",
      "Epoch [5/11], Step [20/104], Loss: 0.0884\n",
      "Epoch [5/11], Step [30/104], Loss: 0.2055\n",
      "Epoch [5/11], Step [40/104], Loss: 0.2743\n",
      "Epoch [5/11], Step [50/104], Loss: 0.1403\n",
      "Epoch [5/11], Step [60/104], Loss: 0.0565\n",
      "Epoch [5/11], Step [70/104], Loss: 0.0680\n",
      "Epoch [5/11], Step [80/104], Loss: 0.1095\n",
      "Epoch [5/11], Step [90/104], Loss: 0.1524\n",
      "Epoch [5/11], Step [100/104], Loss: 0.0342\n",
      "Epoch [6/11], Step [10/104], Loss: 0.2073\n",
      "Epoch [6/11], Step [20/104], Loss: 0.1435\n",
      "Epoch [6/11], Step [30/104], Loss: 0.0584\n",
      "Epoch [6/11], Step [40/104], Loss: 0.0736\n",
      "Epoch [6/11], Step [50/104], Loss: 0.1546\n",
      "Epoch [6/11], Step [60/104], Loss: 0.0939\n",
      "Epoch [6/11], Step [70/104], Loss: 0.0419\n",
      "Epoch [6/11], Step [80/104], Loss: 0.0796\n",
      "Epoch [6/11], Step [90/104], Loss: 0.0979\n",
      "Epoch [6/11], Step [100/104], Loss: 0.0494\n",
      "Epoch [7/11], Step [10/104], Loss: 0.0535\n",
      "Epoch [7/11], Step [20/104], Loss: 0.0519\n",
      "Epoch [7/11], Step [30/104], Loss: 0.1187\n",
      "Epoch [7/11], Step [40/104], Loss: 0.0802\n",
      "Epoch [7/11], Step [50/104], Loss: 0.0851\n",
      "Epoch [7/11], Step [60/104], Loss: 0.0461\n",
      "Epoch [7/11], Step [70/104], Loss: 0.0682\n",
      "Epoch [7/11], Step [80/104], Loss: 0.2101\n",
      "Epoch [7/11], Step [90/104], Loss: 0.0356\n",
      "Epoch [7/11], Step [100/104], Loss: 0.0519\n",
      "Epoch [8/11], Step [10/104], Loss: 0.1049\n",
      "Epoch [8/11], Step [20/104], Loss: 0.0466\n",
      "Epoch [8/11], Step [30/104], Loss: 0.0211\n",
      "Epoch [8/11], Step [40/104], Loss: 0.0486\n",
      "Epoch [8/11], Step [50/104], Loss: 0.1493\n",
      "Epoch [8/11], Step [60/104], Loss: 0.0911\n",
      "Epoch [8/11], Step [70/104], Loss: 0.1234\n",
      "Epoch [8/11], Step [80/104], Loss: 0.0492\n",
      "Epoch [8/11], Step [90/104], Loss: 0.0325\n",
      "Epoch [8/11], Step [100/104], Loss: 0.0561\n",
      "Epoch [9/11], Step [10/104], Loss: 0.1642\n",
      "Epoch [9/11], Step [20/104], Loss: 0.0707\n",
      "Epoch [9/11], Step [30/104], Loss: 0.0726\n",
      "Epoch [9/11], Step [40/104], Loss: 0.0917\n",
      "Epoch [9/11], Step [50/104], Loss: 0.0402\n",
      "Epoch [9/11], Step [60/104], Loss: 0.0466\n",
      "Epoch [9/11], Step [70/104], Loss: 0.0277\n",
      "Epoch [9/11], Step [80/104], Loss: 0.0774\n",
      "Epoch [9/11], Step [90/104], Loss: 0.0415\n",
      "Epoch [9/11], Step [100/104], Loss: 0.0923\n",
      "Epoch [10/11], Step [10/104], Loss: 0.0496\n",
      "Epoch [10/11], Step [20/104], Loss: 0.0391\n",
      "Epoch [10/11], Step [30/104], Loss: 0.0352\n",
      "Epoch [10/11], Step [40/104], Loss: 0.0886\n",
      "Epoch [10/11], Step [50/104], Loss: 0.1217\n",
      "Epoch [10/11], Step [60/104], Loss: 0.0679\n",
      "Epoch [10/11], Step [70/104], Loss: 0.0232\n",
      "Epoch [10/11], Step [80/104], Loss: 0.0326\n",
      "Epoch [10/11], Step [90/104], Loss: 0.0256\n",
      "Epoch [10/11], Step [100/104], Loss: 0.0205\n",
      "Epoch [11/11], Step [10/104], Loss: 0.0339\n",
      "Epoch [11/11], Step [20/104], Loss: 0.0444\n",
      "Epoch [11/11], Step [30/104], Loss: 0.0479\n",
      "Epoch [11/11], Step [40/104], Loss: 0.0652\n",
      "Epoch [11/11], Step [50/104], Loss: 0.0304\n",
      "Epoch [11/11], Step [60/104], Loss: 0.0444\n",
      "Epoch [11/11], Step [70/104], Loss: 0.0192\n",
      "Epoch [11/11], Step [80/104], Loss: 0.0362\n",
      "Epoch [11/11], Step [90/104], Loss: 0.0808\n",
      "Epoch [11/11], Step [100/104], Loss: 0.0481\n",
      "Epoch done:  12  Calculating accuracy\n",
      "Accuracy of the network: 97.33333333333333 %\n",
      "Accuracy of Normal: 99.07692307692308 %\n",
      "Accuracy of Tuberculosis: 95.27272727272727 %\n",
      "Epoch [1/12], Step [10/104], Loss: 0.6369\n",
      "Epoch [1/12], Step [20/104], Loss: 0.5992\n",
      "Epoch [1/12], Step [30/104], Loss: 0.5682\n",
      "Epoch [1/12], Step [40/104], Loss: 0.4729\n",
      "Epoch [1/12], Step [50/104], Loss: 0.4311\n",
      "Epoch [1/12], Step [60/104], Loss: 0.3779\n",
      "Epoch [1/12], Step [70/104], Loss: 0.4313\n",
      "Epoch [1/12], Step [80/104], Loss: 0.3600\n",
      "Epoch [1/12], Step [90/104], Loss: 0.3508\n",
      "Epoch [1/12], Step [100/104], Loss: 0.2873\n",
      "Epoch [2/12], Step [10/104], Loss: 0.2644\n",
      "Epoch [2/12], Step [20/104], Loss: 0.3200\n",
      "Epoch [2/12], Step [30/104], Loss: 0.2641\n",
      "Epoch [2/12], Step [40/104], Loss: 0.2533\n",
      "Epoch [2/12], Step [50/104], Loss: 0.2751\n",
      "Epoch [2/12], Step [60/104], Loss: 0.2928\n",
      "Epoch [2/12], Step [70/104], Loss: 0.3564\n",
      "Epoch [2/12], Step [80/104], Loss: 0.2988\n",
      "Epoch [2/12], Step [90/104], Loss: 0.1621\n",
      "Epoch [2/12], Step [100/104], Loss: 0.2317\n",
      "Epoch [3/12], Step [10/104], Loss: 0.1470\n",
      "Epoch [3/12], Step [20/104], Loss: 0.2240\n",
      "Epoch [3/12], Step [30/104], Loss: 0.2103\n",
      "Epoch [3/12], Step [40/104], Loss: 0.2453\n",
      "Epoch [3/12], Step [50/104], Loss: 0.1362\n",
      "Epoch [3/12], Step [60/104], Loss: 0.1676\n",
      "Epoch [3/12], Step [70/104], Loss: 0.1303\n",
      "Epoch [3/12], Step [80/104], Loss: 0.1348\n",
      "Epoch [3/12], Step [90/104], Loss: 0.1403\n",
      "Epoch [3/12], Step [100/104], Loss: 0.2920\n",
      "Epoch [4/12], Step [10/104], Loss: 0.1612\n",
      "Epoch [4/12], Step [20/104], Loss: 0.1390\n",
      "Epoch [4/12], Step [30/104], Loss: 0.1636\n",
      "Epoch [4/12], Step [40/104], Loss: 0.0864\n",
      "Epoch [4/12], Step [50/104], Loss: 0.1612\n",
      "Epoch [4/12], Step [60/104], Loss: 0.3204\n",
      "Epoch [4/12], Step [70/104], Loss: 0.2024\n",
      "Epoch [4/12], Step [80/104], Loss: 0.0962\n",
      "Epoch [4/12], Step [90/104], Loss: 0.1394\n",
      "Epoch [4/12], Step [100/104], Loss: 0.1006\n",
      "Epoch [5/12], Step [10/104], Loss: 0.1516\n",
      "Epoch [5/12], Step [20/104], Loss: 0.0859\n",
      "Epoch [5/12], Step [30/104], Loss: 0.1315\n",
      "Epoch [5/12], Step [40/104], Loss: 0.0868\n",
      "Epoch [5/12], Step [50/104], Loss: 0.1399\n",
      "Epoch [5/12], Step [60/104], Loss: 0.1006\n",
      "Epoch [5/12], Step [70/104], Loss: 0.3788\n",
      "Epoch [5/12], Step [80/104], Loss: 0.1831\n",
      "Epoch [5/12], Step [90/104], Loss: 0.1631\n",
      "Epoch [5/12], Step [100/104], Loss: 0.1588\n",
      "Epoch [6/12], Step [10/104], Loss: 0.1558\n",
      "Epoch [6/12], Step [20/104], Loss: 0.1048\n",
      "Epoch [6/12], Step [30/104], Loss: 0.1064\n",
      "Epoch [6/12], Step [40/104], Loss: 0.1379\n",
      "Epoch [6/12], Step [50/104], Loss: 0.2921\n",
      "Epoch [6/12], Step [60/104], Loss: 0.0803\n",
      "Epoch [6/12], Step [70/104], Loss: 0.1129\n",
      "Epoch [6/12], Step [80/104], Loss: 0.1219\n",
      "Epoch [6/12], Step [90/104], Loss: 0.1261\n",
      "Epoch [6/12], Step [100/104], Loss: 0.1491\n",
      "Epoch [7/12], Step [10/104], Loss: 0.2357\n",
      "Epoch [7/12], Step [20/104], Loss: 0.1195\n",
      "Epoch [7/12], Step [30/104], Loss: 0.1207\n",
      "Epoch [7/12], Step [40/104], Loss: 0.0686\n",
      "Epoch [7/12], Step [50/104], Loss: 0.0828\n",
      "Epoch [7/12], Step [60/104], Loss: 0.1013\n",
      "Epoch [7/12], Step [70/104], Loss: 0.0500\n",
      "Epoch [7/12], Step [80/104], Loss: 0.0513\n",
      "Epoch [7/12], Step [90/104], Loss: 0.0911\n",
      "Epoch [7/12], Step [100/104], Loss: 0.0866\n",
      "Epoch [8/12], Step [10/104], Loss: 0.1262\n",
      "Epoch [8/12], Step [20/104], Loss: 0.1009\n",
      "Epoch [8/12], Step [30/104], Loss: 0.0970\n",
      "Epoch [8/12], Step [40/104], Loss: 0.1222\n",
      "Epoch [8/12], Step [50/104], Loss: 0.0657\n",
      "Epoch [8/12], Step [60/104], Loss: 0.1224\n",
      "Epoch [8/12], Step [70/104], Loss: 0.1460\n",
      "Epoch [8/12], Step [80/104], Loss: 0.0621\n",
      "Epoch [8/12], Step [90/104], Loss: 0.0697\n",
      "Epoch [8/12], Step [100/104], Loss: 0.0455\n",
      "Epoch [9/12], Step [10/104], Loss: 0.1526\n",
      "Epoch [9/12], Step [20/104], Loss: 0.0779\n",
      "Epoch [9/12], Step [30/104], Loss: 0.0965\n",
      "Epoch [9/12], Step [40/104], Loss: 0.0464\n",
      "Epoch [9/12], Step [50/104], Loss: 0.0558\n",
      "Epoch [9/12], Step [60/104], Loss: 0.0372\n",
      "Epoch [9/12], Step [70/104], Loss: 0.0879\n",
      "Epoch [9/12], Step [80/104], Loss: 0.0794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/12], Step [90/104], Loss: 0.0538\n",
      "Epoch [9/12], Step [100/104], Loss: 0.0583\n",
      "Epoch [10/12], Step [10/104], Loss: 0.0410\n",
      "Epoch [10/12], Step [20/104], Loss: 0.0620\n",
      "Epoch [10/12], Step [30/104], Loss: 0.0801\n",
      "Epoch [10/12], Step [40/104], Loss: 0.0762\n",
      "Epoch [10/12], Step [50/104], Loss: 0.0990\n",
      "Epoch [10/12], Step [60/104], Loss: 0.0478\n",
      "Epoch [10/12], Step [70/104], Loss: 0.0561\n",
      "Epoch [10/12], Step [80/104], Loss: 0.0203\n",
      "Epoch [10/12], Step [90/104], Loss: 0.1108\n",
      "Epoch [10/12], Step [100/104], Loss: 0.0616\n",
      "Epoch [11/12], Step [10/104], Loss: 0.0725\n",
      "Epoch [11/12], Step [20/104], Loss: 0.1335\n",
      "Epoch [11/12], Step [30/104], Loss: 0.0287\n",
      "Epoch [11/12], Step [40/104], Loss: 0.0450\n",
      "Epoch [11/12], Step [50/104], Loss: 0.0533\n",
      "Epoch [11/12], Step [60/104], Loss: 0.0538\n",
      "Epoch [11/12], Step [70/104], Loss: 0.0513\n",
      "Epoch [11/12], Step [80/104], Loss: 0.0778\n",
      "Epoch [11/12], Step [90/104], Loss: 0.0396\n",
      "Epoch [11/12], Step [100/104], Loss: 0.0752\n",
      "Epoch [12/12], Step [10/104], Loss: 0.0562\n",
      "Epoch [12/12], Step [20/104], Loss: 0.0323\n",
      "Epoch [12/12], Step [30/104], Loss: 0.0648\n",
      "Epoch [12/12], Step [40/104], Loss: 0.0563\n",
      "Epoch [12/12], Step [50/104], Loss: 0.0321\n",
      "Epoch [12/12], Step [60/104], Loss: 0.0128\n",
      "Epoch [12/12], Step [70/104], Loss: 0.0831\n",
      "Epoch [12/12], Step [80/104], Loss: 0.0206\n",
      "Epoch [12/12], Step [90/104], Loss: 0.1080\n",
      "Epoch [12/12], Step [100/104], Loss: 0.0175\n",
      "Epoch done:  13  Calculating accuracy\n",
      "Accuracy of the network: 98.0 %\n",
      "Accuracy of Normal: 96.6789667896679 %\n",
      "Accuracy of Tuberculosis: 99.08814589665654 %\n",
      "Epoch [1/13], Step [10/104], Loss: 0.6397\n",
      "Epoch [1/13], Step [20/104], Loss: 0.5365\n",
      "Epoch [1/13], Step [30/104], Loss: 0.5239\n",
      "Epoch [1/13], Step [40/104], Loss: 0.4688\n",
      "Epoch [1/13], Step [50/104], Loss: 0.4872\n",
      "Epoch [1/13], Step [60/104], Loss: 0.4587\n",
      "Epoch [1/13], Step [70/104], Loss: 0.4419\n",
      "Epoch [1/13], Step [80/104], Loss: 0.3568\n",
      "Epoch [1/13], Step [90/104], Loss: 0.3772\n",
      "Epoch [1/13], Step [100/104], Loss: 0.3042\n",
      "Epoch [2/13], Step [10/104], Loss: 0.2314\n",
      "Epoch [2/13], Step [20/104], Loss: 0.3155\n",
      "Epoch [2/13], Step [30/104], Loss: 0.3193\n",
      "Epoch [2/13], Step [40/104], Loss: 0.2480\n",
      "Epoch [2/13], Step [50/104], Loss: 0.3637\n",
      "Epoch [2/13], Step [60/104], Loss: 0.4091\n",
      "Epoch [2/13], Step [70/104], Loss: 0.2873\n",
      "Epoch [2/13], Step [80/104], Loss: 0.2523\n",
      "Epoch [2/13], Step [90/104], Loss: 0.2422\n",
      "Epoch [2/13], Step [100/104], Loss: 0.2029\n",
      "Epoch [3/13], Step [10/104], Loss: 0.2104\n",
      "Epoch [3/13], Step [20/104], Loss: 0.1556\n",
      "Epoch [3/13], Step [30/104], Loss: 0.1527\n",
      "Epoch [3/13], Step [40/104], Loss: 0.4942\n",
      "Epoch [3/13], Step [50/104], Loss: 0.1788\n",
      "Epoch [3/13], Step [60/104], Loss: 0.1482\n",
      "Epoch [3/13], Step [70/104], Loss: 0.2323\n",
      "Epoch [3/13], Step [80/104], Loss: 0.2783\n",
      "Epoch [3/13], Step [90/104], Loss: 0.2506\n",
      "Epoch [3/13], Step [100/104], Loss: 0.1745\n",
      "Epoch [4/13], Step [10/104], Loss: 0.2990\n",
      "Epoch [4/13], Step [20/104], Loss: 0.0937\n",
      "Epoch [4/13], Step [30/104], Loss: 0.3233\n",
      "Epoch [4/13], Step [40/104], Loss: 0.1960\n",
      "Epoch [4/13], Step [50/104], Loss: 0.1949\n",
      "Epoch [4/13], Step [60/104], Loss: 0.1848\n",
      "Epoch [4/13], Step [70/104], Loss: 0.2225\n",
      "Epoch [4/13], Step [80/104], Loss: 0.1257\n",
      "Epoch [4/13], Step [90/104], Loss: 0.1933\n",
      "Epoch [4/13], Step [100/104], Loss: 0.2168\n",
      "Epoch [5/13], Step [10/104], Loss: 0.0842\n",
      "Epoch [5/13], Step [20/104], Loss: 0.2255\n",
      "Epoch [5/13], Step [30/104], Loss: 0.2218\n",
      "Epoch [5/13], Step [40/104], Loss: 0.1607\n",
      "Epoch [5/13], Step [50/104], Loss: 0.1654\n",
      "Epoch [5/13], Step [60/104], Loss: 0.2016\n",
      "Epoch [5/13], Step [70/104], Loss: 0.1776\n",
      "Epoch [5/13], Step [80/104], Loss: 0.1124\n",
      "Epoch [5/13], Step [90/104], Loss: 0.0564\n",
      "Epoch [5/13], Step [100/104], Loss: 0.2111\n",
      "Epoch [6/13], Step [10/104], Loss: 0.1855\n",
      "Epoch [6/13], Step [20/104], Loss: 0.0980\n",
      "Epoch [6/13], Step [30/104], Loss: 0.2346\n",
      "Epoch [6/13], Step [40/104], Loss: 0.1588\n",
      "Epoch [6/13], Step [50/104], Loss: 0.0904\n",
      "Epoch [6/13], Step [60/104], Loss: 0.0853\n",
      "Epoch [6/13], Step [70/104], Loss: 0.1207\n",
      "Epoch [6/13], Step [80/104], Loss: 0.1169\n",
      "Epoch [6/13], Step [90/104], Loss: 0.1500\n",
      "Epoch [6/13], Step [100/104], Loss: 0.0399\n",
      "Epoch [7/13], Step [10/104], Loss: 0.1011\n",
      "Epoch [7/13], Step [20/104], Loss: 0.1315\n",
      "Epoch [7/13], Step [30/104], Loss: 0.0523\n",
      "Epoch [7/13], Step [40/104], Loss: 0.1387\n",
      "Epoch [7/13], Step [50/104], Loss: 0.1750\n",
      "Epoch [7/13], Step [60/104], Loss: 0.1200\n",
      "Epoch [7/13], Step [70/104], Loss: 0.0431\n",
      "Epoch [7/13], Step [80/104], Loss: 0.0864\n",
      "Epoch [7/13], Step [90/104], Loss: 0.1117\n",
      "Epoch [7/13], Step [100/104], Loss: 0.0951\n",
      "Epoch [8/13], Step [10/104], Loss: 0.1399\n",
      "Epoch [8/13], Step [20/104], Loss: 0.0767\n",
      "Epoch [8/13], Step [30/104], Loss: 0.1198\n",
      "Epoch [8/13], Step [40/104], Loss: 0.1384\n",
      "Epoch [8/13], Step [50/104], Loss: 0.1175\n",
      "Epoch [8/13], Step [60/104], Loss: 0.1331\n",
      "Epoch [8/13], Step [70/104], Loss: 0.1730\n",
      "Epoch [8/13], Step [80/104], Loss: 0.0711\n",
      "Epoch [8/13], Step [90/104], Loss: 0.0525\n",
      "Epoch [8/13], Step [100/104], Loss: 0.0649\n",
      "Epoch [9/13], Step [10/104], Loss: 0.0837\n",
      "Epoch [9/13], Step [20/104], Loss: 0.1248\n",
      "Epoch [9/13], Step [30/104], Loss: 0.1017\n",
      "Epoch [9/13], Step [40/104], Loss: 0.1069\n",
      "Epoch [9/13], Step [50/104], Loss: 0.0327\n",
      "Epoch [9/13], Step [60/104], Loss: 0.0710\n",
      "Epoch [9/13], Step [70/104], Loss: 0.1014\n",
      "Epoch [9/13], Step [80/104], Loss: 0.0300\n",
      "Epoch [9/13], Step [90/104], Loss: 0.1169\n",
      "Epoch [9/13], Step [100/104], Loss: 0.0640\n",
      "Epoch [10/13], Step [10/104], Loss: 0.0519\n",
      "Epoch [10/13], Step [20/104], Loss: 0.1162\n",
      "Epoch [10/13], Step [30/104], Loss: 0.0291\n",
      "Epoch [10/13], Step [40/104], Loss: 0.0948\n",
      "Epoch [10/13], Step [50/104], Loss: 0.0700\n",
      "Epoch [10/13], Step [60/104], Loss: 0.1281\n",
      "Epoch [10/13], Step [70/104], Loss: 0.1006\n",
      "Epoch [10/13], Step [80/104], Loss: 0.1198\n",
      "Epoch [10/13], Step [90/104], Loss: 0.0785\n",
      "Epoch [10/13], Step [100/104], Loss: 0.0769\n",
      "Epoch [11/13], Step [10/104], Loss: 0.0731\n",
      "Epoch [11/13], Step [20/104], Loss: 0.0676\n",
      "Epoch [11/13], Step [30/104], Loss: 0.0760\n",
      "Epoch [11/13], Step [40/104], Loss: 0.0322\n",
      "Epoch [11/13], Step [50/104], Loss: 0.1432\n",
      "Epoch [11/13], Step [60/104], Loss: 0.0866\n",
      "Epoch [11/13], Step [70/104], Loss: 0.0239\n",
      "Epoch [11/13], Step [80/104], Loss: 0.0418\n",
      "Epoch [11/13], Step [90/104], Loss: 0.0413\n",
      "Epoch [11/13], Step [100/104], Loss: 0.0836\n",
      "Epoch [12/13], Step [10/104], Loss: 0.0211\n",
      "Epoch [12/13], Step [20/104], Loss: 0.1127\n",
      "Epoch [12/13], Step [30/104], Loss: 0.0694\n",
      "Epoch [12/13], Step [40/104], Loss: 0.0731\n",
      "Epoch [12/13], Step [50/104], Loss: 0.0717\n",
      "Epoch [12/13], Step [60/104], Loss: 0.0752\n",
      "Epoch [12/13], Step [70/104], Loss: 0.0336\n",
      "Epoch [12/13], Step [80/104], Loss: 0.0212\n",
      "Epoch [12/13], Step [90/104], Loss: 0.0637\n",
      "Epoch [12/13], Step [100/104], Loss: 0.0357\n",
      "Epoch [13/13], Step [10/104], Loss: 0.0465\n",
      "Epoch [13/13], Step [20/104], Loss: 0.0488\n",
      "Epoch [13/13], Step [30/104], Loss: 0.0759\n",
      "Epoch [13/13], Step [40/104], Loss: 0.0393\n",
      "Epoch [13/13], Step [50/104], Loss: 0.0201\n",
      "Epoch [13/13], Step [60/104], Loss: 0.0161\n",
      "Epoch [13/13], Step [70/104], Loss: 0.0890\n",
      "Epoch [13/13], Step [80/104], Loss: 0.0332\n",
      "Epoch [13/13], Step [90/104], Loss: 0.1517\n",
      "Epoch [13/13], Step [100/104], Loss: 0.0217\n",
      "Epoch done:  14  Calculating accuracy\n",
      "Accuracy of the network: 98.0 %\n",
      "Accuracy of Normal: 98.68852459016394 %\n",
      "Accuracy of Tuberculosis: 97.28813559322033 %\n",
      "Epoch [1/14], Step [10/104], Loss: 0.6212\n",
      "Epoch [1/14], Step [20/104], Loss: 0.5461\n",
      "Epoch [1/14], Step [30/104], Loss: 0.4710\n",
      "Epoch [1/14], Step [40/104], Loss: 0.4236\n",
      "Epoch [1/14], Step [50/104], Loss: 0.3934\n",
      "Epoch [1/14], Step [60/104], Loss: 0.2995\n",
      "Epoch [1/14], Step [70/104], Loss: 0.4148\n",
      "Epoch [1/14], Step [80/104], Loss: 0.3460\n",
      "Epoch [1/14], Step [90/104], Loss: 0.3711\n",
      "Epoch [1/14], Step [100/104], Loss: 0.3095\n",
      "Epoch [2/14], Step [10/104], Loss: 0.3543\n",
      "Epoch [2/14], Step [20/104], Loss: 0.2935\n",
      "Epoch [2/14], Step [30/104], Loss: 0.2636\n",
      "Epoch [2/14], Step [40/104], Loss: 0.2244\n",
      "Epoch [2/14], Step [50/104], Loss: 0.3927\n",
      "Epoch [2/14], Step [60/104], Loss: 0.1285\n",
      "Epoch [2/14], Step [70/104], Loss: 0.2205\n",
      "Epoch [2/14], Step [80/104], Loss: 0.2153\n",
      "Epoch [2/14], Step [90/104], Loss: 0.1997\n",
      "Epoch [2/14], Step [100/104], Loss: 0.2928\n",
      "Epoch [3/14], Step [10/104], Loss: 0.3178\n",
      "Epoch [3/14], Step [20/104], Loss: 0.1142\n",
      "Epoch [3/14], Step [30/104], Loss: 0.1487\n",
      "Epoch [3/14], Step [40/104], Loss: 0.1630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/14], Step [50/104], Loss: 0.1510\n",
      "Epoch [3/14], Step [60/104], Loss: 0.0947\n",
      "Epoch [3/14], Step [70/104], Loss: 0.2016\n",
      "Epoch [3/14], Step [80/104], Loss: 0.1428\n",
      "Epoch [3/14], Step [90/104], Loss: 0.1881\n",
      "Epoch [3/14], Step [100/104], Loss: 0.1994\n",
      "Epoch [4/14], Step [10/104], Loss: 0.2083\n",
      "Epoch [4/14], Step [20/104], Loss: 0.1807\n",
      "Epoch [4/14], Step [30/104], Loss: 0.1880\n",
      "Epoch [4/14], Step [40/104], Loss: 0.2902\n",
      "Epoch [4/14], Step [50/104], Loss: 0.2329\n",
      "Epoch [4/14], Step [60/104], Loss: 0.1382\n",
      "Epoch [4/14], Step [70/104], Loss: 0.1908\n",
      "Epoch [4/14], Step [80/104], Loss: 0.1542\n",
      "Epoch [4/14], Step [90/104], Loss: 0.1896\n",
      "Epoch [4/14], Step [100/104], Loss: 0.1797\n",
      "Epoch [5/14], Step [10/104], Loss: 0.0998\n",
      "Epoch [5/14], Step [20/104], Loss: 0.2584\n",
      "Epoch [5/14], Step [30/104], Loss: 0.1588\n",
      "Epoch [5/14], Step [40/104], Loss: 0.1014\n",
      "Epoch [5/14], Step [50/104], Loss: 0.0911\n",
      "Epoch [5/14], Step [60/104], Loss: 0.1486\n",
      "Epoch [5/14], Step [70/104], Loss: 0.1715\n",
      "Epoch [5/14], Step [80/104], Loss: 0.0867\n",
      "Epoch [5/14], Step [90/104], Loss: 0.0883\n",
      "Epoch [5/14], Step [100/104], Loss: 0.1204\n",
      "Epoch [6/14], Step [10/104], Loss: 0.1699\n",
      "Epoch [6/14], Step [20/104], Loss: 0.0719\n",
      "Epoch [6/14], Step [30/104], Loss: 0.0526\n",
      "Epoch [6/14], Step [40/104], Loss: 0.0634\n",
      "Epoch [6/14], Step [50/104], Loss: 0.1889\n",
      "Epoch [6/14], Step [60/104], Loss: 0.0958\n",
      "Epoch [6/14], Step [70/104], Loss: 0.0353\n",
      "Epoch [6/14], Step [80/104], Loss: 0.1367\n",
      "Epoch [6/14], Step [90/104], Loss: 0.1549\n",
      "Epoch [6/14], Step [100/104], Loss: 0.1616\n",
      "Epoch [7/14], Step [10/104], Loss: 0.0877\n",
      "Epoch [7/14], Step [20/104], Loss: 0.3136\n",
      "Epoch [7/14], Step [30/104], Loss: 0.1407\n",
      "Epoch [7/14], Step [40/104], Loss: 0.0995\n",
      "Epoch [7/14], Step [50/104], Loss: 0.0548\n",
      "Epoch [7/14], Step [60/104], Loss: 0.0689\n",
      "Epoch [7/14], Step [70/104], Loss: 0.0828\n",
      "Epoch [7/14], Step [80/104], Loss: 0.0406\n",
      "Epoch [7/14], Step [90/104], Loss: 0.0813\n",
      "Epoch [7/14], Step [100/104], Loss: 0.1103\n",
      "Epoch [8/14], Step [10/104], Loss: 0.1916\n",
      "Epoch [8/14], Step [20/104], Loss: 0.0523\n",
      "Epoch [8/14], Step [30/104], Loss: 0.1003\n",
      "Epoch [8/14], Step [40/104], Loss: 0.1156\n",
      "Epoch [8/14], Step [50/104], Loss: 0.0552\n",
      "Epoch [8/14], Step [60/104], Loss: 0.0685\n",
      "Epoch [8/14], Step [70/104], Loss: 0.1235\n",
      "Epoch [8/14], Step [80/104], Loss: 0.1317\n",
      "Epoch [8/14], Step [90/104], Loss: 0.0487\n",
      "Epoch [8/14], Step [100/104], Loss: 0.0524\n",
      "Epoch [9/14], Step [10/104], Loss: 0.0563\n",
      "Epoch [9/14], Step [20/104], Loss: 0.0559\n",
      "Epoch [9/14], Step [30/104], Loss: 0.0862\n",
      "Epoch [9/14], Step [40/104], Loss: 0.0805\n",
      "Epoch [9/14], Step [50/104], Loss: 0.1309\n",
      "Epoch [9/14], Step [60/104], Loss: 0.0988\n",
      "Epoch [9/14], Step [70/104], Loss: 0.0523\n",
      "Epoch [9/14], Step [80/104], Loss: 0.2458\n",
      "Epoch [9/14], Step [90/104], Loss: 0.1252\n",
      "Epoch [9/14], Step [100/104], Loss: 0.0914\n",
      "Epoch [10/14], Step [10/104], Loss: 0.1050\n",
      "Epoch [10/14], Step [20/104], Loss: 0.0429\n",
      "Epoch [10/14], Step [30/104], Loss: 0.0536\n",
      "Epoch [10/14], Step [40/104], Loss: 0.1231\n",
      "Epoch [10/14], Step [50/104], Loss: 0.0367\n",
      "Epoch [10/14], Step [60/104], Loss: 0.0502\n",
      "Epoch [10/14], Step [70/104], Loss: 0.1003\n",
      "Epoch [10/14], Step [80/104], Loss: 0.0350\n",
      "Epoch [10/14], Step [90/104], Loss: 0.0768\n",
      "Epoch [10/14], Step [100/104], Loss: 0.0588\n",
      "Epoch [11/14], Step [10/104], Loss: 0.0133\n",
      "Epoch [11/14], Step [20/104], Loss: 0.1245\n",
      "Epoch [11/14], Step [30/104], Loss: 0.0461\n",
      "Epoch [11/14], Step [40/104], Loss: 0.0331\n",
      "Epoch [11/14], Step [50/104], Loss: 0.0316\n",
      "Epoch [11/14], Step [60/104], Loss: 0.1542\n",
      "Epoch [11/14], Step [70/104], Loss: 0.0465\n",
      "Epoch [11/14], Step [80/104], Loss: 0.0620\n",
      "Epoch [11/14], Step [90/104], Loss: 0.0493\n",
      "Epoch [11/14], Step [100/104], Loss: 0.1119\n",
      "Epoch [12/14], Step [10/104], Loss: 0.0563\n",
      "Epoch [12/14], Step [20/104], Loss: 0.0692\n",
      "Epoch [12/14], Step [30/104], Loss: 0.1830\n",
      "Epoch [12/14], Step [40/104], Loss: 0.0294\n",
      "Epoch [12/14], Step [50/104], Loss: 0.0356\n",
      "Epoch [12/14], Step [60/104], Loss: 0.0498\n",
      "Epoch [12/14], Step [70/104], Loss: 0.0415\n",
      "Epoch [12/14], Step [80/104], Loss: 0.0410\n",
      "Epoch [12/14], Step [90/104], Loss: 0.1177\n",
      "Epoch [12/14], Step [100/104], Loss: 0.0614\n",
      "Epoch [13/14], Step [10/104], Loss: 0.0699\n",
      "Epoch [13/14], Step [20/104], Loss: 0.0420\n",
      "Epoch [13/14], Step [30/104], Loss: 0.0197\n",
      "Epoch [13/14], Step [40/104], Loss: 0.0841\n",
      "Epoch [13/14], Step [50/104], Loss: 0.0478\n",
      "Epoch [13/14], Step [60/104], Loss: 0.0647\n",
      "Epoch [13/14], Step [70/104], Loss: 0.1138\n",
      "Epoch [13/14], Step [80/104], Loss: 0.0288\n",
      "Epoch [13/14], Step [90/104], Loss: 0.0195\n",
      "Epoch [13/14], Step [100/104], Loss: 0.0304\n",
      "Epoch [14/14], Step [10/104], Loss: 0.1184\n",
      "Epoch [14/14], Step [20/104], Loss: 0.0468\n",
      "Epoch [14/14], Step [30/104], Loss: 0.0255\n",
      "Epoch [14/14], Step [40/104], Loss: 0.0567\n",
      "Epoch [14/14], Step [50/104], Loss: 0.0392\n",
      "Epoch [14/14], Step [60/104], Loss: 0.1274\n",
      "Epoch [14/14], Step [70/104], Loss: 0.0784\n",
      "Epoch [14/14], Step [80/104], Loss: 0.0659\n",
      "Epoch [14/14], Step [90/104], Loss: 0.1184\n",
      "Epoch [14/14], Step [100/104], Loss: 0.0996\n",
      "Epoch done:  15  Calculating accuracy\n",
      "Accuracy of the network: 97.5 %\n",
      "Accuracy of Normal: 96.72131147540983 %\n",
      "Accuracy of Tuberculosis: 98.30508474576271 %\n",
      "Epoch [1/15], Step [10/104], Loss: 0.6072\n",
      "Epoch [1/15], Step [20/104], Loss: 0.5648\n",
      "Epoch [1/15], Step [30/104], Loss: 0.4704\n",
      "Epoch [1/15], Step [40/104], Loss: 0.3969\n",
      "Epoch [1/15], Step [50/104], Loss: 0.5025\n",
      "Epoch [1/15], Step [60/104], Loss: 0.4524\n",
      "Epoch [1/15], Step [70/104], Loss: 0.3290\n",
      "Epoch [1/15], Step [80/104], Loss: 0.2656\n",
      "Epoch [1/15], Step [90/104], Loss: 0.5766\n",
      "Epoch [1/15], Step [100/104], Loss: 0.2400\n",
      "Epoch [2/15], Step [10/104], Loss: 0.2966\n",
      "Epoch [2/15], Step [20/104], Loss: 0.2810\n",
      "Epoch [2/15], Step [30/104], Loss: 0.2913\n",
      "Epoch [2/15], Step [40/104], Loss: 0.2546\n",
      "Epoch [2/15], Step [50/104], Loss: 0.2095\n",
      "Epoch [2/15], Step [60/104], Loss: 0.2537\n",
      "Epoch [2/15], Step [70/104], Loss: 0.1309\n",
      "Epoch [2/15], Step [80/104], Loss: 0.2568\n",
      "Epoch [2/15], Step [90/104], Loss: 0.1228\n",
      "Epoch [2/15], Step [100/104], Loss: 0.1466\n",
      "Epoch [3/15], Step [10/104], Loss: 0.2175\n",
      "Epoch [3/15], Step [20/104], Loss: 0.2526\n",
      "Epoch [3/15], Step [30/104], Loss: 0.1349\n",
      "Epoch [3/15], Step [40/104], Loss: 0.3846\n",
      "Epoch [3/15], Step [50/104], Loss: 0.2543\n",
      "Epoch [3/15], Step [60/104], Loss: 0.2405\n",
      "Epoch [3/15], Step [70/104], Loss: 0.1401\n",
      "Epoch [3/15], Step [80/104], Loss: 0.1579\n",
      "Epoch [3/15], Step [90/104], Loss: 0.1004\n",
      "Epoch [3/15], Step [100/104], Loss: 0.0668\n",
      "Epoch [4/15], Step [10/104], Loss: 0.1095\n",
      "Epoch [4/15], Step [20/104], Loss: 0.1140\n",
      "Epoch [4/15], Step [30/104], Loss: 0.1405\n",
      "Epoch [4/15], Step [40/104], Loss: 0.0493\n",
      "Epoch [4/15], Step [50/104], Loss: 0.1201\n",
      "Epoch [4/15], Step [60/104], Loss: 0.1599\n",
      "Epoch [4/15], Step [70/104], Loss: 0.0487\n",
      "Epoch [4/15], Step [80/104], Loss: 0.1495\n",
      "Epoch [4/15], Step [90/104], Loss: 0.0947\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-edd63c883f97>\u001b[0m in \u001b[0;36mtrain_by_model\u001b[0;34m(model, model_name, epo, verbose)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mn_total_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-de9de66cc787>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mimage_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_dirs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    902\u001b[0m         \"\"\"\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Accuracy for LeNet5 with various epoch\n",
    "\n",
    "model = LeNet5()\n",
    "model_name = \"LeNet5\"\n",
    "\n",
    "losses = train_by_model(model, model_name, 15, verbose = False)\n",
    "\n",
    "accs = {}\n",
    "for epo in LeNet5_model_with_epoch:\n",
    "    print(\"Calculating accuracy of model with epoch: \", epo)\n",
    "    model = LeNet5_model_with_epoch[epo]\n",
    "    acc = get_acc_from_data(test_loader)\n",
    "    accs[epo] = acc\n",
    "\n",
    "acc_of_model_epoch[model_name] = accs\n",
    "\n",
    "# -----------------------------------------------------\n",
    "import json\n",
    "with open('loss_data_of_model_epoch.json', 'w') as fp:\n",
    "    json.dump(loss_data_of_model_epoch, fp)\n",
    "    \n",
    "with open('acc_of_model_epoch.json', 'w') as fp:\n",
    "    json.dump(acc_of_model_epoch, fp)\n",
    "# -----------------------------------------------------\n",
    "\n",
    "model_name = \"LeNet5\"\n",
    "max_acc_epo = 1\n",
    "max_acc = acc_of_model_epoch[model_name][max_acc_epo]\n",
    "for epo in acc_of_model_epoch[model_name]:\n",
    "    if max_acc < acc_of_model_epoch[model_name][epo]:\n",
    "        max_acc = acc_of_model_epoch[model_name][epo]\n",
    "        max_acc_epo = epo\n",
    "\n",
    "print(\"Maximum accuracy is \", max_acc, \" with epoch as \", max_acc_epo)\n",
    "\n",
    "plt.plot(list(accs.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5690e0e5",
   "metadata": {},
   "source": [
    "### Experiment 3: Deciding batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadf4150",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Experiment with various batch sizes for LeNet5 with epoch = 5\n",
    "\n",
    "\n",
    "for bs in [16, 32, 64]:\n",
    "    print(\"Batch Size: \", bs)\n",
    "    train_loader =  torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True)\n",
    "    test_loader =  torch.utils.data.DataLoader(testset, batch_size=bs, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(valset, batch_size=bs, shuffle=True)\n",
    "    model = LeNet5()\n",
    "    train_by_model(model, model_name, 5)\n",
    "    acc_of_model_batch[model_name][bs] = get_acc_from_data(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5503525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Batch Size that gives highest accuracy\n",
    "\n",
    "# model_name = \"LeNet5\"\n",
    "# max_acc_bat = 16\n",
    "# max_acc = acc_of_model_batch[model_name][max_acc_epo]\n",
    "# for bat in acc_of_model_batch[model_name]:\n",
    "#     if max_acc < acc_of_model_batch[model_name][bat]:\n",
    "#         max_acc = acc_of_model_batch[model_name][bat]\n",
    "#         max_acc_bat = bat \n",
    "\n",
    "# print(\"Maximum accuracy is \", max_acc, \" with epoch as \", max_acc_epo)\n",
    "\n",
    "print(\"Upon analyzing the runtime and accuracy of data we took the following parameters forward\")\n",
    "print(\"Batch Size: 32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77161340",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454e917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_epochs = 12\n",
    "batch_size = 32\n",
    "\n",
    "train_loader =  torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader =  torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = LeNet5()\n",
    "model_name = \"LeNet5\"\n",
    "\n",
    "losses = train_by_model(model, model_name, args.num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085abeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc_from_data(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2363dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc_from_data(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c523b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
