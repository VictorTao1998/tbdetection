{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff1ede8c",
   "metadata": {},
   "source": [
    "# ECE 228 Project\n",
    "## Tuberculosis Detection | Team 26\n",
    "### Jianyu Tao\n",
    "### Shreyas Borse\n",
    "### Harshit Bhadani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89309d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version 1.11.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "## Importing modules for necessary operations\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pdb\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import argparse\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print('Using PyTorch version', torch.__version__)\n",
    "\n",
    "\n",
    "from os.path import isfile\n",
    "from os import rename\n",
    "SMOOTH=1\n",
    "import pdb\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from PIL.ImageFilter import GaussianBlur\n",
    "\n",
    "# import pdb\n",
    "from numpy import pi as PI\n",
    "from numpy import sqrt\n",
    "from scipy.special import comb\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0be2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscellaneous initialization\n",
    "torch.manual_seed(1)\n",
    "start_time = time.time()\n",
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0d5de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"\"\n",
    "test_dataset_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fc58232",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/Users/harshitb/Desktop/Studies/ECE 228/TB_dataset/TB_Chest_Radiography_Database\"\n",
    "class_names = ['Normal', 'Tuberculosis']\n",
    "source_dirs = ['Normal', 'Tuberculosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "930810b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.add_argument('--num_epochs', type=int, default=5, help='Number of training epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='Batch size')\n",
    "parser.add_argument('--lr', type=float, default=5e-4, help='Learning rate')\n",
    "parser.add_argument('--l2', type=float, default=0, help='L2 regularisation')\n",
    "parser.add_argument('--aug', action='store_true', default=False, help='Use data augmentation')\n",
    "parser.add_argument('--data_path', type=str, default=root_dir,help='Path to data.')\n",
    "parser.add_argument('--bond_dim', type=int, default=5, help='MPS Bond dimension')\n",
    "parser.add_argument('--nChannel', type=int, default=1, help='Number of input channels')\n",
    "parser.add_argument('--dense_net', action='store_true', default=False, help='Using Dense Net model')\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "684a5c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = args.batch_size\n",
    "\n",
    "# LoTeNet parameters\n",
    "adaptive_mode = False \n",
    "periodic_bc   = False\n",
    "\n",
    "kernel = 2 # Stride along spatial dimensions\n",
    "output_dim = 1 # output dimension\n",
    " \n",
    "feature_dim = 2\n",
    "\n",
    "normTensor = 0.5*torch.ones(args.nChannel)\n",
    "### Data processing and loading....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a61e98b",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc2837a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data processing and loading....\n",
    "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.Resize(size=(256,256)),\n",
    "                                      transforms.RandomVerticalFlip(),\n",
    "                                      transforms.RandomRotation(20),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=normTensor,std=normTensor)])\n",
    "\n",
    "valid_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size=(256,256)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(20),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=normTensor,std=normTensor)\n",
    "    #torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1abf12",
   "metadata": {},
   "source": [
    "### Creating Datasets classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a87dbe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXRayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_dirs,transform):\n",
    "        def get_images(class_name):\n",
    "            images = [x for x in os.listdir(image_dirs[class_name]) if x.lower().endswith('png')]\n",
    "            print(f'Found {len(images)}{class_name}')\n",
    "            return images\n",
    "        self.images={}\n",
    "        self.class_names=['Normal', 'Tuberculosis']\n",
    "        for c in self.class_names:\n",
    "            self.images[c]=get_images(c)\n",
    "        self.image_dirs=image_dirs\n",
    "        self.transform=transform\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return sum([len(self.images[c]) for c in self.class_names])\n",
    "    def __getitem__(self, index):\n",
    "        class_name=random.choice(self.class_names)\n",
    "        index=index%len(self.images[class_name])\n",
    "        image_name=self.images[class_name][index]\n",
    "        image_path =os.path.join(self.image_dirs[class_name], image_name)\n",
    "        image=Image.open(image_path).convert('L')\n",
    "        return self.transform(image), self.class_names.index(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56fa2063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3500Normal\n",
      "Found 700Tuberculosis\n"
     ]
    }
   ],
   "source": [
    "train_dirs = {\n",
    "    'Normal': root_dir + '/Normal',\n",
    "    'Tuberculosis': root_dir + '/Tuberculosis'\n",
    "}\n",
    "dataset = ChestXRayDataset(train_dirs, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbe34a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset, valset = random_split(dataset, [3300, 600, 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1288b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader =  torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader =  torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8fa93a",
   "metadata": {},
   "source": [
    "# Creating various architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "966057cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        #         xl = 1\n",
    "        #         for i in x.shape[1:]: xl *= i\n",
    "        #         self.fc1 = nn.Linear(13456, 120)\n",
    "        self.fc1 = nn.Linear(984064, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        #         x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
    "        #         x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv1(x))  # -> n, 6, 14, 14\n",
    "        x = F.relu(self.conv2(x))\n",
    "        xl = 1\n",
    "        for i in x.shape[1:]: xl *= i\n",
    "        x = x.view(-1, xl)            # \n",
    "        x = F.relu(self.fc1(x))               # -> n, 120\n",
    "        x = F.relu(self.fc2(x))               # -> n, 84\n",
    "        x = self.fc3(x)                       # -> n, 2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a40b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the convolutional neural network\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Linear(59536, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddf655a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.conv1_1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv4_1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv5_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(32768, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv5_1(x))\n",
    "        x = F.relu(self.conv5_2(x))\n",
    "        x = F.relu(self.conv5_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "#         print(\"HERE ... \", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, 0.5) #dropout was included to combat overfitting\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, 0.5)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88249028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising variable that will be used in the experiments in the project\n",
    "\n",
    "loss_data_of_model_epoch = {}\n",
    "acc_of_model_epoch = {}\n",
    "acc_of_model_batch = {}\n",
    "\n",
    "all_models = {}\n",
    "all_models['ConvNet'] = ConvNet()\n",
    "all_models['LeNet5']  = LeNet5()\n",
    "all_models['VGG16']   = VGG16()\n",
    "\n",
    "for model_name in all_models.keys():\n",
    "    loss_data_of_model_epoch[model_name] = {}\n",
    "    acc_of_model_epoch[model_name] = {}\n",
    "    acc_of_model_batch[model_name] = {}\n",
    "\n",
    "LeNet5_model_with_epoch = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab437e84",
   "metadata": {},
   "source": [
    "# Defining various functions to make the code modular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bd40115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_from_data(d_loader):\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        n_class_correct = [0 for i in range(2)]\n",
    "        n_class_samples = [0 for i in range(2)]\n",
    "        for images, labels in d_loader:\n",
    "            #         print(len(labels))\n",
    "            outputs = model(images)\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                pred = predicted[i]\n",
    "                if (label == pred):\n",
    "                    n_class_correct[label] += 1\n",
    "                n_class_samples[label] += 1\n",
    "\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network: {acc} %')\n",
    "        \n",
    "        all_acc = []\n",
    "        overall_accuracy = acc\n",
    "        all_acc.append(overall_accuracy)\n",
    "\n",
    "        for i in range(2):\n",
    "            acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "            print(f'Accuracy of {class_names[i]}: {acc} %')\n",
    "            all_acc.append(acc)\n",
    "                \n",
    "    #return all_acc\n",
    "    return overall_accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b1e415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_by_model(model, model_name, epo = 3, verbose = True):\n",
    "    args.num_epochs = epo\n",
    "    learning_rate = 0.001\n",
    "    all_loss = []\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    n_total_steps = len(train_loader)\n",
    "    for epoch in range(args.num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            all_loss.append(loss.item())\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if ((i+1) % 10 == 0) and verbose:\n",
    "                print (f'Epoch [{epoch+1}/{args.num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "        LeNet5_model_with_epoch[epoch+1] = copy.deepcopy(model)\n",
    "        \n",
    "    return all_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb0a14",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f57aec",
   "metadata": {},
   "source": [
    "### Experiment: Deciding Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5446561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [10/104], Loss: 0.6480\n",
      "Epoch [1/3], Step [20/104], Loss: 0.6886\n",
      "Epoch [1/3], Step [30/104], Loss: 0.6137\n",
      "Epoch [1/3], Step [40/104], Loss: 0.5863\n",
      "Epoch [1/3], Step [50/104], Loss: 0.5662\n",
      "Epoch [1/3], Step [60/104], Loss: 0.5802\n",
      "Epoch [1/3], Step [70/104], Loss: 0.5153\n"
     ]
    }
   ],
   "source": [
    "# Checking various architectures above one by one with epoch = 3\n",
    "\n",
    "model_name = \"LeNet5\"\n",
    "model = all_models[model_name]\n",
    "\n",
    "train_by_model(model, model_name)\n",
    "get_acc_from_data(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e87e940",
   "metadata": {},
   "source": [
    "### Experiment: Deciding epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75599bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Accuracy for LeNet5 with various epoch\n",
    "\n",
    "model = LeNet5()\n",
    "model_name = \"LeNet5\"\n",
    "\n",
    "losses = train_by_model(model, model_name, 15, verbose = False)\n",
    "\n",
    "accs = {}\n",
    "for epo in LeNet5_model_with_epoch:\n",
    "    print(\"Calculating accuracy of model with epoch: \", epo)\n",
    "    model = LeNet5_model_with_epoch[epo]\n",
    "    acc = get_acc_from_data(test_loader)\n",
    "    accs[epo] = acc\n",
    "\n",
    "acc_of_model_epoch[model_name] = accs\n",
    "\n",
    "# -----------------------------------------------------\n",
    "import json\n",
    "with open('loss_data_of_model_epoch.json', 'w') as fp:\n",
    "    json.dump(loss_data_of_model_epoch, fp)\n",
    "    \n",
    "with open('acc_of_model_epoch.json', 'w') as fp:\n",
    "    json.dump(acc_of_model_epoch, fp)\n",
    "# -----------------------------------------------------\n",
    "\n",
    "model_name = \"LeNet5\"\n",
    "max_acc_epo = 1\n",
    "max_acc = acc_of_model_epoch[model_name][max_acc_epo]\n",
    "for epo in acc_of_model_epoch[model_name]:\n",
    "    if max_acc < acc_of_model_epoch[model_name][epo]:\n",
    "        max_acc = acc_of_model_epoch[model_name][epo]\n",
    "        max_acc_epo = epo\n",
    "\n",
    "print(\"Maximum accuracy is \", max_acc, \" with epoch as \", max_acc_epo)\n",
    "\n",
    "plt.plot(list(accs.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5690e0e5",
   "metadata": {},
   "source": [
    "### Experiment: Deciding batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadf4150",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Experiment with various batch sizes for LeNet5 with epoch = 5\n",
    "\n",
    "\n",
    "for bs in [16, 32, 64]:\n",
    "    print(\"Batch Size: \", bs)\n",
    "    train_loader =  torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True)\n",
    "    test_loader =  torch.utils.data.DataLoader(testset, batch_size=bs, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(valset, batch_size=bs, shuffle=True)\n",
    "    model = LeNet5()\n",
    "    train_by_model(model, model_name, 5, verbose = False)\n",
    "    acc_of_model_batch[model_name][bs] = get_acc_from_data(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5503525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Batch Size that gives highest accuracy\n",
    "\n",
    "model_name = \"LeNet5\"\n",
    "max_acc_bat = 16\n",
    "max_acc = acc_of_model_batch[model_name][max_acc_bat]\n",
    "for bat in acc_of_model_batch[model_name]:\n",
    "    if max_acc < acc_of_model_batch[model_name][bat]:\n",
    "        max_acc = acc_of_model_batch[model_name][bat]\n",
    "        max_acc_bat = bat \n",
    "\n",
    "print(\"Maximum accuracy is \", max_acc, \" with batch size as \", max_acc_bat)\n",
    "\n",
    "print(\"Upon analyzing the runtime and accuracy of data we took the following parameters forward\")\n",
    "print(\"Batch Size: 32\")\n",
    "print(\"32 was taken as it had lesser runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77161340",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454e917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_epochs = 12\n",
    "batch_size = 32\n",
    "\n",
    "train_loader =  torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader =  torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = LeNet5()\n",
    "model_name = \"LeNet5\"\n",
    "\n",
    "losses = train_by_model(model, model_name, args.num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085abeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc_from_data(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2363dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc_from_data(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c523b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
