{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff1ede8c",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89309d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version 1.11.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pdb\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import argparse\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print('Using PyTorch version', torch.__version__)\n",
    "\n",
    "\n",
    "from os.path import isfile\n",
    "from os import rename\n",
    "SMOOTH=1\n",
    "import pdb\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from PIL.ImageFilter import GaussianBlur\n",
    "\n",
    "# import pdb\n",
    "from numpy import pi as PI\n",
    "from numpy import sqrt\n",
    "from scipy.special import comb\n",
    "import math\n",
    "\n",
    "import copy\n",
    "# tensorflow libraries\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5c46b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch res, res101..\n",
    "\n",
    "# Tying papers -> Take inputs from the papers and comparision\n",
    "# Implementing. LeNet\n",
    "# EDA. More about Dataset\n",
    "# Data Augmentation -> Its Benifits\n",
    "# Can use different dataset on top of this\n",
    "# Loss plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0be2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscellaneous initialization\n",
    "torch.manual_seed(1)\n",
    "start_time = time.time()\n",
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0d5de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"\"\n",
    "test_dataset_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fc58232",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/Users/harshitb/Desktop/Studies/ECE 228/TB_dataset/TB_Chest_Radiography_Database\"\n",
    "class_names = ['Normal', 'Tuberculosis']\n",
    "source_dirs = ['Normal', 'Tuberculosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "930810b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.add_argument('--num_epochs', type=int, default=5, help='Number of training epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='Batch size')\n",
    "parser.add_argument('--lr', type=float, default=5e-4, help='Learning rate')\n",
    "parser.add_argument('--l2', type=float, default=0, help='L2 regularisation')\n",
    "parser.add_argument('--aug', action='store_true', default=False, help='Use data augmentation')\n",
    "parser.add_argument('--data_path', type=str, default=root_dir,help='Path to data.')\n",
    "parser.add_argument('--bond_dim', type=int, default=5, help='MPS Bond dimension')\n",
    "parser.add_argument('--nChannel', type=int, default=1, help='Number of input channels')\n",
    "parser.add_argument('--dense_net', action='store_true', default=False, help='Using Dense Net model')\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "684a5c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = args.batch_size\n",
    "\n",
    "# LoTeNet parameters\n",
    "adaptive_mode = False \n",
    "periodic_bc   = False\n",
    "\n",
    "kernel = 2 # Stride along spatial dimensions\n",
    "output_dim = 1 # output dimension\n",
    " \n",
    "feature_dim = 2\n",
    "\n",
    "#logFile = time.strftime(\"%Y%m%d_%H_%M\")+'.txt'\n",
    "#makeLogFile(logFile)\n",
    "\n",
    "normTensor = 0.5*torch.ones(args.nChannel)\n",
    "### Data processing and loading....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc2837a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data processing and loading....\n",
    "# mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225]\n",
    "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.Resize(size=(256,256)),\n",
    "#                                       transforms.RandomVerticalFlip(),\n",
    "#                                       transforms.RandomRotation(20),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=normTensor,std=normTensor)])\n",
    "\n",
    "valid_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size=(256,256)),\n",
    "#     torchvision.transforms.RandomHorizontalFlip(),\n",
    "#     torchvision.transforms.RandomRotation(20),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=normTensor,std=normTensor)\n",
    "    #torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a87dbe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXRayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_dirs,transform):\n",
    "        def get_images(class_name):\n",
    "            images = [x for x in os.listdir(image_dirs[class_name]) if x.lower().endswith('png')]\n",
    "            print(f'Found {len(images)}{class_name}')\n",
    "            return images\n",
    "        self.images={}\n",
    "        self.class_names=['Normal', 'Tuberculosis']\n",
    "        for c in self.class_names:\n",
    "            self.images[c]=get_images(c)\n",
    "        self.image_dirs=image_dirs\n",
    "        self.transform=transform\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return sum([len(self.images[c]) for c in self.class_names])\n",
    "    def __getitem__(self, index):\n",
    "        class_name=random.choice(self.class_names)\n",
    "        index=index%len(self.images[class_name])\n",
    "        image_name=self.images[class_name][index]\n",
    "        image_path =os.path.join(self.image_dirs[class_name], image_name)\n",
    "        image=Image.open(image_path).convert('L')\n",
    "        return self.transform(image), self.class_names.index(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56fa2063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3500Normal\n",
      "Found 700Tuberculosis\n"
     ]
    }
   ],
   "source": [
    "train_dirs = {\n",
    "    'Normal': root_dir + '/Normal',\n",
    "    'Tuberculosis': root_dir + '/Tuberculosis'\n",
    "}\n",
    "dataset = ChestXRayDataset(train_dirs, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6795fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,l = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfaf2476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbe34a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset, valset = random_split(dataset, [3300, 600, 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1288b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader =  torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader =  torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "966057cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        #         xl = 1\n",
    "        #         for i in x.shape[1:]: xl *= i\n",
    "        #         self.fc1 = nn.Linear(13456, 120)\n",
    "        self.fc1 = nn.Linear(984064, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        #         x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
    "        #         x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv1(x))  # -> n, 6, 14, 14\n",
    "        x = F.relu(self.conv2(x))\n",
    "        xl = 1\n",
    "        for i in x.shape[1:]: xl *= i\n",
    "        x = x.view(-1, xl)            # \n",
    "        x = F.relu(self.fc1(x))               # -> n, 120\n",
    "        x = F.relu(self.fc2(x))               # -> n, 84\n",
    "        x = self.fc3(x)                       # -> n, 2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a40b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the convolutional neural network\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Linear(59536, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddf655a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.conv1_1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv4_1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv5_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(32768, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv5_1(x))\n",
    "        x = F.relu(self.conv5_2(x))\n",
    "        x = F.relu(self.conv5_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "#         print(\"HERE ... \", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, 0.5) #dropout was included to combat overfitting\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, 0.5)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88249028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising variable that will be used in the experiments in the project\n",
    "\n",
    "loss_data_of_model_epoch = {}\n",
    "acc_of_model_epoch = {}\n",
    "acc_of_model_batch = {}\n",
    "\n",
    "all_models = {}\n",
    "all_models['ConvNet'] = ConvNet()\n",
    "all_models['LeNet5']  = LeNet5()\n",
    "all_models['VGG16']   = VGG16()\n",
    "\n",
    "for model_name in all_models.keys():\n",
    "    loss_data_of_model_epoch[model_name] = {}\n",
    "    acc_of_model_epoch[model_name] = {}\n",
    "    acc_of_model_batch[model_name] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bd40115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_from_data(d_loader):\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        n_class_correct = [0 for i in range(2)]\n",
    "        n_class_samples = [0 for i in range(2)]\n",
    "        for images, labels in d_loader:\n",
    "            #         print(len(labels))\n",
    "            outputs = model(images)\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                pred = predicted[i]\n",
    "                if (label == pred):\n",
    "                    n_class_correct[label] += 1\n",
    "                n_class_samples[label] += 1\n",
    "\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network: {acc} %')\n",
    "        \n",
    "        all_acc = []\n",
    "        overall_accuracy = acc\n",
    "        all_acc.append(overall_accuracy)\n",
    "\n",
    "        for i in range(2):\n",
    "            acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "            print(f'Accuracy of {class_names[i]}: {acc} %')\n",
    "            all_acc.append(acc)\n",
    "                \n",
    "    #return all_acc\n",
    "    return overall_accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f864a6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet5_model_with_epoch = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b1e415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_by_model(model, model_name, epo = 3, verbose = True):\n",
    "    args.num_epochs = epo\n",
    "    learning_rate = 0.001\n",
    "    all_loss = []\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    n_total_steps = len(train_loader)\n",
    "    for epoch in range(args.num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            all_loss.append(loss.item())\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if ((i+1) % 10 == 0) and verbose:\n",
    "                print (f'Epoch [{epoch+1}/{args.num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "        LeNet5_model_with_epoch[i+1] = copy.deepcopy(model)\n",
    "        \n",
    "    return all_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7aa1a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting epoch as 3\n",
    "args.num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5446561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [10/104], Loss: 0.6094\n",
      "Epoch [1/3], Step [20/104], Loss: 0.4326\n",
      "Epoch [1/3], Step [30/104], Loss: 0.4567\n",
      "Epoch [1/3], Step [40/104], Loss: 0.3177\n",
      "Epoch [1/3], Step [50/104], Loss: 0.3644\n",
      "Epoch [1/3], Step [60/104], Loss: 0.3680\n",
      "Epoch [1/3], Step [70/104], Loss: 0.3047\n",
      "Epoch [1/3], Step [80/104], Loss: 0.2891\n",
      "Epoch [1/3], Step [90/104], Loss: 0.1648\n",
      "Epoch [1/3], Step [100/104], Loss: 0.2321\n",
      "Epoch [2/3], Step [10/104], Loss: 0.2310\n",
      "Epoch [2/3], Step [20/104], Loss: 0.3047\n",
      "Epoch [2/3], Step [30/104], Loss: 0.2559\n",
      "Epoch [2/3], Step [40/104], Loss: 0.2798\n",
      "Epoch [2/3], Step [50/104], Loss: 0.2986\n",
      "Epoch [2/3], Step [60/104], Loss: 0.1637\n",
      "Epoch [2/3], Step [70/104], Loss: 0.2364\n",
      "Epoch [2/3], Step [80/104], Loss: 0.1542\n",
      "Epoch [2/3], Step [90/104], Loss: 0.1273\n",
      "Epoch [2/3], Step [100/104], Loss: 0.2105\n",
      "Epoch [3/3], Step [10/104], Loss: 0.1661\n",
      "Epoch [3/3], Step [20/104], Loss: 0.1403\n",
      "Epoch [3/3], Step [30/104], Loss: 0.2445\n",
      "Epoch [3/3], Step [40/104], Loss: 0.1987\n",
      "Epoch [3/3], Step [50/104], Loss: 0.1885\n",
      "Epoch [3/3], Step [60/104], Loss: 0.1617\n",
      "Epoch [3/3], Step [70/104], Loss: 0.0773\n",
      "Epoch [3/3], Step [80/104], Loss: 0.1920\n",
      "Epoch [3/3], Step [90/104], Loss: 0.1602\n",
      "Epoch [3/3], Step [100/104], Loss: 0.1770\n",
      "Accuracy of the network: 94.83333333333333 %\n",
      "Accuracy of Normal: 90.3225806451613 %\n",
      "Accuracy of Tuberculosis: 99.65517241379311 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94.83333333333333"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking various architectures above one by one with epoch = 3\n",
    "\n",
    "model_name = \"LeNet5\"\n",
    "model = all_models[model_name]\n",
    "\n",
    "train_by_model(model, model_name)\n",
    "get_acc_from_data(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75599bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [10/104], Loss: 0.6192\n",
      "Epoch [1/1], Step [20/104], Loss: 0.5485\n",
      "Epoch [1/1], Step [30/104], Loss: 0.4677\n",
      "Epoch [1/1], Step [40/104], Loss: 0.4153\n",
      "Epoch [1/1], Step [50/104], Loss: 0.4323\n",
      "Epoch [1/1], Step [60/104], Loss: 0.3215\n",
      "Epoch [1/1], Step [70/104], Loss: 0.4409\n",
      "Epoch [1/1], Step [80/104], Loss: 0.2864\n",
      "Epoch [1/1], Step [90/104], Loss: 0.2285\n",
      "Epoch [1/1], Step [100/104], Loss: 0.2481\n",
      "Epoch done:  2  Calculating accuracy\n",
      "Accuracy of the network: 87.5 %\n",
      "Accuracy of Normal: 98.6842105263158 %\n",
      "Accuracy of Tuberculosis: 76.01351351351352 %\n",
      "Epoch [1/2], Step [10/104], Loss: 0.6396\n",
      "Epoch [1/2], Step [20/104], Loss: 0.5425\n",
      "Epoch [1/2], Step [30/104], Loss: 0.4834\n",
      "Epoch [1/2], Step [40/104], Loss: 0.4625\n",
      "Epoch [1/2], Step [50/104], Loss: 0.4291\n",
      "Epoch [1/2], Step [60/104], Loss: 0.3717\n",
      "Epoch [1/2], Step [70/104], Loss: 0.3176\n",
      "Epoch [1/2], Step [80/104], Loss: 0.3216\n",
      "Epoch [1/2], Step [90/104], Loss: 0.2489\n",
      "Epoch [1/2], Step [100/104], Loss: 0.1935\n",
      "Epoch [2/2], Step [10/104], Loss: 0.3132\n",
      "Epoch [2/2], Step [20/104], Loss: 0.2294\n",
      "Epoch [2/2], Step [30/104], Loss: 0.2515\n",
      "Epoch [2/2], Step [40/104], Loss: 0.1908\n",
      "Epoch [2/2], Step [50/104], Loss: 0.2775\n",
      "Epoch [2/2], Step [60/104], Loss: 0.1270\n",
      "Epoch [2/2], Step [70/104], Loss: 0.1992\n",
      "Epoch [2/2], Step [80/104], Loss: 0.1271\n",
      "Epoch [2/2], Step [90/104], Loss: 0.2376\n",
      "Epoch [2/2], Step [100/104], Loss: 0.1785\n",
      "Epoch done:  3  Calculating accuracy\n",
      "Accuracy of the network: 80.83333333333333 %\n",
      "Accuracy of Normal: 99.66442953020135 %\n",
      "Accuracy of Tuberculosis: 62.25165562913907 %\n",
      "Epoch [1/3], Step [10/104], Loss: 0.6451\n",
      "Epoch [1/3], Step [20/104], Loss: 0.6120\n",
      "Epoch [1/3], Step [30/104], Loss: 0.5177\n",
      "Epoch [1/3], Step [40/104], Loss: 0.4873\n",
      "Epoch [1/3], Step [50/104], Loss: 0.4627\n",
      "Epoch [1/3], Step [60/104], Loss: 0.4021\n",
      "Epoch [1/3], Step [70/104], Loss: 0.3873\n",
      "Epoch [1/3], Step [80/104], Loss: 0.2989\n",
      "Epoch [1/3], Step [90/104], Loss: 0.4019\n",
      "Epoch [1/3], Step [100/104], Loss: 0.3606\n",
      "Epoch [2/3], Step [10/104], Loss: 0.2420\n",
      "Epoch [2/3], Step [20/104], Loss: 0.4264\n",
      "Epoch [2/3], Step [30/104], Loss: 0.3049\n",
      "Epoch [2/3], Step [40/104], Loss: 0.3384\n",
      "Epoch [2/3], Step [50/104], Loss: 0.2803\n",
      "Epoch [2/3], Step [60/104], Loss: 0.2677\n",
      "Epoch [2/3], Step [70/104], Loss: 0.2472\n",
      "Epoch [2/3], Step [80/104], Loss: 0.3289\n",
      "Epoch [2/3], Step [90/104], Loss: 0.2003\n",
      "Epoch [2/3], Step [100/104], Loss: 0.1675\n",
      "Epoch [3/3], Step [10/104], Loss: 0.2957\n",
      "Epoch [3/3], Step [20/104], Loss: 0.2034\n",
      "Epoch [3/3], Step [30/104], Loss: 0.2202\n",
      "Epoch [3/3], Step [40/104], Loss: 0.1708\n",
      "Epoch [3/3], Step [50/104], Loss: 0.1913\n",
      "Epoch [3/3], Step [60/104], Loss: 0.2304\n",
      "Epoch [3/3], Step [70/104], Loss: 0.1106\n",
      "Epoch [3/3], Step [80/104], Loss: 0.1413\n",
      "Epoch [3/3], Step [90/104], Loss: 0.1948\n",
      "Epoch [3/3], Step [100/104], Loss: 0.2675\n",
      "Epoch done:  4  Calculating accuracy\n",
      "Accuracy of the network: 95.16666666666667 %\n",
      "Accuracy of Normal: 95.06172839506173 %\n",
      "Accuracy of Tuberculosis: 95.28985507246377 %\n",
      "Epoch [1/4], Step [10/104], Loss: 0.6631\n",
      "Epoch [1/4], Step [20/104], Loss: 0.5554\n",
      "Epoch [1/4], Step [30/104], Loss: 0.5685\n",
      "Epoch [1/4], Step [40/104], Loss: 0.4462\n",
      "Epoch [1/4], Step [50/104], Loss: 0.4020\n",
      "Epoch [1/4], Step [60/104], Loss: 0.3748\n",
      "Epoch [1/4], Step [70/104], Loss: 0.3093\n",
      "Epoch [1/4], Step [80/104], Loss: 0.3291\n",
      "Epoch [1/4], Step [90/104], Loss: 0.2841\n",
      "Epoch [1/4], Step [100/104], Loss: 0.3842\n",
      "Epoch [2/4], Step [10/104], Loss: 0.3335\n",
      "Epoch [2/4], Step [20/104], Loss: 0.2950\n",
      "Epoch [2/4], Step [30/104], Loss: 0.2072\n",
      "Epoch [2/4], Step [40/104], Loss: 0.3603\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-e3dc28119aa4>\u001b[0m in \u001b[0;36mtrain_by_model\u001b[0;34m(model, model_name, epo, verbose)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mn_total_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-de9de66cc787>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_dirs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Accuracy for LeNet5 with various epoch\n",
    "\n",
    "model_name = 'LeNet5'\n",
    "model = LeNet5()\n",
    "for i in range(1,16):\n",
    "    model = LeNet5()\n",
    "    losses = train_by_model(model, model_name, i)\n",
    "    loss_data_of_model_epoch[model_name][i] = losses\n",
    "    print(\"Epoch done: \", i, \" Calculating accuracy\")\n",
    "    acc_of_model_epoch[model_name][i] = get_acc_from_data(test_loader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec53c649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy is  95.16666666666667  with epoch as  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbea9387550>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Getting Epoch that gives highest accuracy\n",
    "\n",
    "model_name = \"LeNet5\"\n",
    "acc_of_model_epoch\n",
    "max_acc_epo = 1\n",
    "max_acc = acc_of_model_epoch[model_name][max_acc_epo]\n",
    "for epo in acc_of_model_epoch[model_name]:\n",
    "    if max_acc < acc_of_model_epoch[model_name][epo]:\n",
    "        max_acc = acc_of_model_epoch[model_name][epo]\n",
    "        max_acc_epo = epo\n",
    "\n",
    "print(\"Maximum accuracy is \", max_acc, \" with epoch as \", max_acc_epo)\n",
    "\n",
    "# loss_data_of_model_epoch\n",
    "# acc_of_model_epoch\n",
    "\n",
    "import json\n",
    "with open('loss_data_of_model_epoch_t.json', 'w') as fp:\n",
    "    json.dump(loss_data_of_model_epoch, fp)\n",
    "    \n",
    "with open('acc_of_model_epoch_t.json', 'w') as fp:\n",
    "    json.dump(acc_of_model_epoch, fp)\n",
    "\n",
    "all_accuracies = []\n",
    "for epo in acc_of_model_epoch[model_name]:\n",
    "    all_accuracies.append(acc_of_model_epoch[model_name][epo])\n",
    "\n",
    "plt.plot(all_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ecf67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size:  16\n",
      "Epoch [1/5], Step [10/207], Loss: 0.6068\n",
      "Epoch [1/5], Step [20/207], Loss: 0.5503\n",
      "Epoch [1/5], Step [30/207], Loss: 0.6159\n",
      "Epoch [1/5], Step [40/207], Loss: 0.4328\n",
      "Epoch [1/5], Step [50/207], Loss: 0.3719\n",
      "Epoch [1/5], Step [60/207], Loss: 0.3254\n",
      "Epoch [1/5], Step [70/207], Loss: 0.3624\n",
      "Epoch [1/5], Step [80/207], Loss: 0.4185\n",
      "Epoch [1/5], Step [90/207], Loss: 0.2952\n",
      "Epoch [1/5], Step [100/207], Loss: 0.2442\n",
      "Epoch [1/5], Step [110/207], Loss: 0.2040\n",
      "Epoch [1/5], Step [120/207], Loss: 0.2007\n",
      "Epoch [1/5], Step [130/207], Loss: 0.2323\n",
      "Epoch [1/5], Step [140/207], Loss: 0.3009\n",
      "Epoch [1/5], Step [150/207], Loss: 0.3715\n",
      "Epoch [1/5], Step [160/207], Loss: 0.1898\n",
      "Epoch [1/5], Step [170/207], Loss: 0.2887\n",
      "Epoch [1/5], Step [180/207], Loss: 0.1570\n",
      "Epoch [1/5], Step [190/207], Loss: 0.3488\n",
      "Epoch [1/5], Step [200/207], Loss: 0.2307\n",
      "Epoch [2/5], Step [10/207], Loss: 0.1339\n",
      "Epoch [2/5], Step [20/207], Loss: 0.1879\n",
      "Epoch [2/5], Step [30/207], Loss: 0.1315\n",
      "Epoch [2/5], Step [40/207], Loss: 0.0613\n",
      "Epoch [2/5], Step [50/207], Loss: 0.1082\n",
      "Epoch [2/5], Step [60/207], Loss: 0.1881\n",
      "Epoch [2/5], Step [70/207], Loss: 0.1209\n",
      "Epoch [2/5], Step [80/207], Loss: 0.0543\n",
      "Epoch [2/5], Step [90/207], Loss: 0.1010\n",
      "Epoch [2/5], Step [100/207], Loss: 0.0888\n",
      "Epoch [2/5], Step [110/207], Loss: 0.1333\n",
      "Epoch [2/5], Step [120/207], Loss: 0.1323\n",
      "Epoch [2/5], Step [130/207], Loss: 0.0965\n",
      "Epoch [2/5], Step [140/207], Loss: 0.1602\n",
      "Epoch [2/5], Step [150/207], Loss: 0.1312\n",
      "Epoch [2/5], Step [160/207], Loss: 0.1061\n",
      "Epoch [2/5], Step [170/207], Loss: 0.1417\n",
      "Epoch [2/5], Step [180/207], Loss: 0.3404\n",
      "Epoch [2/5], Step [190/207], Loss: 0.4990\n",
      "Epoch [2/5], Step [200/207], Loss: 0.1840\n",
      "Epoch [3/5], Step [10/207], Loss: 0.0336\n",
      "Epoch [3/5], Step [20/207], Loss: 0.0966\n",
      "Epoch [3/5], Step [30/207], Loss: 0.0322\n",
      "Epoch [3/5], Step [40/207], Loss: 0.1244\n",
      "Epoch [3/5], Step [50/207], Loss: 0.1110\n",
      "Epoch [3/5], Step [60/207], Loss: 0.0702\n",
      "Epoch [3/5], Step [70/207], Loss: 0.1410\n",
      "Epoch [3/5], Step [80/207], Loss: 0.0781\n",
      "Epoch [3/5], Step [90/207], Loss: 0.1497\n",
      "Epoch [3/5], Step [100/207], Loss: 0.1475\n",
      "Epoch [3/5], Step [110/207], Loss: 0.0772\n",
      "Epoch [3/5], Step [120/207], Loss: 0.0586\n",
      "Epoch [3/5], Step [130/207], Loss: 0.2817\n",
      "Epoch [3/5], Step [140/207], Loss: 0.0601\n",
      "Epoch [3/5], Step [150/207], Loss: 0.0551\n",
      "Epoch [3/5], Step [160/207], Loss: 0.1900\n",
      "Epoch [3/5], Step [170/207], Loss: 0.1474\n",
      "Epoch [3/5], Step [180/207], Loss: 0.1029\n",
      "Epoch [3/5], Step [190/207], Loss: 0.1069\n",
      "Epoch [3/5], Step [200/207], Loss: 0.0386\n",
      "Epoch [4/5], Step [10/207], Loss: 0.0265\n",
      "Epoch [4/5], Step [20/207], Loss: 0.0360\n",
      "Epoch [4/5], Step [30/207], Loss: 0.1702\n",
      "Epoch [4/5], Step [40/207], Loss: 0.0435\n",
      "Epoch [4/5], Step [50/207], Loss: 0.1077\n",
      "Epoch [4/5], Step [60/207], Loss: 0.0263\n",
      "Epoch [4/5], Step [70/207], Loss: 0.0340\n",
      "Epoch [4/5], Step [80/207], Loss: 0.1041\n",
      "Epoch [4/5], Step [90/207], Loss: 0.0388\n",
      "Epoch [4/5], Step [100/207], Loss: 0.0239\n",
      "Epoch [4/5], Step [110/207], Loss: 0.1399\n",
      "Epoch [4/5], Step [120/207], Loss: 0.0134\n",
      "Epoch [4/5], Step [130/207], Loss: 0.0276\n",
      "Epoch [4/5], Step [140/207], Loss: 0.0365\n",
      "Epoch [4/5], Step [150/207], Loss: 0.2289\n",
      "Epoch [4/5], Step [160/207], Loss: 0.1260\n",
      "Epoch [4/5], Step [170/207], Loss: 0.0966\n",
      "Epoch [4/5], Step [180/207], Loss: 0.0596\n",
      "Epoch [4/5], Step [190/207], Loss: 0.0876\n",
      "Epoch [4/5], Step [200/207], Loss: 0.2628\n",
      "Epoch [5/5], Step [10/207], Loss: 0.0518\n",
      "Epoch [5/5], Step [20/207], Loss: 0.1604\n",
      "Epoch [5/5], Step [30/207], Loss: 0.0320\n",
      "Epoch [5/5], Step [40/207], Loss: 0.0286\n",
      "Epoch [5/5], Step [50/207], Loss: 0.0375\n",
      "Epoch [5/5], Step [60/207], Loss: 0.0836\n",
      "Epoch [5/5], Step [70/207], Loss: 0.0186\n",
      "Epoch [5/5], Step [80/207], Loss: 0.0526\n",
      "Epoch [5/5], Step [90/207], Loss: 0.0181\n",
      "Epoch [5/5], Step [100/207], Loss: 0.0791\n",
      "Epoch [5/5], Step [110/207], Loss: 0.0664\n",
      "Epoch [5/5], Step [120/207], Loss: 0.0566\n",
      "Epoch [5/5], Step [130/207], Loss: 0.1327\n",
      "Epoch [5/5], Step [140/207], Loss: 0.0268\n",
      "Epoch [5/5], Step [150/207], Loss: 0.0820\n",
      "Epoch [5/5], Step [160/207], Loss: 0.0361\n",
      "Epoch [5/5], Step [170/207], Loss: 0.0571\n",
      "Epoch [5/5], Step [180/207], Loss: 0.0288\n",
      "Epoch [5/5], Step [190/207], Loss: 0.2377\n",
      "Epoch [5/5], Step [200/207], Loss: 0.0281\n",
      "Accuracy of the network: 96.66666666666667 %\n",
      "Accuracy of Normal: 94.09836065573771 %\n",
      "Accuracy of Tuberculosis: 99.32203389830508 %\n",
      "Batch Size:  32\n",
      "Epoch [1/5], Step [10/104], Loss: 0.5981\n",
      "Epoch [1/5], Step [20/104], Loss: 0.5618\n",
      "Epoch [1/5], Step [30/104], Loss: 0.3991\n",
      "Epoch [1/5], Step [40/104], Loss: 0.3995\n",
      "Epoch [1/5], Step [50/104], Loss: 0.3318\n",
      "Epoch [1/5], Step [60/104], Loss: 0.3741\n",
      "Epoch [1/5], Step [70/104], Loss: 0.3887\n",
      "Epoch [1/5], Step [80/104], Loss: 0.2720\n",
      "Epoch [1/5], Step [90/104], Loss: 0.2077\n",
      "Epoch [1/5], Step [100/104], Loss: 0.3090\n",
      "Epoch [2/5], Step [10/104], Loss: 0.3317\n",
      "Epoch [2/5], Step [20/104], Loss: 0.2260\n",
      "Epoch [2/5], Step [30/104], Loss: 0.3263\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Experiment with various batch sizes for LeNet5 with epoch = 5\n",
    "\n",
    "\n",
    "for bs in [16, 32, 64]:\n",
    "    print(\"Batch Size: \", bs)\n",
    "    train_loader =  torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True)\n",
    "    test_loader =  torch.utils.data.DataLoader(testset, batch_size=bs, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(valset, batch_size=bs, shuffle=True)\n",
    "    model = LeNet5()\n",
    "    train_by_model(model, model_name, 5)\n",
    "    acc_of_model_batch[model_name][bs] = get_acc_from_data(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec8d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Batch Size that gives highest accuracy\n",
    "\n",
    "# model_name = \"LeNet5\"\n",
    "# max_acc_bat = 16\n",
    "# max_acc = acc_of_model_batch[model_name][max_acc_epo]\n",
    "# for bat in acc_of_model_batch[model_name]:\n",
    "#     if max_acc < acc_of_model_batch[model_name][bat]:\n",
    "#         max_acc = acc_of_model_batch[model_name][bat]\n",
    "#         max_acc_bat = bat \n",
    "\n",
    "# print(\"Maximum accuracy is \", max_acc, \" with epoch as \", max_acc_epo)\n",
    "\n",
    "print(\"Upon analyzing the runtime and accuracy of data we took the following parameters forward\")\n",
    "print(\"Batch Size: 32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454e917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "train_loader =  torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader =  torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = LeNet5()\n",
    "model_name = \"LeNet5\"\n",
    "\n",
    "losses = train_by_model(model, model_name, args.num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085abeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc_from_data(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2363dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc_from_data(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c523b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
