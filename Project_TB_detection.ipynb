{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff1ede8c",
   "metadata": {},
   "source": [
    "# ECE 228 Project\n",
    "## Tuberculosis Detection | Team 26\n",
    "### Jianyu Tao\n",
    "### Shreyas Borse\n",
    "### Harshit Bhadani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89309d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version 1.11.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "## Importing modules for necessary operations\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pdb\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import argparse\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print('Using PyTorch version', torch.__version__)\n",
    "\n",
    "\n",
    "from os.path import isfile\n",
    "from os import rename\n",
    "SMOOTH=1\n",
    "import pdb\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from PIL.ImageFilter import GaussianBlur\n",
    "\n",
    "# import pdb\n",
    "from numpy import pi as PI\n",
    "from numpy import sqrt\n",
    "from scipy.special import comb\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0be2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscellaneous initialization\n",
    "torch.manual_seed(1)\n",
    "start_time = time.time()\n",
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0d5de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"\"\n",
    "test_dataset_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fc58232",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/Users/harshitb/Desktop/Studies/ECE 228/TB_dataset/TB_Chest_Radiography_Database\"\n",
    "class_names = ['Normal', 'Tuberculosis']\n",
    "source_dirs = ['Normal', 'Tuberculosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "930810b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.add_argument('--num_epochs', type=int, default=5, help='Number of training epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='Batch size')\n",
    "parser.add_argument('--lr', type=float, default=5e-4, help='Learning rate')\n",
    "parser.add_argument('--l2', type=float, default=0, help='L2 regularisation')\n",
    "parser.add_argument('--aug', action='store_true', default=False, help='Use data augmentation')\n",
    "parser.add_argument('--data_path', type=str, default=root_dir,help='Path to data.')\n",
    "parser.add_argument('--bond_dim', type=int, default=5, help='MPS Bond dimension')\n",
    "parser.add_argument('--nChannel', type=int, default=1, help='Number of input channels')\n",
    "parser.add_argument('--dense_net', action='store_true', default=False, help='Using Dense Net model')\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "684a5c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = args.batch_size\n",
    "\n",
    "# LoTeNet parameters\n",
    "adaptive_mode = False \n",
    "periodic_bc   = False\n",
    "\n",
    "kernel = 2 # Stride along spatial dimensions\n",
    "output_dim = 1 # output dimension\n",
    " \n",
    "feature_dim = 2\n",
    "\n",
    "normTensor = 0.5*torch.ones(args.nChannel)\n",
    "### Data processing and loading....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a61e98b",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc2837a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data processing and loading....\n",
    "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.Resize(size=(256,256)),\n",
    "#                                       transforms.RandomVerticalFlip(),\n",
    "#                                       transforms.RandomRotation(20),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=normTensor,std=normTensor)])\n",
    "\n",
    "valid_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size=(256,256)),\n",
    "#     torchvision.transforms.RandomHorizontalFlip(),\n",
    "#     torchvision.transforms.RandomRotation(20),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=normTensor,std=normTensor)\n",
    "    #torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1abf12",
   "metadata": {},
   "source": [
    "### Creating Datasets classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a87dbe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXRayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_dirs,transform):\n",
    "        def get_images(class_name):\n",
    "            images = [x for x in os.listdir(image_dirs[class_name]) if x.lower().endswith('png')]\n",
    "            print(f'Found {len(images)}{class_name}')\n",
    "            return images\n",
    "        self.images={}\n",
    "        self.class_names=['Normal', 'Tuberculosis']\n",
    "        for c in self.class_names:\n",
    "            self.images[c]=get_images(c)\n",
    "        self.image_dirs=image_dirs\n",
    "        self.transform=transform\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return sum([len(self.images[c]) for c in self.class_names])\n",
    "    def __getitem__(self, index):\n",
    "        class_name=random.choice(self.class_names)\n",
    "        index=index%len(self.images[class_name])\n",
    "        image_name=self.images[class_name][index]\n",
    "        image_path =os.path.join(self.image_dirs[class_name], image_name)\n",
    "        image=Image.open(image_path).convert('L')\n",
    "        return self.transform(image), self.class_names.index(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56fa2063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3500Normal\n",
      "Found 700Tuberculosis\n"
     ]
    }
   ],
   "source": [
    "train_dirs = {\n",
    "    'Normal': root_dir + '/Normal',\n",
    "    'Tuberculosis': root_dir + '/Tuberculosis'\n",
    "}\n",
    "dataset = ChestXRayDataset(train_dirs, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbe34a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset, valset = random_split(dataset, [3300, 600, 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1288b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader =  torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader =  torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8fa93a",
   "metadata": {},
   "source": [
    "# Creating various architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "966057cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        #         xl = 1\n",
    "        #         for i in x.shape[1:]: xl *= i\n",
    "        #         self.fc1 = nn.Linear(13456, 120)\n",
    "        self.fc1 = nn.Linear(984064, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        #         x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
    "        #         x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv1(x))  # -> n, 6, 14, 14\n",
    "        x = F.relu(self.conv2(x))\n",
    "        xl = 1\n",
    "        for i in x.shape[1:]: xl *= i\n",
    "        x = x.view(-1, xl)            # \n",
    "        x = F.relu(self.fc1(x))               # -> n, 120\n",
    "        x = F.relu(self.fc2(x))               # -> n, 84\n",
    "        x = self.fc3(x)                       # -> n, 2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a40b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the convolutional neural network\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Linear(59536, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddf655a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.conv1_1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv4_1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv5_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(32768, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv5_1(x))\n",
    "        x = F.relu(self.conv5_2(x))\n",
    "        x = F.relu(self.conv5_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "#         print(\"HERE ... \", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, 0.5) #dropout was included to combat overfitting\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, 0.5)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88249028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising variable that will be used in the experiments in the project\n",
    "\n",
    "loss_data_of_model_epoch = {}\n",
    "acc_of_model_epoch = {}\n",
    "acc_of_model_batch = {}\n",
    "\n",
    "all_models = {}\n",
    "all_models['ConvNet'] = ConvNet()\n",
    "all_models['LeNet5']  = LeNet5()\n",
    "all_models['VGG16']   = VGG16()\n",
    "\n",
    "for model_name in all_models.keys():\n",
    "    loss_data_of_model_epoch[model_name] = {}\n",
    "    acc_of_model_epoch[model_name] = {}\n",
    "    acc_of_model_batch[model_name] = {}\n",
    "\n",
    "LeNet5_model_with_epoch = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab437e84",
   "metadata": {},
   "source": [
    "# Defining various functions to make the code modular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bd40115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_from_data(d_loader):\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        n_class_correct = [0 for i in range(2)]\n",
    "        n_class_samples = [0 for i in range(2)]\n",
    "        for images, labels in d_loader:\n",
    "            #         print(len(labels))\n",
    "            outputs = model(images)\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                pred = predicted[i]\n",
    "                if (label == pred):\n",
    "                    n_class_correct[label] += 1\n",
    "                n_class_samples[label] += 1\n",
    "\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network: {acc} %')\n",
    "        \n",
    "        all_acc = []\n",
    "        overall_accuracy = acc\n",
    "        all_acc.append(overall_accuracy)\n",
    "\n",
    "        for i in range(2):\n",
    "            acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "            print(f'Accuracy of {class_names[i]}: {acc} %')\n",
    "            all_acc.append(acc)\n",
    "                \n",
    "    #return all_acc\n",
    "    return overall_accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b1e415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_by_model(model, model_name, epo = 3, verbose = True):\n",
    "    args.num_epochs = epo\n",
    "    learning_rate = 0.001\n",
    "    all_loss = []\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    n_total_steps = len(train_loader)\n",
    "    for epoch in range(args.num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            all_loss.append(loss.item())\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if ((i+1) % 10 == 0) and verbose:\n",
    "                print (f'Epoch [{epoch+1}/{args.num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "        LeNet5_model_with_epoch[epoch+1] = copy.deepcopy(model)\n",
    "        \n",
    "    return all_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb0a14",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f57aec",
   "metadata": {},
   "source": [
    "### Experiment: Deciding Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5446561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [10/104], Loss: 0.1378\n",
      "Epoch [1/3], Step [20/104], Loss: 0.0541\n",
      "Epoch [1/3], Step [30/104], Loss: 0.1998\n",
      "Epoch [1/3], Step [40/104], Loss: 0.0948\n",
      "Epoch [1/3], Step [50/104], Loss: 0.2272\n",
      "Epoch [1/3], Step [60/104], Loss: 0.0910\n",
      "Epoch [1/3], Step [70/104], Loss: 0.1483\n",
      "Epoch [1/3], Step [80/104], Loss: 0.1670\n",
      "Epoch [1/3], Step [90/104], Loss: 0.0980\n",
      "Epoch [1/3], Step [100/104], Loss: 0.1897\n",
      "Epoch [2/3], Step [10/104], Loss: 0.0874\n",
      "Epoch [2/3], Step [20/104], Loss: 0.0868\n",
      "Epoch [2/3], Step [30/104], Loss: 0.1110\n",
      "Epoch [2/3], Step [40/104], Loss: 0.1992\n",
      "Epoch [2/3], Step [50/104], Loss: 0.0814\n",
      "Epoch [2/3], Step [60/104], Loss: 0.3178\n",
      "Epoch [2/3], Step [70/104], Loss: 0.0554\n",
      "Epoch [2/3], Step [80/104], Loss: 0.0304\n",
      "Epoch [2/3], Step [90/104], Loss: 0.1781\n",
      "Epoch [2/3], Step [100/104], Loss: 0.0558\n",
      "Epoch [3/3], Step [10/104], Loss: 0.1445\n",
      "Epoch [3/3], Step [20/104], Loss: 0.0854\n",
      "Epoch [3/3], Step [30/104], Loss: 0.0790\n",
      "Epoch [3/3], Step [40/104], Loss: 0.0811\n",
      "Epoch [3/3], Step [50/104], Loss: 0.0900\n",
      "Epoch [3/3], Step [60/104], Loss: 0.1753\n",
      "Epoch [3/3], Step [70/104], Loss: 0.0478\n",
      "Epoch [3/3], Step [80/104], Loss: 0.0533\n",
      "Epoch [3/3], Step [90/104], Loss: 0.0588\n",
      "Epoch [3/3], Step [100/104], Loss: 0.0352\n",
      "Accuracy of the network: 97.0 %\n",
      "Accuracy of Normal: 97.32441471571906 %\n",
      "Accuracy of Tuberculosis: 96.67774086378738 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "97.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking various architectures above one by one with epoch = 3\n",
    "\n",
    "model_name = \"LeNet5\"\n",
    "model = all_models[model_name]\n",
    "\n",
    "train_by_model(model, model_name)\n",
    "get_acc_from_data(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e87e940",
   "metadata": {},
   "source": [
    "### Experiment: Deciding epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75599bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating accuracy of model with epoch:  1\n",
      "Accuracy of the network: 87.0 %\n",
      "Accuracy of Normal: 94.42508710801394 %\n",
      "Accuracy of Tuberculosis: 80.19169329073482 %\n",
      "Calculating accuracy of model with epoch:  2\n",
      "Accuracy of the network: 92.16666666666667 %\n",
      "Accuracy of Normal: 92.5925925925926 %\n",
      "Accuracy of Tuberculosis: 91.74917491749174 %\n",
      "Calculating accuracy of model with epoch:  3\n",
      "Accuracy of the network: 92.66666666666667 %\n",
      "Accuracy of Normal: 89.7196261682243 %\n",
      "Accuracy of Tuberculosis: 96.05734767025089 %\n",
      "Calculating accuracy of model with epoch:  4\n",
      "Accuracy of the network: 93.66666666666667 %\n",
      "Accuracy of Normal: 96.19047619047619 %\n",
      "Accuracy of Tuberculosis: 90.87719298245614 %\n",
      "Calculating accuracy of model with epoch:  5\n",
      "Accuracy of the network: 95.33333333333333 %\n",
      "Accuracy of Normal: 93.38235294117646 %\n",
      "Accuracy of Tuberculosis: 96.95121951219512 %\n",
      "Calculating accuracy of model with epoch:  6\n",
      "Accuracy of the network: 94.83333333333333 %\n",
      "Accuracy of Normal: 95.20547945205479 %\n",
      "Accuracy of Tuberculosis: 94.48051948051948 %\n",
      "Calculating accuracy of model with epoch:  7\n",
      "Accuracy of the network: 94.83333333333333 %\n",
      "Accuracy of Normal: 92.78996865203762 %\n",
      "Accuracy of Tuberculosis: 97.15302491103203 %\n",
      "Calculating accuracy of model with epoch:  8\n",
      "Accuracy of the network: 95.5 %\n",
      "Accuracy of Normal: 96.94915254237289 %\n",
      "Accuracy of Tuberculosis: 94.09836065573771 %\n",
      "Calculating accuracy of model with epoch:  9\n",
      "Accuracy of the network: 97.5 %\n",
      "Accuracy of Normal: 96.05263157894737 %\n",
      "Accuracy of Tuberculosis: 98.98648648648648 %\n",
      "Calculating accuracy of model with epoch:  10\n",
      "Accuracy of the network: 97.16666666666667 %\n",
      "Accuracy of Normal: 96.45161290322581 %\n",
      "Accuracy of Tuberculosis: 97.93103448275862 %\n",
      "Calculating accuracy of model with epoch:  11\n",
      "Accuracy of the network: 96.66666666666667 %\n",
      "Accuracy of Normal: 96.61016949152543 %\n",
      "Accuracy of Tuberculosis: 96.72131147540983 %\n",
      "Calculating accuracy of model with epoch:  12\n",
      "Accuracy of the network: 98.33333333333333 %\n",
      "Accuracy of Normal: 97.82608695652173 %\n",
      "Accuracy of Tuberculosis: 98.92086330935251 %\n",
      "Calculating accuracy of model with epoch:  13\n",
      "Accuracy of the network: 92.83333333333333 %\n",
      "Accuracy of Normal: 98.95104895104895 %\n",
      "Accuracy of Tuberculosis: 87.26114649681529 %\n",
      "Calculating accuracy of model with epoch:  14\n",
      "Accuracy of the network: 98.33333333333333 %\n",
      "Accuracy of Normal: 97.26027397260275 %\n",
      "Accuracy of Tuberculosis: 99.35064935064935 %\n",
      "Calculating accuracy of model with epoch:  15\n",
      "Accuracy of the network: 97.83333333333333 %\n",
      "Accuracy of Normal: 96.36963696369637 %\n",
      "Accuracy of Tuberculosis: 99.32659932659932 %\n",
      "Maximum accuracy is  98.33333333333333  with epoch as  12\n",
      "CPU times: user 27min 40s, sys: 12.9 s, total: 27min 53s\n",
      "Wall time: 22min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7f90ab84f0>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "# Accuracy for LeNet5 with various epoch\n",
    "\n",
    "model = LeNet5()\n",
    "model_name = \"LeNet5\"\n",
    "\n",
    "losses = train_by_model(model, model_name, 15, verbose = False)\n",
    "\n",
    "accs = {}\n",
    "for epo in LeNet5_model_with_epoch:\n",
    "    print(\"Calculating accuracy of model with epoch: \", epo)\n",
    "    model = LeNet5_model_with_epoch[epo]\n",
    "    acc = get_acc_from_data(test_loader)\n",
    "    accs[epo] = acc\n",
    "\n",
    "acc_of_model_epoch[model_name] = accs\n",
    "\n",
    "# -----------------------------------------------------\n",
    "import json\n",
    "with open('loss_data_of_model_epoch.json', 'w') as fp:\n",
    "    json.dump(loss_data_of_model_epoch, fp)\n",
    "    \n",
    "with open('acc_of_model_epoch.json', 'w') as fp:\n",
    "    json.dump(acc_of_model_epoch, fp)\n",
    "# -----------------------------------------------------\n",
    "\n",
    "model_name = \"LeNet5\"\n",
    "max_acc_epo = 1\n",
    "max_acc = acc_of_model_epoch[model_name][max_acc_epo]\n",
    "for epo in acc_of_model_epoch[model_name]:\n",
    "    if max_acc < acc_of_model_epoch[model_name][epo]:\n",
    "        max_acc = acc_of_model_epoch[model_name][epo]\n",
    "        max_acc_epo = epo\n",
    "\n",
    "print(\"Maximum accuracy is \", max_acc, \" with epoch as \", max_acc_epo)\n",
    "\n",
    "plt.plot(list(accs.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5690e0e5",
   "metadata": {},
   "source": [
    "### Experiment: Deciding batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eadf4150",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size:  16\n",
      "Accuracy of the network: 96.16666666666667 %\n",
      "Accuracy of Normal: 93.99293286219081 %\n",
      "Accuracy of Tuberculosis: 98.10725552050474 %\n",
      "Batch Size:  32\n",
      "Accuracy of the network: 96.16666666666667 %\n",
      "Accuracy of Normal: 95.65217391304348 %\n",
      "Accuracy of Tuberculosis: 96.60493827160494 %\n",
      "Batch Size:  64\n",
      "Accuracy of the network: 94.33333333333333 %\n",
      "Accuracy of Normal: 94.69964664310955 %\n",
      "Accuracy of Tuberculosis: 94.00630914826499 %\n",
      "CPU times: user 25min 32s, sys: 19.7 s, total: 25min 52s\n",
      "Wall time: 21min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Experiment with various batch sizes for LeNet5 with epoch = 5\n",
    "\n",
    "\n",
    "for bs in [16, 32, 64]:\n",
    "    print(\"Batch Size: \", bs)\n",
    "    train_loader =  torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True)\n",
    "    test_loader =  torch.utils.data.DataLoader(testset, batch_size=bs, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(valset, batch_size=bs, shuffle=True)\n",
    "    model = LeNet5()\n",
    "    train_by_model(model, model_name, 5, verbose = False)\n",
    "    acc_of_model_batch[model_name][bs] = get_acc_from_data(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5503525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy is  96.16666666666667  with epoch as  16\n",
      "Upon analyzing the runtime and accuracy of data we took the following parameters forward\n",
      "Batch Size: 32\n"
     ]
    }
   ],
   "source": [
    "# Getting Batch Size that gives highest accuracy\n",
    "\n",
    "model_name = \"LeNet5\"\n",
    "max_acc_bat = 16\n",
    "max_acc = acc_of_model_batch[model_name][max_acc_bat]\n",
    "for bat in acc_of_model_batch[model_name]:\n",
    "    if max_acc < acc_of_model_batch[model_name][bat]:\n",
    "        max_acc = acc_of_model_batch[model_name][bat]\n",
    "        max_acc_bat = bat \n",
    "\n",
    "print(\"Maximum accuracy is \", max_acc, \" with batch size as \", max_acc_bat)\n",
    "\n",
    "print(\"Upon analyzing the runtime and accuracy of data we took the following parameters forward\")\n",
    "print(\"Batch Size: 32\")\n",
    "print(\"32 was taken as it had lesser runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77161340",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "454e917b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/12], Step [10/104], Loss: 0.6191\n",
      "Epoch [1/12], Step [20/104], Loss: 0.5606\n",
      "Epoch [1/12], Step [30/104], Loss: 0.4078\n",
      "Epoch [1/12], Step [40/104], Loss: 0.3709\n",
      "Epoch [1/12], Step [50/104], Loss: 0.4473\n",
      "Epoch [1/12], Step [60/104], Loss: 0.3545\n",
      "Epoch [1/12], Step [70/104], Loss: 0.4041\n",
      "Epoch [1/12], Step [80/104], Loss: 0.1900\n",
      "Epoch [1/12], Step [90/104], Loss: 0.2357\n",
      "Epoch [1/12], Step [100/104], Loss: 0.2593\n",
      "Epoch [2/12], Step [10/104], Loss: 0.2958\n",
      "Epoch [2/12], Step [20/104], Loss: 0.2190\n",
      "Epoch [2/12], Step [30/104], Loss: 0.2317\n",
      "Epoch [2/12], Step [40/104], Loss: 0.1674\n",
      "Epoch [2/12], Step [50/104], Loss: 0.1525\n",
      "Epoch [2/12], Step [60/104], Loss: 0.0860\n",
      "Epoch [2/12], Step [70/104], Loss: 0.2359\n",
      "Epoch [2/12], Step [80/104], Loss: 0.2206\n",
      "Epoch [2/12], Step [90/104], Loss: 0.1535\n",
      "Epoch [2/12], Step [100/104], Loss: 0.1222\n",
      "Epoch [3/12], Step [10/104], Loss: 0.1029\n",
      "Epoch [3/12], Step [20/104], Loss: 0.2905\n",
      "Epoch [3/12], Step [30/104], Loss: 0.2315\n",
      "Epoch [3/12], Step [40/104], Loss: 0.1354\n",
      "Epoch [3/12], Step [50/104], Loss: 0.1070\n",
      "Epoch [3/12], Step [60/104], Loss: 0.1376\n",
      "Epoch [3/12], Step [70/104], Loss: 0.0762\n",
      "Epoch [3/12], Step [80/104], Loss: 0.1417\n",
      "Epoch [3/12], Step [90/104], Loss: 0.1545\n",
      "Epoch [3/12], Step [100/104], Loss: 0.0740\n",
      "Epoch [4/12], Step [10/104], Loss: 0.0794\n",
      "Epoch [4/12], Step [20/104], Loss: 0.1232\n",
      "Epoch [4/12], Step [30/104], Loss: 0.1294\n",
      "Epoch [4/12], Step [40/104], Loss: 0.0924\n",
      "Epoch [4/12], Step [50/104], Loss: 0.0692\n",
      "Epoch [4/12], Step [60/104], Loss: 0.0597\n",
      "Epoch [4/12], Step [70/104], Loss: 0.1280\n",
      "Epoch [4/12], Step [80/104], Loss: 0.0564\n",
      "Epoch [4/12], Step [90/104], Loss: 0.2603\n",
      "Epoch [4/12], Step [100/104], Loss: 0.0757\n",
      "Epoch [5/12], Step [10/104], Loss: 0.1119\n",
      "Epoch [5/12], Step [20/104], Loss: 0.2260\n",
      "Epoch [5/12], Step [30/104], Loss: 0.0696\n",
      "Epoch [5/12], Step [40/104], Loss: 0.0782\n",
      "Epoch [5/12], Step [50/104], Loss: 0.0252\n",
      "Epoch [5/12], Step [60/104], Loss: 0.0665\n",
      "Epoch [5/12], Step [70/104], Loss: 0.0861\n",
      "Epoch [5/12], Step [80/104], Loss: 0.0942\n",
      "Epoch [5/12], Step [90/104], Loss: 0.0536\n",
      "Epoch [5/12], Step [100/104], Loss: 0.0271\n",
      "Epoch [6/12], Step [10/104], Loss: 0.1170\n",
      "Epoch [6/12], Step [20/104], Loss: 0.1884\n",
      "Epoch [6/12], Step [30/104], Loss: 0.0218\n",
      "Epoch [6/12], Step [40/104], Loss: 0.0776\n",
      "Epoch [6/12], Step [50/104], Loss: 0.0619\n",
      "Epoch [6/12], Step [60/104], Loss: 0.0870\n",
      "Epoch [6/12], Step [70/104], Loss: 0.0640\n",
      "Epoch [6/12], Step [80/104], Loss: 0.0518\n",
      "Epoch [6/12], Step [90/104], Loss: 0.0652\n",
      "Epoch [6/12], Step [100/104], Loss: 0.1124\n",
      "Epoch [7/12], Step [10/104], Loss: 0.0709\n",
      "Epoch [7/12], Step [20/104], Loss: 0.0373\n",
      "Epoch [7/12], Step [30/104], Loss: 0.0509\n",
      "Epoch [7/12], Step [40/104], Loss: 0.0809\n",
      "Epoch [7/12], Step [50/104], Loss: 0.0341\n",
      "Epoch [7/12], Step [60/104], Loss: 0.0923\n",
      "Epoch [7/12], Step [70/104], Loss: 0.0618\n",
      "Epoch [7/12], Step [80/104], Loss: 0.1064\n",
      "Epoch [7/12], Step [90/104], Loss: 0.0747\n",
      "Epoch [7/12], Step [100/104], Loss: 0.1349\n",
      "Epoch [8/12], Step [10/104], Loss: 0.0470\n",
      "Epoch [8/12], Step [20/104], Loss: 0.1124\n",
      "Epoch [8/12], Step [30/104], Loss: 0.0357\n",
      "Epoch [8/12], Step [40/104], Loss: 0.0325\n",
      "Epoch [8/12], Step [50/104], Loss: 0.0379\n",
      "Epoch [8/12], Step [60/104], Loss: 0.0503\n",
      "Epoch [8/12], Step [70/104], Loss: 0.1333\n",
      "Epoch [8/12], Step [80/104], Loss: 0.1256\n",
      "Epoch [8/12], Step [90/104], Loss: 0.0293\n",
      "Epoch [8/12], Step [100/104], Loss: 0.0668\n",
      "Epoch [9/12], Step [10/104], Loss: 0.0640\n",
      "Epoch [9/12], Step [20/104], Loss: 0.0275\n",
      "Epoch [9/12], Step [30/104], Loss: 0.0431\n",
      "Epoch [9/12], Step [40/104], Loss: 0.0678\n",
      "Epoch [9/12], Step [50/104], Loss: 0.0690\n",
      "Epoch [9/12], Step [60/104], Loss: 0.0633\n",
      "Epoch [9/12], Step [70/104], Loss: 0.1279\n",
      "Epoch [9/12], Step [80/104], Loss: 0.0652\n",
      "Epoch [9/12], Step [90/104], Loss: 0.0861\n",
      "Epoch [9/12], Step [100/104], Loss: 0.0405\n",
      "Epoch [10/12], Step [10/104], Loss: 0.0238\n",
      "Epoch [10/12], Step [20/104], Loss: 0.0267\n",
      "Epoch [10/12], Step [30/104], Loss: 0.0626\n",
      "Epoch [10/12], Step [40/104], Loss: 0.0226\n",
      "Epoch [10/12], Step [50/104], Loss: 0.0285\n",
      "Epoch [10/12], Step [60/104], Loss: 0.0535\n",
      "Epoch [10/12], Step [70/104], Loss: 0.0243\n",
      "Epoch [10/12], Step [80/104], Loss: 0.0389\n",
      "Epoch [10/12], Step [90/104], Loss: 0.0636\n",
      "Epoch [10/12], Step [100/104], Loss: 0.0860\n",
      "Epoch [11/12], Step [10/104], Loss: 0.0641\n",
      "Epoch [11/12], Step [20/104], Loss: 0.0742\n",
      "Epoch [11/12], Step [30/104], Loss: 0.1773\n",
      "Epoch [11/12], Step [40/104], Loss: 0.0901\n",
      "Epoch [11/12], Step [50/104], Loss: 0.0547\n",
      "Epoch [11/12], Step [60/104], Loss: 0.0452\n",
      "Epoch [11/12], Step [70/104], Loss: 0.1685\n",
      "Epoch [11/12], Step [80/104], Loss: 0.0256\n",
      "Epoch [11/12], Step [90/104], Loss: 0.0888\n",
      "Epoch [11/12], Step [100/104], Loss: 0.0780\n",
      "Epoch [12/12], Step [10/104], Loss: 0.1391\n",
      "Epoch [12/12], Step [20/104], Loss: 0.0926\n",
      "Epoch [12/12], Step [30/104], Loss: 0.0242\n",
      "Epoch [12/12], Step [40/104], Loss: 0.0386\n",
      "Epoch [12/12], Step [50/104], Loss: 0.0815\n",
      "Epoch [12/12], Step [60/104], Loss: 0.0566\n",
      "Epoch [12/12], Step [70/104], Loss: 0.1138\n",
      "Epoch [12/12], Step [80/104], Loss: 0.0336\n",
      "Epoch [12/12], Step [90/104], Loss: 0.0561\n",
      "Epoch [12/12], Step [100/104], Loss: 0.0680\n"
     ]
    }
   ],
   "source": [
    "args.num_epochs = 12\n",
    "batch_size = 32\n",
    "\n",
    "train_loader =  torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader =  torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = LeNet5()\n",
    "model_name = \"LeNet5\"\n",
    "\n",
    "losses = train_by_model(model, model_name, args.num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "085abeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 98.0 %\n",
      "Accuracy of Normal: 96.27118644067797 %\n",
      "Accuracy of Tuberculosis: 99.67213114754098 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_acc_from_data(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2363dbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 98.33333333333333 %\n",
      "Accuracy of Normal: 97.5 %\n",
      "Accuracy of Tuberculosis: 99.28571428571429 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98.33333333333333"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_acc_from_data(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c523b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
