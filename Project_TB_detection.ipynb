{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff1ede8c",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89309d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version 1.11.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pdb\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import argparse\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print('Using PyTorch version', torch.__version__)\n",
    "\n",
    "\n",
    "from os.path import isfile\n",
    "from os import rename\n",
    "SMOOTH=1\n",
    "import pdb\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from PIL.ImageFilter import GaussianBlur\n",
    "\n",
    "# import pdb\n",
    "from numpy import pi as PI\n",
    "from numpy import sqrt\n",
    "from scipy.special import comb\n",
    "import math\n",
    "# tensorflow libraries\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5c46b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch res, res101..\n",
    "\n",
    "# Tying papers -> Take inputs from the papers and comparision\n",
    "# Implementing. LeNet\n",
    "# EDA. More about Dataset\n",
    "# Data Augmentation -> Its Benifits\n",
    "# Can use different dataset on top of this\n",
    "# Loss plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0be2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscellaneous initialization\n",
    "torch.manual_seed(1)\n",
    "start_time = time.time()\n",
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0d5de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"\"\n",
    "test_dataset_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fc58232",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/Users/harshitb/Desktop/Studies/ECE 228/TB_dataset/TB_Chest_Radiography_Database\"\n",
    "class_names = ['Normal', 'Tuberculosis']\n",
    "source_dirs = ['Normal', 'Tuberculosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "930810b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.add_argument('--num_epochs', type=int, default=5, help='Number of training epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='Batch size')\n",
    "parser.add_argument('--lr', type=float, default=5e-4, help='Learning rate')\n",
    "parser.add_argument('--l2', type=float, default=0, help='L2 regularisation')\n",
    "parser.add_argument('--aug', action='store_true', default=False, help='Use data augmentation')\n",
    "parser.add_argument('--data_path', type=str, default=root_dir,help='Path to data.')\n",
    "parser.add_argument('--bond_dim', type=int, default=5, help='MPS Bond dimension')\n",
    "parser.add_argument('--nChannel', type=int, default=1, help='Number of input channels')\n",
    "parser.add_argument('--dense_net', action='store_true', default=False, help='Using Dense Net model')\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "684a5c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = args.batch_size\n",
    "\n",
    "# LoTeNet parameters\n",
    "adaptive_mode = False \n",
    "periodic_bc   = False\n",
    "\n",
    "kernel = 2 # Stride along spatial dimensions\n",
    "output_dim = 1 # output dimension\n",
    " \n",
    "feature_dim = 2\n",
    "\n",
    "#logFile = time.strftime(\"%Y%m%d_%H_%M\")+'.txt'\n",
    "#makeLogFile(logFile)\n",
    "\n",
    "normTensor = 0.5*torch.ones(args.nChannel)\n",
    "### Data processing and loading....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc2837a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data processing and loading....\n",
    "# mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225]\n",
    "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.Resize(size=(256,256)),\n",
    "#                                       transforms.RandomVerticalFlip(),\n",
    "#                                       transforms.RandomRotation(20),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=normTensor,std=normTensor)])\n",
    "\n",
    "valid_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size=(256,256)),\n",
    "#     torchvision.transforms.RandomHorizontalFlip(),\n",
    "#     torchvision.transforms.RandomRotation(20),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=normTensor,std=normTensor)\n",
    "    #torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a87dbe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXRayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_dirs,transform):\n",
    "        def get_images(class_name):\n",
    "            images = [x for x in os.listdir(image_dirs[class_name]) if x.lower().endswith('png')]\n",
    "            print(f'Found {len(images)}{class_name}')\n",
    "            return images\n",
    "        self.images={}\n",
    "        self.class_names=['Normal', 'Tuberculosis']\n",
    "        for c in self.class_names:\n",
    "            self.images[c]=get_images(c)\n",
    "        self.image_dirs=image_dirs\n",
    "        self.transform=transform\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return sum([len(self.images[c]) for c in self.class_names])\n",
    "    def __getitem__(self, index):\n",
    "        class_name=random.choice(self.class_names)\n",
    "        index=index%len(self.images[class_name])\n",
    "        image_name=self.images[class_name][index]\n",
    "        image_path =os.path.join(self.image_dirs[class_name], image_name)\n",
    "        image=Image.open(image_path).convert('L')\n",
    "        return self.transform(image), self.class_names.index(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56fa2063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3500Normal\n",
      "Found 700Tuberculosis\n"
     ]
    }
   ],
   "source": [
    "train_dirs = {\n",
    "    'Normal': root_dir + '/Normal',\n",
    "    'Tuberculosis': root_dir + '/Tuberculosis'\n",
    "}\n",
    "dataset = ChestXRayDataset(train_dirs, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6795fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,l = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfaf2476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbe34a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset, valset = random_split(dataset, [3300, 600, 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1288b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader =  torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader =  torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74cad098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.num_epochs = 3\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48c9cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = args.num_epochs\n",
    "# total_samples = 3500\n",
    "# n_iterations = math.ceil(total_samples/batch_size)\n",
    "# for epoch in range(args.num_epochs):\n",
    "#     for i, (inputs, labels) in enumerate(train_loader):\n",
    "#         if (i+1) % 10 == 0:\n",
    "#             print(f'Epoch: {epoch+1}/{num_epochs}, \\\n",
    "#                     Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22a839de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = inputs\n",
    "\n",
    "# conv1 = nn.Conv2d(1, 6, 5)\n",
    "# x = conv1(x)\n",
    "# print(\"C1: \", x.shape)\n",
    "\n",
    "# # pool = nn.MaxPool2d(2, 2)\n",
    "# # x = pool(x)\n",
    "# # print(\"P1: \", x.shape)\n",
    "\n",
    "# conv2 = nn.Conv2d(6, 16, 5)\n",
    "# x = conv2(x)\n",
    "# print(\"C2: \", x.shape)\n",
    "\n",
    "# # x = pool(x)\n",
    "# # print(\"P1: \", x.shape)\n",
    "\n",
    "# xl = 1\n",
    "# for i in x.shape[1:]: xl *= i\n",
    "# print(xl)\n",
    "# fc1 = nn.Linear(xl, 120)\n",
    "# x = x.view(-1, xl) \n",
    "# x = fc1(x)\n",
    "# print(\"F1: \", x.shape)\n",
    "\n",
    "# # self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "# # self.fc2 = nn.Linear(120, 84)\n",
    "# # self.fc3 = nn.Linear(84, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "966057cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        #         xl = 1\n",
    "        #         for i in x.shape[1:]: xl *= i\n",
    "        #         self.fc1 = nn.Linear(13456, 120)\n",
    "        self.fc1 = nn.Linear(984064, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        #         x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
    "        #         x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv1(x))  # -> n, 6, 14, 14\n",
    "        x = F.relu(self.conv2(x))\n",
    "        xl = 1\n",
    "        for i in x.shape[1:]: xl *= i\n",
    "        x = x.view(-1, xl)            # \n",
    "        x = F.relu(self.fc1(x))               # -> n, 120\n",
    "        x = F.relu(self.fc2(x))               # -> n, 84\n",
    "        x = self.fc3(x)                       # -> n, 2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a40b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the convolutional neural network\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Linear(59536, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddf655a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.conv1_1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv4_1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv5_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(32768, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv5_1(x))\n",
    "        x = F.relu(self.conv5_2(x))\n",
    "        x = F.relu(self.conv5_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "#         print(\"HERE ... \", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, 0.5) #dropout was included to combat overfitting\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, 0.5)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c452716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = inputs\n",
    "\n",
    "# layer1 = nn.Sequential(\n",
    "#     nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "#     nn.BatchNorm2d(6),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "# x = layer1(x)\n",
    "# print(\"L1: \", x.shape)\n",
    "\n",
    "# layer2 = nn.Sequential(\n",
    "#     nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "#     nn.BatchNorm2d(16),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "# x = layer2(x)\n",
    "# print(\"L2: \", x.shape)\n",
    "\n",
    "# fc = nn.Linear(22326, 120)\n",
    "# relu = nn.ReLU()\n",
    "# fc1 = nn.Linear(120, 84)\n",
    "# relu1 = nn.ReLU()\n",
    "# fc2 = nn.Linear(84, 2)\n",
    "\n",
    "# x = x.reshape(x.size(0), -1)\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88249028",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_data_of_model_epoch = {}\n",
    "acc_of_model_epoch = {}\n",
    "acc_of_model_batch = {}\n",
    "\n",
    "all_models = {}\n",
    "all_models['ConvNet'] = ConvNet()\n",
    "all_models['LeNet5']  = LeNet5()\n",
    "all_models['VGG16']   = VGG16()\n",
    "\n",
    "for model_name in all_models.keys():\n",
    "    loss_data_of_model_epoch[model_name] = {}\n",
    "    acc_of_model_epoch[model_name] = {}\n",
    "    acc_of_model_batch[model_name] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bd40115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_from_data(d_loader):\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        n_class_correct = [0 for i in range(2)]\n",
    "        n_class_samples = [0 for i in range(2)]\n",
    "        for images, labels in d_loader:\n",
    "            #         print(len(labels))\n",
    "            outputs = model(images)\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                pred = predicted[i]\n",
    "                if (label == pred):\n",
    "                    n_class_correct[label] += 1\n",
    "                n_class_samples[label] += 1\n",
    "\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network: {acc} %')\n",
    "        \n",
    "        overall_accuracy = acc\n",
    "\n",
    "        for i in range(2):\n",
    "            acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "            print(f'Accuracy of {class_names[i]}: {acc} %')\n",
    "                \n",
    "    return overall_accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc62586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b1e415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_by_model(model, model_name, epo = 3):\n",
    "    args.num_epochs = epo\n",
    "    learning_rate = 0.001\n",
    "    all_loss = []\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    n_total_steps = len(train_loader)\n",
    "    for epoch in range(args.num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            all_loss.append(loss.item())\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 10 == 0:\n",
    "                print (f'Epoch [{epoch+1}/{args.num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "    return all_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aa1a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5446561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75599bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [10/104], Loss: 0.6099\n",
      "Epoch [1/1], Step [20/104], Loss: 0.6002\n",
      "Epoch [1/1], Step [30/104], Loss: 0.5000\n",
      "Epoch [1/1], Step [40/104], Loss: 0.4820\n",
      "Epoch [1/1], Step [50/104], Loss: 0.4082\n",
      "Epoch [1/1], Step [60/104], Loss: 0.3592\n",
      "Epoch [1/1], Step [70/104], Loss: 0.3478\n",
      "Epoch [1/1], Step [80/104], Loss: 0.4887\n",
      "Epoch [1/1], Step [90/104], Loss: 0.4300\n",
      "Epoch [1/1], Step [100/104], Loss: 0.4713\n",
      "Epoch done:  2  Calculating accuracy\n",
      "Accuracy of the network: 87.0 %\n",
      "Accuracy of Normal: 94.65648854961832 %\n",
      "Accuracy of Tuberculosis: 81.06508875739645 %\n",
      "Epoch [1/2], Step [10/104], Loss: 0.6367\n",
      "Epoch [1/2], Step [20/104], Loss: 0.6151\n",
      "Epoch [1/2], Step [30/104], Loss: 0.4790\n",
      "Epoch [1/2], Step [40/104], Loss: 0.4428\n",
      "Epoch [1/2], Step [50/104], Loss: 0.4681\n",
      "Epoch [1/2], Step [60/104], Loss: 0.3934\n",
      "Epoch [1/2], Step [70/104], Loss: 0.4032\n",
      "Epoch [1/2], Step [80/104], Loss: 0.3950\n",
      "Epoch [1/2], Step [90/104], Loss: 0.2425\n",
      "Epoch [1/2], Step [100/104], Loss: 0.3901\n",
      "Epoch [2/2], Step [10/104], Loss: 0.3502\n",
      "Epoch [2/2], Step [20/104], Loss: 0.3362\n",
      "Epoch [2/2], Step [30/104], Loss: 0.2535\n",
      "Epoch [2/2], Step [40/104], Loss: 0.2101\n",
      "Epoch [2/2], Step [50/104], Loss: 0.2010\n",
      "Epoch [2/2], Step [60/104], Loss: 0.2482\n",
      "Epoch [2/2], Step [70/104], Loss: 0.2309\n",
      "Epoch [2/2], Step [80/104], Loss: 0.1985\n",
      "Epoch [2/2], Step [90/104], Loss: 0.2584\n",
      "Epoch [2/2], Step [100/104], Loss: 0.3366\n",
      "Epoch done:  3  Calculating accuracy\n",
      "Accuracy of the network: 94.0 %\n",
      "Accuracy of Normal: 93.24324324324324 %\n",
      "Accuracy of Tuberculosis: 94.73684210526316 %\n",
      "Epoch [1/3], Step [10/104], Loss: 0.6397\n",
      "Epoch [1/3], Step [20/104], Loss: 0.5496\n",
      "Epoch [1/3], Step [30/104], Loss: 0.4447\n",
      "Epoch [1/3], Step [40/104], Loss: 0.4020\n",
      "Epoch [1/3], Step [50/104], Loss: 0.4239\n",
      "Epoch [1/3], Step [60/104], Loss: 0.3825\n",
      "Epoch [1/3], Step [70/104], Loss: 0.3783\n",
      "Epoch [1/3], Step [80/104], Loss: 0.2747\n",
      "Epoch [1/3], Step [90/104], Loss: 0.3207\n",
      "Epoch [1/3], Step [100/104], Loss: 0.2432\n",
      "Epoch [2/3], Step [10/104], Loss: 0.3059\n",
      "Epoch [2/3], Step [20/104], Loss: 0.2205\n",
      "Epoch [2/3], Step [30/104], Loss: 0.2882\n",
      "Epoch [2/3], Step [40/104], Loss: 0.2438\n",
      "Epoch [2/3], Step [50/104], Loss: 0.1974\n",
      "Epoch [2/3], Step [60/104], Loss: 0.1415\n",
      "Epoch [2/3], Step [70/104], Loss: 0.2156\n",
      "Epoch [2/3], Step [80/104], Loss: 0.2002\n",
      "Epoch [2/3], Step [90/104], Loss: 0.0987\n",
      "Epoch [2/3], Step [100/104], Loss: 0.3867\n",
      "Epoch [3/3], Step [10/104], Loss: 0.1446\n",
      "Epoch [3/3], Step [20/104], Loss: 0.1324\n",
      "Epoch [3/3], Step [30/104], Loss: 0.1049\n",
      "Epoch [3/3], Step [40/104], Loss: 0.1369\n",
      "Epoch [3/3], Step [50/104], Loss: 0.3540\n",
      "Epoch [3/3], Step [60/104], Loss: 0.1979\n",
      "Epoch [3/3], Step [70/104], Loss: 0.3250\n",
      "Epoch [3/3], Step [80/104], Loss: 0.3176\n",
      "Epoch [3/3], Step [90/104], Loss: 0.2045\n",
      "Epoch [3/3], Step [100/104], Loss: 0.1679\n",
      "Epoch done:  4  Calculating accuracy\n",
      "Accuracy of the network: 90.66666666666667 %\n",
      "Accuracy of Normal: 85.52631578947368 %\n",
      "Accuracy of Tuberculosis: 95.94594594594595 %\n",
      "Epoch [1/4], Step [10/104], Loss: 0.6313\n",
      "Epoch [1/4], Step [20/104], Loss: 0.5541\n",
      "Epoch [1/4], Step [30/104], Loss: 0.4266\n",
      "Epoch [1/4], Step [40/104], Loss: 0.4294\n",
      "Epoch [1/4], Step [50/104], Loss: 0.4007\n",
      "Epoch [1/4], Step [60/104], Loss: 0.2307\n",
      "Epoch [1/4], Step [70/104], Loss: 0.3352\n",
      "Epoch [1/4], Step [80/104], Loss: 0.3932\n",
      "Epoch [1/4], Step [90/104], Loss: 0.3254\n",
      "Epoch [1/4], Step [100/104], Loss: 0.3416\n",
      "Epoch [2/4], Step [10/104], Loss: 0.2704\n",
      "Epoch [2/4], Step [20/104], Loss: 0.2078\n",
      "Epoch [2/4], Step [30/104], Loss: 0.2161\n",
      "Epoch [2/4], Step [40/104], Loss: 0.2001\n",
      "Epoch [2/4], Step [50/104], Loss: 0.2040\n",
      "Epoch [2/4], Step [60/104], Loss: 0.1397\n",
      "Epoch [2/4], Step [70/104], Loss: 0.1652\n",
      "Epoch [2/4], Step [80/104], Loss: 0.1744\n",
      "Epoch [2/4], Step [90/104], Loss: 0.2211\n",
      "Epoch [2/4], Step [100/104], Loss: 0.1297\n",
      "Epoch [3/4], Step [10/104], Loss: 0.2182\n",
      "Epoch [3/4], Step [20/104], Loss: 0.1859\n",
      "Epoch [3/4], Step [30/104], Loss: 0.1362\n",
      "Epoch [3/4], Step [40/104], Loss: 0.1714\n",
      "Epoch [3/4], Step [50/104], Loss: 0.1275\n",
      "Epoch [3/4], Step [60/104], Loss: 0.2098\n",
      "Epoch [3/4], Step [70/104], Loss: 0.1031\n",
      "Epoch [3/4], Step [80/104], Loss: 0.3234\n",
      "Epoch [3/4], Step [90/104], Loss: 0.1847\n",
      "Epoch [3/4], Step [100/104], Loss: 0.0732\n",
      "Epoch [4/4], Step [10/104], Loss: 0.0802\n",
      "Epoch [4/4], Step [20/104], Loss: 0.0923\n",
      "Epoch [4/4], Step [30/104], Loss: 0.2786\n",
      "Epoch [4/4], Step [40/104], Loss: 0.1390\n",
      "Epoch [4/4], Step [50/104], Loss: 0.1530\n",
      "Epoch [4/4], Step [60/104], Loss: 0.0711\n",
      "Epoch [4/4], Step [70/104], Loss: 0.1139\n",
      "Epoch [4/4], Step [80/104], Loss: 0.1605\n",
      "Epoch [4/4], Step [90/104], Loss: 0.1842\n",
      "Epoch [4/4], Step [100/104], Loss: 0.1108\n",
      "Epoch done:  5  Calculating accuracy\n",
      "Accuracy of the network: 96.0 %\n",
      "Accuracy of Normal: 98.54014598540147 %\n",
      "Accuracy of Tuberculosis: 93.86503067484662 %\n",
      "Epoch [1/5], Step [10/104], Loss: 0.6189\n",
      "Epoch [1/5], Step [20/104], Loss: 0.5291\n",
      "Epoch [1/5], Step [30/104], Loss: 0.4192\n",
      "Epoch [1/5], Step [40/104], Loss: 0.3553\n",
      "Epoch [1/5], Step [50/104], Loss: 0.3963\n",
      "Epoch [1/5], Step [60/104], Loss: 0.4143\n",
      "Epoch [1/5], Step [70/104], Loss: 0.3815\n",
      "Epoch [1/5], Step [80/104], Loss: 0.3763\n",
      "Epoch [1/5], Step [90/104], Loss: 0.3269\n",
      "Epoch [1/5], Step [100/104], Loss: 0.3294\n",
      "Epoch [2/5], Step [10/104], Loss: 0.3976\n",
      "Epoch [2/5], Step [20/104], Loss: 0.3123\n",
      "Epoch [2/5], Step [30/104], Loss: 0.2552\n",
      "Epoch [2/5], Step [40/104], Loss: 0.2386\n",
      "Epoch [2/5], Step [50/104], Loss: 0.1689\n",
      "Epoch [2/5], Step [60/104], Loss: 0.2787\n",
      "Epoch [2/5], Step [70/104], Loss: 0.2578\n",
      "Epoch [2/5], Step [80/104], Loss: 0.1302\n",
      "Epoch [2/5], Step [90/104], Loss: 0.2162\n",
      "Epoch [2/5], Step [100/104], Loss: 0.4593\n",
      "Epoch [3/5], Step [10/104], Loss: 0.1270\n",
      "Epoch [3/5], Step [20/104], Loss: 0.2588\n",
      "Epoch [3/5], Step [30/104], Loss: 0.0956\n",
      "Epoch [3/5], Step [40/104], Loss: 0.1486\n",
      "Epoch [3/5], Step [50/104], Loss: 0.2382\n",
      "Epoch [3/5], Step [60/104], Loss: 0.2047\n",
      "Epoch [3/5], Step [70/104], Loss: 0.1439\n",
      "Epoch [3/5], Step [80/104], Loss: 0.1495\n",
      "Epoch [3/5], Step [90/104], Loss: 0.1791\n",
      "Epoch [3/5], Step [100/104], Loss: 0.1332\n",
      "Epoch [4/5], Step [10/104], Loss: 0.0920\n",
      "Epoch [4/5], Step [20/104], Loss: 0.1341\n",
      "Epoch [4/5], Step [30/104], Loss: 0.1367\n",
      "Epoch [4/5], Step [40/104], Loss: 0.1016\n",
      "Epoch [4/5], Step [50/104], Loss: 0.0935\n",
      "Epoch [4/5], Step [60/104], Loss: 0.1364\n",
      "Epoch [4/5], Step [70/104], Loss: 0.1289\n",
      "Epoch [4/5], Step [80/104], Loss: 0.1193\n",
      "Epoch [4/5], Step [90/104], Loss: 0.1625\n",
      "Epoch [4/5], Step [100/104], Loss: 0.0905\n",
      "Epoch [5/5], Step [10/104], Loss: 0.1411\n",
      "Epoch [5/5], Step [20/104], Loss: 0.0926\n",
      "Epoch [5/5], Step [30/104], Loss: 0.0960\n",
      "Epoch [5/5], Step [40/104], Loss: 0.1671\n",
      "Epoch [5/5], Step [50/104], Loss: 0.3272\n",
      "Epoch [5/5], Step [60/104], Loss: 0.1342\n",
      "Epoch [5/5], Step [70/104], Loss: 0.0421\n",
      "Epoch [5/5], Step [80/104], Loss: 0.2887\n",
      "Epoch [5/5], Step [90/104], Loss: 0.2469\n",
      "Epoch [5/5], Step [100/104], Loss: 0.1797\n",
      "Epoch done:  6  Calculating accuracy\n",
      "Accuracy of the network: 94.66666666666667 %\n",
      "Accuracy of Normal: 100.0 %\n",
      "Accuracy of Tuberculosis: 89.1156462585034 %\n",
      "Epoch [1/6], Step [10/104], Loss: 0.6515\n",
      "Epoch [1/6], Step [20/104], Loss: 0.5680\n",
      "Epoch [1/6], Step [30/104], Loss: 0.5543\n",
      "Epoch [1/6], Step [40/104], Loss: 0.4468\n",
      "Epoch [1/6], Step [50/104], Loss: 0.3888\n",
      "Epoch [1/6], Step [60/104], Loss: 0.4872\n",
      "Epoch [1/6], Step [70/104], Loss: 0.2670\n",
      "Epoch [1/6], Step [80/104], Loss: 0.2421\n",
      "Epoch [1/6], Step [90/104], Loss: 0.3384\n",
      "Epoch [1/6], Step [100/104], Loss: 0.2516\n",
      "Epoch [2/6], Step [10/104], Loss: 0.2776\n",
      "Epoch [2/6], Step [20/104], Loss: 0.1518\n",
      "Epoch [2/6], Step [30/104], Loss: 0.2412\n",
      "Epoch [2/6], Step [40/104], Loss: 0.2663\n",
      "Epoch [2/6], Step [50/104], Loss: 0.3202\n",
      "Epoch [2/6], Step [60/104], Loss: 0.1445\n",
      "Epoch [2/6], Step [70/104], Loss: 0.3081\n",
      "Epoch [2/6], Step [80/104], Loss: 0.3785\n",
      "Epoch [2/6], Step [90/104], Loss: 0.2071\n",
      "Epoch [2/6], Step [100/104], Loss: 0.1258\n",
      "Epoch [3/6], Step [10/104], Loss: 0.2359\n",
      "Epoch [3/6], Step [20/104], Loss: 0.2910\n",
      "Epoch [3/6], Step [30/104], Loss: 0.2459\n",
      "Epoch [3/6], Step [40/104], Loss: 0.1788\n",
      "Epoch [3/6], Step [50/104], Loss: 0.1388\n",
      "Epoch [3/6], Step [60/104], Loss: 0.3184\n",
      "Epoch [3/6], Step [70/104], Loss: 0.1171\n",
      "Epoch [3/6], Step [80/104], Loss: 0.1565\n",
      "Epoch [3/6], Step [90/104], Loss: 0.1496\n",
      "Epoch [3/6], Step [100/104], Loss: 0.2615\n",
      "Epoch [4/6], Step [10/104], Loss: 0.1206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/6], Step [20/104], Loss: 0.3089\n",
      "Epoch [4/6], Step [30/104], Loss: 0.2747\n",
      "Epoch [4/6], Step [40/104], Loss: 0.2046\n",
      "Epoch [4/6], Step [50/104], Loss: 0.2886\n",
      "Epoch [4/6], Step [60/104], Loss: 0.1306\n",
      "Epoch [4/6], Step [70/104], Loss: 0.1636\n",
      "Epoch [4/6], Step [80/104], Loss: 0.1125\n",
      "Epoch [4/6], Step [90/104], Loss: 0.2586\n",
      "Epoch [4/6], Step [100/104], Loss: 0.1957\n",
      "Epoch [5/6], Step [10/104], Loss: 0.1075\n",
      "Epoch [5/6], Step [20/104], Loss: 0.0875\n",
      "Epoch [5/6], Step [30/104], Loss: 0.2852\n",
      "Epoch [5/6], Step [40/104], Loss: 0.2101\n",
      "Epoch [5/6], Step [50/104], Loss: 0.1267\n",
      "Epoch [5/6], Step [60/104], Loss: 0.1156\n",
      "Epoch [5/6], Step [70/104], Loss: 0.1223\n",
      "Epoch [5/6], Step [80/104], Loss: 0.2097\n",
      "Epoch [5/6], Step [90/104], Loss: 0.1433\n",
      "Epoch [5/6], Step [100/104], Loss: 0.0425\n",
      "Epoch [6/6], Step [10/104], Loss: 0.0919\n",
      "Epoch [6/6], Step [20/104], Loss: 0.1092\n",
      "Epoch [6/6], Step [30/104], Loss: 0.1345\n",
      "Epoch [6/6], Step [40/104], Loss: 0.1210\n",
      "Epoch [6/6], Step [50/104], Loss: 0.1803\n",
      "Epoch [6/6], Step [60/104], Loss: 0.1373\n",
      "Epoch [6/6], Step [70/104], Loss: 0.0586\n",
      "Epoch [6/6], Step [80/104], Loss: 0.1915\n",
      "Epoch [6/6], Step [90/104], Loss: 0.1598\n",
      "Epoch [6/6], Step [100/104], Loss: 0.0915\n",
      "Epoch done:  7  Calculating accuracy\n",
      "Accuracy of the network: 98.0 %\n",
      "Accuracy of Normal: 98.125 %\n",
      "Accuracy of Tuberculosis: 97.85714285714286 %\n",
      "Epoch [1/7], Step [10/104], Loss: 0.6234\n",
      "Epoch [1/7], Step [20/104], Loss: 0.5905\n",
      "Epoch [1/7], Step [30/104], Loss: 0.4976\n",
      "Epoch [1/7], Step [40/104], Loss: 0.4602\n",
      "Epoch [1/7], Step [50/104], Loss: 0.3758\n",
      "Epoch [1/7], Step [60/104], Loss: 0.4128\n",
      "Epoch [1/7], Step [70/104], Loss: 0.3979\n",
      "Epoch [1/7], Step [80/104], Loss: 0.2865\n",
      "Epoch [1/7], Step [90/104], Loss: 0.2625\n",
      "Epoch [1/7], Step [100/104], Loss: 0.2834\n",
      "Epoch [2/7], Step [10/104], Loss: 0.2745\n",
      "Epoch [2/7], Step [20/104], Loss: 0.2360\n",
      "Epoch [2/7], Step [30/104], Loss: 0.2111\n",
      "Epoch [2/7], Step [40/104], Loss: 0.1314\n",
      "Epoch [2/7], Step [50/104], Loss: 0.3251\n",
      "Epoch [2/7], Step [60/104], Loss: 0.1852\n",
      "Epoch [2/7], Step [70/104], Loss: 0.2286\n",
      "Epoch [2/7], Step [80/104], Loss: 0.2305\n",
      "Epoch [2/7], Step [90/104], Loss: 0.1665\n",
      "Epoch [2/7], Step [100/104], Loss: 0.2315\n",
      "Epoch [3/7], Step [10/104], Loss: 0.1979\n",
      "Epoch [3/7], Step [20/104], Loss: 0.2944\n",
      "Epoch [3/7], Step [30/104], Loss: 0.1472\n",
      "Epoch [3/7], Step [40/104], Loss: 0.1355\n",
      "Epoch [3/7], Step [50/104], Loss: 0.1195\n",
      "Epoch [3/7], Step [60/104], Loss: 0.1403\n",
      "Epoch [3/7], Step [70/104], Loss: 0.1538\n",
      "Epoch [3/7], Step [80/104], Loss: 0.1460\n",
      "Epoch [3/7], Step [90/104], Loss: 0.1749\n",
      "Epoch [3/7], Step [100/104], Loss: 0.2104\n",
      "Epoch [4/7], Step [10/104], Loss: 0.1515\n",
      "Epoch [4/7], Step [20/104], Loss: 0.1317\n",
      "Epoch [4/7], Step [30/104], Loss: 0.1158\n",
      "Epoch [4/7], Step [40/104], Loss: 0.1208\n",
      "Epoch [4/7], Step [50/104], Loss: 0.1091\n",
      "Epoch [4/7], Step [60/104], Loss: 0.1279\n",
      "Epoch [4/7], Step [70/104], Loss: 0.2770\n",
      "Epoch [4/7], Step [80/104], Loss: 0.2893\n",
      "Epoch [4/7], Step [90/104], Loss: 0.1534\n",
      "Epoch [4/7], Step [100/104], Loss: 0.0676\n",
      "Epoch [5/7], Step [10/104], Loss: 0.1021\n",
      "Epoch [5/7], Step [20/104], Loss: 0.0630\n",
      "Epoch [5/7], Step [30/104], Loss: 0.1262\n",
      "Epoch [5/7], Step [40/104], Loss: 0.0799\n",
      "Epoch [5/7], Step [50/104], Loss: 0.0778\n",
      "Epoch [5/7], Step [60/104], Loss: 0.1996\n",
      "Epoch [5/7], Step [70/104], Loss: 0.0977\n",
      "Epoch [5/7], Step [80/104], Loss: 0.0977\n",
      "Epoch [5/7], Step [90/104], Loss: 0.1030\n",
      "Epoch [5/7], Step [100/104], Loss: 0.0505\n",
      "Epoch [6/7], Step [10/104], Loss: 0.0843\n",
      "Epoch [6/7], Step [20/104], Loss: 0.0659\n",
      "Epoch [6/7], Step [30/104], Loss: 0.2400\n",
      "Epoch [6/7], Step [40/104], Loss: 0.2089\n",
      "Epoch [6/7], Step [50/104], Loss: 0.2342\n",
      "Epoch [6/7], Step [60/104], Loss: 0.1155\n",
      "Epoch [6/7], Step [70/104], Loss: 0.1246\n",
      "Epoch [6/7], Step [80/104], Loss: 0.1942\n",
      "Epoch [6/7], Step [90/104], Loss: 0.0997\n",
      "Epoch [6/7], Step [100/104], Loss: 0.0678\n",
      "Epoch [7/7], Step [10/104], Loss: 0.1285\n",
      "Epoch [7/7], Step [20/104], Loss: 0.0712\n",
      "Epoch [7/7], Step [30/104], Loss: 0.1501\n",
      "Epoch [7/7], Step [40/104], Loss: 0.0702\n",
      "Epoch [7/7], Step [50/104], Loss: 0.0460\n",
      "Epoch [7/7], Step [60/104], Loss: 0.0432\n",
      "Epoch [7/7], Step [70/104], Loss: 0.0704\n",
      "Epoch [7/7], Step [80/104], Loss: 0.1354\n",
      "Epoch [7/7], Step [90/104], Loss: 0.1890\n",
      "Epoch [7/7], Step [100/104], Loss: 0.0820\n",
      "Epoch done:  8  Calculating accuracy\n",
      "Accuracy of the network: 99.0 %\n",
      "Accuracy of Normal: 98.0 %\n",
      "Accuracy of Tuberculosis: 100.0 %\n",
      "Epoch [1/8], Step [10/104], Loss: 0.6686\n",
      "Epoch [1/8], Step [20/104], Loss: 0.5903\n",
      "Epoch [1/8], Step [30/104], Loss: 0.5203\n",
      "Epoch [1/8], Step [40/104], Loss: 0.4733\n",
      "Epoch [1/8], Step [50/104], Loss: 0.4619\n",
      "Epoch [1/8], Step [60/104], Loss: 0.3668\n",
      "Epoch [1/8], Step [70/104], Loss: 0.4236\n",
      "Epoch [1/8], Step [80/104], Loss: 0.2903\n",
      "Epoch [1/8], Step [90/104], Loss: 0.2879\n",
      "Epoch [1/8], Step [100/104], Loss: 0.2740\n",
      "Epoch [2/8], Step [10/104], Loss: 0.3619\n",
      "Epoch [2/8], Step [20/104], Loss: 0.2766\n",
      "Epoch [2/8], Step [30/104], Loss: 0.3413\n",
      "Epoch [2/8], Step [40/104], Loss: 0.3744\n",
      "Epoch [2/8], Step [50/104], Loss: 0.1923\n",
      "Epoch [2/8], Step [60/104], Loss: 0.1895\n",
      "Epoch [2/8], Step [70/104], Loss: 0.1696\n",
      "Epoch [2/8], Step [80/104], Loss: 0.1555\n",
      "Epoch [2/8], Step [90/104], Loss: 0.2674\n",
      "Epoch [2/8], Step [100/104], Loss: 0.2551\n",
      "Epoch [3/8], Step [10/104], Loss: 0.2911\n",
      "Epoch [3/8], Step [20/104], Loss: 0.2328\n",
      "Epoch [3/8], Step [30/104], Loss: 0.1846\n",
      "Epoch [3/8], Step [40/104], Loss: 0.1300\n",
      "Epoch [3/8], Step [50/104], Loss: 0.1444\n",
      "Epoch [3/8], Step [60/104], Loss: 0.2666\n",
      "Epoch [3/8], Step [70/104], Loss: 0.1239\n",
      "Epoch [3/8], Step [80/104], Loss: 0.0726\n",
      "Epoch [3/8], Step [90/104], Loss: 0.0880\n",
      "Epoch [3/8], Step [100/104], Loss: 0.1436\n",
      "Epoch [4/8], Step [10/104], Loss: 0.1333\n",
      "Epoch [4/8], Step [20/104], Loss: 0.1834\n",
      "Epoch [4/8], Step [30/104], Loss: 0.0781\n",
      "Epoch [4/8], Step [40/104], Loss: 0.2856\n",
      "Epoch [4/8], Step [50/104], Loss: 0.1539\n",
      "Epoch [4/8], Step [60/104], Loss: 0.2553\n",
      "Epoch [4/8], Step [70/104], Loss: 0.1870\n",
      "Epoch [4/8], Step [80/104], Loss: 0.1720\n",
      "Epoch [4/8], Step [90/104], Loss: 0.1621\n",
      "Epoch [4/8], Step [100/104], Loss: 0.1731\n",
      "Epoch [5/8], Step [10/104], Loss: 0.0409\n",
      "Epoch [5/8], Step [20/104], Loss: 0.1035\n",
      "Epoch [5/8], Step [30/104], Loss: 0.1474\n",
      "Epoch [5/8], Step [40/104], Loss: 0.1560\n",
      "Epoch [5/8], Step [50/104], Loss: 0.2061\n",
      "Epoch [5/8], Step [60/104], Loss: 0.1933\n",
      "Epoch [5/8], Step [70/104], Loss: 0.1995\n",
      "Epoch [5/8], Step [80/104], Loss: 0.1401\n",
      "Epoch [5/8], Step [90/104], Loss: 0.1089\n",
      "Epoch [5/8], Step [100/104], Loss: 0.0635\n",
      "Epoch [6/8], Step [10/104], Loss: 0.1264\n",
      "Epoch [6/8], Step [20/104], Loss: 0.1596\n",
      "Epoch [6/8], Step [30/104], Loss: 0.1296\n",
      "Epoch [6/8], Step [40/104], Loss: 0.0508\n",
      "Epoch [6/8], Step [50/104], Loss: 0.1089\n",
      "Epoch [6/8], Step [60/104], Loss: 0.1033\n",
      "Epoch [6/8], Step [70/104], Loss: 0.0876\n",
      "Epoch [6/8], Step [80/104], Loss: 0.0330\n",
      "Epoch [6/8], Step [90/104], Loss: 0.1009\n",
      "Epoch [6/8], Step [100/104], Loss: 0.0773\n",
      "Epoch [7/8], Step [10/104], Loss: 0.0869\n",
      "Epoch [7/8], Step [20/104], Loss: 0.1201\n",
      "Epoch [7/8], Step [30/104], Loss: 0.0917\n",
      "Epoch [7/8], Step [40/104], Loss: 0.1130\n",
      "Epoch [7/8], Step [50/104], Loss: 0.1062\n",
      "Epoch [7/8], Step [60/104], Loss: 0.1549\n",
      "Epoch [7/8], Step [70/104], Loss: 0.0635\n",
      "Epoch [7/8], Step [80/104], Loss: 0.1219\n",
      "Epoch [7/8], Step [90/104], Loss: 0.0842\n",
      "Epoch [7/8], Step [100/104], Loss: 0.0910\n",
      "Epoch [8/8], Step [10/104], Loss: 0.0972\n",
      "Epoch [8/8], Step [20/104], Loss: 0.0529\n",
      "Epoch [8/8], Step [30/104], Loss: 0.0814\n",
      "Epoch [8/8], Step [40/104], Loss: 0.0807\n",
      "Epoch [8/8], Step [50/104], Loss: 0.0886\n",
      "Epoch [8/8], Step [60/104], Loss: 0.0315\n",
      "Epoch [8/8], Step [70/104], Loss: 0.0318\n",
      "Epoch [8/8], Step [80/104], Loss: 0.0722\n",
      "Epoch [8/8], Step [90/104], Loss: 0.0975\n",
      "Epoch [8/8], Step [100/104], Loss: 0.0695\n",
      "Epoch done:  9  Calculating accuracy\n",
      "Accuracy of the network: 97.33333333333333 %\n",
      "Accuracy of Normal: 96.29629629629629 %\n",
      "Accuracy of Tuberculosis: 98.18181818181819 %\n",
      "Epoch [1/9], Step [10/104], Loss: 0.6267\n",
      "Epoch [1/9], Step [20/104], Loss: 0.5746\n",
      "Epoch [1/9], Step [30/104], Loss: 0.4234\n",
      "Epoch [1/9], Step [40/104], Loss: 0.4200\n",
      "Epoch [1/9], Step [50/104], Loss: 0.3524\n",
      "Epoch [1/9], Step [60/104], Loss: 0.4065\n",
      "Epoch [1/9], Step [70/104], Loss: 0.3591\n",
      "Epoch [1/9], Step [80/104], Loss: 0.3578\n",
      "Epoch [1/9], Step [90/104], Loss: 0.2481\n",
      "Epoch [1/9], Step [100/104], Loss: 0.2001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/9], Step [10/104], Loss: 0.2512\n",
      "Epoch [2/9], Step [20/104], Loss: 0.2138\n",
      "Epoch [2/9], Step [30/104], Loss: 0.2147\n",
      "Epoch [2/9], Step [40/104], Loss: 0.1342\n",
      "Epoch [2/9], Step [50/104], Loss: 0.1928\n",
      "Epoch [2/9], Step [60/104], Loss: 0.1809\n",
      "Epoch [2/9], Step [70/104], Loss: 0.2213\n",
      "Epoch [2/9], Step [80/104], Loss: 0.1074\n",
      "Epoch [2/9], Step [90/104], Loss: 0.1350\n",
      "Epoch [2/9], Step [100/104], Loss: 0.1437\n",
      "Epoch [3/9], Step [10/104], Loss: 0.2057\n",
      "Epoch [3/9], Step [20/104], Loss: 0.1785\n",
      "Epoch [3/9], Step [30/104], Loss: 0.1333\n",
      "Epoch [3/9], Step [40/104], Loss: 0.2024\n",
      "Epoch [3/9], Step [50/104], Loss: 0.2072\n",
      "Epoch [3/9], Step [60/104], Loss: 0.1928\n",
      "Epoch [3/9], Step [70/104], Loss: 0.1070\n",
      "Epoch [3/9], Step [80/104], Loss: 0.0716\n",
      "Epoch [3/9], Step [90/104], Loss: 0.0779\n",
      "Epoch [3/9], Step [100/104], Loss: 0.1468\n",
      "Epoch [4/9], Step [10/104], Loss: 0.1126\n",
      "Epoch [4/9], Step [20/104], Loss: 0.1287\n",
      "Epoch [4/9], Step [30/104], Loss: 0.1032\n",
      "Epoch [4/9], Step [40/104], Loss: 0.1121\n",
      "Epoch [4/9], Step [50/104], Loss: 0.0507\n",
      "Epoch [4/9], Step [60/104], Loss: 0.0835\n",
      "Epoch [4/9], Step [70/104], Loss: 0.0767\n",
      "Epoch [4/9], Step [80/104], Loss: 0.2254\n",
      "Epoch [4/9], Step [90/104], Loss: 0.1615\n",
      "Epoch [4/9], Step [100/104], Loss: 0.0559\n",
      "Epoch [5/9], Step [10/104], Loss: 0.1167\n",
      "Epoch [5/9], Step [20/104], Loss: 0.0358\n",
      "Epoch [5/9], Step [30/104], Loss: 0.0597\n",
      "Epoch [5/9], Step [40/104], Loss: 0.0381\n",
      "Epoch [5/9], Step [50/104], Loss: 0.1708\n",
      "Epoch [5/9], Step [60/104], Loss: 0.0348\n",
      "Epoch [5/9], Step [70/104], Loss: 0.0740\n",
      "Epoch [5/9], Step [80/104], Loss: 0.0825\n",
      "Epoch [5/9], Step [90/104], Loss: 0.0729\n",
      "Epoch [5/9], Step [100/104], Loss: 0.0669\n",
      "Epoch [6/9], Step [10/104], Loss: 0.0753\n",
      "Epoch [6/9], Step [20/104], Loss: 0.0882\n",
      "Epoch [6/9], Step [30/104], Loss: 0.1759\n",
      "Epoch [6/9], Step [40/104], Loss: 0.0289\n",
      "Epoch [6/9], Step [50/104], Loss: 0.0335\n",
      "Epoch [6/9], Step [60/104], Loss: 0.0580\n",
      "Epoch [6/9], Step [70/104], Loss: 0.0628\n",
      "Epoch [6/9], Step [80/104], Loss: 0.1314\n",
      "Epoch [6/9], Step [90/104], Loss: 0.0543\n",
      "Epoch [6/9], Step [100/104], Loss: 0.0981\n",
      "Epoch [7/9], Step [10/104], Loss: 0.1610\n",
      "Epoch [7/9], Step [20/104], Loss: 0.1053\n",
      "Epoch [7/9], Step [30/104], Loss: 0.0275\n",
      "Epoch [7/9], Step [40/104], Loss: 0.0639\n",
      "Epoch [7/9], Step [50/104], Loss: 0.0541\n",
      "Epoch [7/9], Step [60/104], Loss: 0.0404\n",
      "Epoch [7/9], Step [70/104], Loss: 0.2017\n",
      "Epoch [7/9], Step [80/104], Loss: 0.0754\n",
      "Epoch [7/9], Step [90/104], Loss: 0.0449\n",
      "Epoch [7/9], Step [100/104], Loss: 0.0633\n",
      "Epoch [8/9], Step [10/104], Loss: 0.0517\n",
      "Epoch [8/9], Step [20/104], Loss: 0.0527\n",
      "Epoch [8/9], Step [30/104], Loss: 0.0654\n",
      "Epoch [8/9], Step [40/104], Loss: 0.1202\n",
      "Epoch [8/9], Step [50/104], Loss: 0.0417\n",
      "Epoch [8/9], Step [60/104], Loss: 0.1183\n",
      "Epoch [8/9], Step [70/104], Loss: 0.0593\n",
      "Epoch [8/9], Step [80/104], Loss: 0.0516\n",
      "Epoch [8/9], Step [90/104], Loss: 0.0588\n",
      "Epoch [8/9], Step [100/104], Loss: 0.0400\n",
      "Epoch [9/9], Step [10/104], Loss: 0.0535\n",
      "Epoch [9/9], Step [20/104], Loss: 0.0442\n",
      "Epoch [9/9], Step [30/104], Loss: 0.0673\n",
      "Epoch [9/9], Step [40/104], Loss: 0.0234\n",
      "Epoch [9/9], Step [50/104], Loss: 0.0981\n",
      "Epoch [9/9], Step [60/104], Loss: 0.0349\n",
      "Epoch [9/9], Step [70/104], Loss: 0.0261\n",
      "Epoch [9/9], Step [80/104], Loss: 0.0929\n",
      "Epoch [9/9], Step [90/104], Loss: 0.0204\n",
      "Epoch [9/9], Step [100/104], Loss: 0.0324\n",
      "Epoch done:  10  Calculating accuracy\n",
      "Accuracy of the network: 98.0 %\n",
      "Accuracy of Normal: 96.6887417218543 %\n",
      "Accuracy of Tuberculosis: 99.32885906040268 %\n",
      "Epoch [1/10], Step [10/104], Loss: 0.5959\n",
      "Epoch [1/10], Step [20/104], Loss: 0.5678\n",
      "Epoch [1/10], Step [30/104], Loss: 0.4575\n",
      "Epoch [1/10], Step [40/104], Loss: 0.4043\n",
      "Epoch [1/10], Step [50/104], Loss: 0.4575\n",
      "Epoch [1/10], Step [60/104], Loss: 0.3642\n",
      "Epoch [1/10], Step [70/104], Loss: 0.3364\n",
      "Epoch [1/10], Step [80/104], Loss: 0.2823\n",
      "Epoch [1/10], Step [90/104], Loss: 0.2934\n",
      "Epoch [1/10], Step [100/104], Loss: 0.3894\n",
      "Epoch [2/10], Step [10/104], Loss: 0.1830\n",
      "Epoch [2/10], Step [20/104], Loss: 0.2673\n",
      "Epoch [2/10], Step [30/104], Loss: 0.1660\n",
      "Epoch [2/10], Step [40/104], Loss: 0.2096\n",
      "Epoch [2/10], Step [50/104], Loss: 0.1492\n",
      "Epoch [2/10], Step [60/104], Loss: 0.3078\n",
      "Epoch [2/10], Step [70/104], Loss: 0.1764\n",
      "Epoch [2/10], Step [80/104], Loss: 0.1720\n",
      "Epoch [2/10], Step [90/104], Loss: 0.1130\n",
      "Epoch [2/10], Step [100/104], Loss: 0.1636\n",
      "Epoch [3/10], Step [10/104], Loss: 0.2991\n",
      "Epoch [3/10], Step [20/104], Loss: 0.1368\n",
      "Epoch [3/10], Step [30/104], Loss: 0.1529\n",
      "Epoch [3/10], Step [40/104], Loss: 0.1737\n",
      "Epoch [3/10], Step [50/104], Loss: 0.1998\n",
      "Epoch [3/10], Step [60/104], Loss: 0.1389\n",
      "Epoch [3/10], Step [70/104], Loss: 0.1892\n",
      "Epoch [3/10], Step [80/104], Loss: 0.1541\n",
      "Epoch [3/10], Step [90/104], Loss: 0.2440\n",
      "Epoch [3/10], Step [100/104], Loss: 0.2069\n",
      "Epoch [4/10], Step [10/104], Loss: 0.1674\n",
      "Epoch [4/10], Step [20/104], Loss: 0.1414\n",
      "Epoch [4/10], Step [30/104], Loss: 0.0835\n",
      "Epoch [4/10], Step [40/104], Loss: 0.1890\n",
      "Epoch [4/10], Step [50/104], Loss: 0.1240\n",
      "Epoch [4/10], Step [60/104], Loss: 0.0752\n",
      "Epoch [4/10], Step [70/104], Loss: 0.1246\n",
      "Epoch [4/10], Step [80/104], Loss: 0.0662\n",
      "Epoch [4/10], Step [90/104], Loss: 0.0913\n",
      "Epoch [4/10], Step [100/104], Loss: 0.1969\n",
      "Epoch [5/10], Step [10/104], Loss: 0.1587\n",
      "Epoch [5/10], Step [20/104], Loss: 0.1013\n",
      "Epoch [5/10], Step [30/104], Loss: 0.2019\n",
      "Epoch [5/10], Step [40/104], Loss: 0.0677\n",
      "Epoch [5/10], Step [50/104], Loss: 0.1304\n",
      "Epoch [5/10], Step [60/104], Loss: 0.2675\n",
      "Epoch [5/10], Step [70/104], Loss: 0.0730\n",
      "Epoch [5/10], Step [80/104], Loss: 0.0580\n",
      "Epoch [5/10], Step [90/104], Loss: 0.1044\n",
      "Epoch [5/10], Step [100/104], Loss: 0.0652\n",
      "Epoch [6/10], Step [10/104], Loss: 0.1053\n",
      "Epoch [6/10], Step [20/104], Loss: 0.1112\n",
      "Epoch [6/10], Step [30/104], Loss: 0.2958\n",
      "Epoch [6/10], Step [40/104], Loss: 0.1147\n",
      "Epoch [6/10], Step [50/104], Loss: 0.0855\n",
      "Epoch [6/10], Step [60/104], Loss: 0.0971\n",
      "Epoch [6/10], Step [70/104], Loss: 0.0816\n",
      "Epoch [6/10], Step [80/104], Loss: 0.1254\n",
      "Epoch [6/10], Step [90/104], Loss: 0.0300\n",
      "Epoch [6/10], Step [100/104], Loss: 0.0699\n",
      "Epoch [7/10], Step [10/104], Loss: 0.0591\n",
      "Epoch [7/10], Step [20/104], Loss: 0.0557\n",
      "Epoch [7/10], Step [30/104], Loss: 0.0873\n",
      "Epoch [7/10], Step [40/104], Loss: 0.0519\n",
      "Epoch [7/10], Step [50/104], Loss: 0.0692\n",
      "Epoch [7/10], Step [60/104], Loss: 0.0405\n",
      "Epoch [7/10], Step [70/104], Loss: 0.1575\n",
      "Epoch [7/10], Step [80/104], Loss: 0.0845\n",
      "Epoch [7/10], Step [90/104], Loss: 0.0887\n",
      "Epoch [7/10], Step [100/104], Loss: 0.0964\n",
      "Epoch [8/10], Step [10/104], Loss: 0.0786\n",
      "Epoch [8/10], Step [20/104], Loss: 0.0734\n",
      "Epoch [8/10], Step [30/104], Loss: 0.0544\n",
      "Epoch [8/10], Step [40/104], Loss: 0.1213\n",
      "Epoch [8/10], Step [50/104], Loss: 0.1419\n",
      "Epoch [8/10], Step [60/104], Loss: 0.0942\n",
      "Epoch [8/10], Step [70/104], Loss: 0.1988\n",
      "Epoch [8/10], Step [80/104], Loss: 0.0378\n",
      "Epoch [8/10], Step [90/104], Loss: 0.0259\n",
      "Epoch [8/10], Step [100/104], Loss: 0.1327\n",
      "Epoch [9/10], Step [10/104], Loss: 0.0236\n",
      "Epoch [9/10], Step [20/104], Loss: 0.0355\n",
      "Epoch [9/10], Step [30/104], Loss: 0.0836\n",
      "Epoch [9/10], Step [40/104], Loss: 0.0619\n",
      "Epoch [9/10], Step [50/104], Loss: 0.0280\n",
      "Epoch [9/10], Step [60/104], Loss: 0.0623\n",
      "Epoch [9/10], Step [70/104], Loss: 0.0549\n",
      "Epoch [9/10], Step [80/104], Loss: 0.0799\n",
      "Epoch [9/10], Step [90/104], Loss: 0.1126\n",
      "Epoch [9/10], Step [100/104], Loss: 0.0577\n",
      "Epoch [10/10], Step [10/104], Loss: 0.0374\n",
      "Epoch [10/10], Step [20/104], Loss: 0.0270\n",
      "Epoch [10/10], Step [30/104], Loss: 0.0468\n",
      "Epoch [10/10], Step [40/104], Loss: 0.0747\n",
      "Epoch [10/10], Step [50/104], Loss: 0.0312\n",
      "Epoch [10/10], Step [60/104], Loss: 0.0319\n",
      "Epoch [10/10], Step [70/104], Loss: 0.1353\n",
      "Epoch [10/10], Step [80/104], Loss: 0.0222\n",
      "Epoch [10/10], Step [90/104], Loss: 0.0922\n",
      "Epoch [10/10], Step [100/104], Loss: 0.0491\n",
      "Epoch done:  11  Calculating accuracy\n",
      "Accuracy of the network: 98.0 %\n",
      "Accuracy of Normal: 96.52777777777777 %\n",
      "Accuracy of Tuberculosis: 99.35897435897436 %\n",
      "CPU times: user 1h 32min 42s, sys: 44 s, total: 1h 33min 26s\n",
      "Wall time: 1h 15min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Accuracy for LeNet5 with various epoch\n",
    "model_name = 'LeNet5'\n",
    "model = all_models[model_name]\n",
    "for i in range(1,11):\n",
    "    model = LeNet5()\n",
    "    losses = train_by_model(model, model_name, i)\n",
    "    loss_data_of_model_epoch[model_name][i] = losses\n",
    "    print(\"Epoch done: \", i+1, \" Calculating accuracy\")\n",
    "    acc_of_model_epoch[model_name][i] = get_acc_from_data(val_loader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aec6b2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loss_data_of_model_epoch[model_name][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec816ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_data_of_model_epoch\n",
    "# acc_of_model_epoch\n",
    "\n",
    "import json\n",
    "with open('loss_data_of_model_epoch.json', 'w') as fp:\n",
    "    json.dump(loss_data_of_model_epoch, fp)\n",
    "    \n",
    "with open('acc_of_model_epoch.json', 'w') as fp:\n",
    "    json.dump(acc_of_model_epoch, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b80e86f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accuracies = []\n",
    "for acc in acc_of_model_epoch[model_name]:\n",
    "    all_accuracies.append(acc_of_model_epoch[model_name][acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "88e209a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size:  16\n",
      "Epoch [1/5], Step [10/207], Loss: 0.5926\n",
      "Epoch [1/5], Step [20/207], Loss: 0.5055\n",
      "Epoch [1/5], Step [30/207], Loss: 0.3811\n",
      "Epoch [1/5], Step [40/207], Loss: 0.4555\n",
      "Epoch [1/5], Step [50/207], Loss: 0.4348\n",
      "Epoch [1/5], Step [60/207], Loss: 0.3512\n",
      "Epoch [1/5], Step [70/207], Loss: 0.3202\n",
      "Epoch [1/5], Step [80/207], Loss: 0.2436\n",
      "Epoch [1/5], Step [90/207], Loss: 0.3684\n",
      "Epoch [1/5], Step [100/207], Loss: 0.3345\n",
      "Epoch [1/5], Step [110/207], Loss: 0.1474\n",
      "Epoch [1/5], Step [120/207], Loss: 0.4238\n",
      "Epoch [1/5], Step [130/207], Loss: 0.2914\n",
      "Epoch [1/5], Step [140/207], Loss: 0.1242\n",
      "Epoch [1/5], Step [150/207], Loss: 0.2499\n",
      "Epoch [1/5], Step [160/207], Loss: 0.1086\n",
      "Epoch [1/5], Step [170/207], Loss: 0.0873\n",
      "Epoch [1/5], Step [180/207], Loss: 0.1532\n",
      "Epoch [1/5], Step [190/207], Loss: 0.1300\n",
      "Epoch [1/5], Step [200/207], Loss: 0.2643\n",
      "Epoch [2/5], Step [10/207], Loss: 0.3250\n",
      "Epoch [2/5], Step [20/207], Loss: 0.1109\n",
      "Epoch [2/5], Step [30/207], Loss: 0.2369\n",
      "Epoch [2/5], Step [40/207], Loss: 0.2052\n",
      "Epoch [2/5], Step [50/207], Loss: 0.2937\n",
      "Epoch [2/5], Step [60/207], Loss: 0.0748\n",
      "Epoch [2/5], Step [70/207], Loss: 0.0959\n",
      "Epoch [2/5], Step [80/207], Loss: 0.3710\n",
      "Epoch [2/5], Step [90/207], Loss: 0.2644\n",
      "Epoch [2/5], Step [100/207], Loss: 0.1710\n",
      "Epoch [2/5], Step [110/207], Loss: 0.1134\n",
      "Epoch [2/5], Step [120/207], Loss: 0.0751\n",
      "Epoch [2/5], Step [130/207], Loss: 0.1422\n",
      "Epoch [2/5], Step [140/207], Loss: 0.2817\n",
      "Epoch [2/5], Step [150/207], Loss: 0.1586\n",
      "Epoch [2/5], Step [160/207], Loss: 0.1330\n",
      "Epoch [2/5], Step [170/207], Loss: 0.1214\n",
      "Epoch [2/5], Step [180/207], Loss: 0.0783\n",
      "Epoch [2/5], Step [190/207], Loss: 0.1421\n",
      "Epoch [2/5], Step [200/207], Loss: 0.1513\n",
      "Epoch [3/5], Step [10/207], Loss: 0.1337\n",
      "Epoch [3/5], Step [20/207], Loss: 0.0831\n",
      "Epoch [3/5], Step [30/207], Loss: 0.1813\n",
      "Epoch [3/5], Step [40/207], Loss: 0.3261\n",
      "Epoch [3/5], Step [50/207], Loss: 0.0724\n",
      "Epoch [3/5], Step [60/207], Loss: 0.1158\n",
      "Epoch [3/5], Step [70/207], Loss: 0.0669\n",
      "Epoch [3/5], Step [80/207], Loss: 0.0435\n",
      "Epoch [3/5], Step [90/207], Loss: 0.1224\n",
      "Epoch [3/5], Step [100/207], Loss: 0.1419\n",
      "Epoch [3/5], Step [110/207], Loss: 0.0686\n",
      "Epoch [3/5], Step [120/207], Loss: 0.0829\n",
      "Epoch [3/5], Step [130/207], Loss: 0.0168\n",
      "Epoch [3/5], Step [140/207], Loss: 0.2312\n",
      "Epoch [3/5], Step [150/207], Loss: 0.0150\n",
      "Epoch [3/5], Step [160/207], Loss: 0.0994\n",
      "Epoch [3/5], Step [170/207], Loss: 0.0776\n",
      "Epoch [3/5], Step [180/207], Loss: 0.1552\n",
      "Epoch [3/5], Step [190/207], Loss: 0.0966\n",
      "Epoch [3/5], Step [200/207], Loss: 0.0396\n",
      "Epoch [4/5], Step [10/207], Loss: 0.2931\n",
      "Epoch [4/5], Step [20/207], Loss: 0.0602\n",
      "Epoch [4/5], Step [30/207], Loss: 0.0541\n",
      "Epoch [4/5], Step [40/207], Loss: 0.0329\n",
      "Epoch [4/5], Step [50/207], Loss: 0.1507\n",
      "Epoch [4/5], Step [60/207], Loss: 0.3456\n",
      "Epoch [4/5], Step [70/207], Loss: 0.0879\n",
      "Epoch [4/5], Step [80/207], Loss: 0.0118\n",
      "Epoch [4/5], Step [90/207], Loss: 0.4195\n",
      "Epoch [4/5], Step [100/207], Loss: 0.0306\n",
      "Epoch [4/5], Step [110/207], Loss: 0.0288\n",
      "Epoch [4/5], Step [120/207], Loss: 0.0349\n",
      "Epoch [4/5], Step [130/207], Loss: 0.1263\n",
      "Epoch [4/5], Step [140/207], Loss: 0.0326\n",
      "Epoch [4/5], Step [150/207], Loss: 0.2173\n",
      "Epoch [4/5], Step [160/207], Loss: 0.0123\n",
      "Epoch [4/5], Step [170/207], Loss: 0.0274\n",
      "Epoch [4/5], Step [180/207], Loss: 0.0331\n",
      "Epoch [4/5], Step [190/207], Loss: 0.0242\n",
      "Epoch [4/5], Step [200/207], Loss: 0.2232\n",
      "Epoch [5/5], Step [10/207], Loss: 0.0534\n",
      "Epoch [5/5], Step [20/207], Loss: 0.0313\n",
      "Epoch [5/5], Step [30/207], Loss: 0.1636\n",
      "Epoch [5/5], Step [40/207], Loss: 0.1509\n",
      "Epoch [5/5], Step [50/207], Loss: 0.0456\n",
      "Epoch [5/5], Step [60/207], Loss: 0.0465\n",
      "Epoch [5/5], Step [70/207], Loss: 0.0383\n",
      "Epoch [5/5], Step [80/207], Loss: 0.0143\n",
      "Epoch [5/5], Step [90/207], Loss: 0.0448\n",
      "Epoch [5/5], Step [100/207], Loss: 0.0135\n",
      "Epoch [5/5], Step [110/207], Loss: 0.1027\n",
      "Epoch [5/5], Step [120/207], Loss: 0.0603\n",
      "Epoch [5/5], Step [130/207], Loss: 0.0560\n",
      "Epoch [5/5], Step [140/207], Loss: 0.0373\n",
      "Epoch [5/5], Step [150/207], Loss: 0.0467\n",
      "Epoch [5/5], Step [160/207], Loss: 0.0291\n",
      "Epoch [5/5], Step [170/207], Loss: 0.0236\n",
      "Epoch [5/5], Step [180/207], Loss: 0.0221\n",
      "Epoch [5/5], Step [190/207], Loss: 0.0330\n",
      "Epoch [5/5], Step [200/207], Loss: 0.1237\n",
      "Accuracy of the network: 94.0 %\n",
      "Accuracy of Normal: 87.41258741258741 %\n",
      "Accuracy of Tuberculosis: 100.0 %\n",
      "Batch Size:  32\n",
      "Epoch [1/5], Step [10/104], Loss: 0.6192\n",
      "Epoch [1/5], Step [20/104], Loss: 0.4887\n",
      "Epoch [1/5], Step [30/104], Loss: 0.4802\n",
      "Epoch [1/5], Step [40/104], Loss: 0.3822\n",
      "Epoch [1/5], Step [50/104], Loss: 0.4535\n",
      "Epoch [1/5], Step [60/104], Loss: 0.2983\n",
      "Epoch [1/5], Step [70/104], Loss: 0.4158\n",
      "Epoch [1/5], Step [80/104], Loss: 0.3496\n",
      "Epoch [1/5], Step [90/104], Loss: 0.3211\n",
      "Epoch [1/5], Step [100/104], Loss: 0.2949\n",
      "Epoch [2/5], Step [10/104], Loss: 0.2350\n",
      "Epoch [2/5], Step [20/104], Loss: 0.2881\n",
      "Epoch [2/5], Step [30/104], Loss: 0.2068\n",
      "Epoch [2/5], Step [40/104], Loss: 0.2445\n",
      "Epoch [2/5], Step [50/104], Loss: 0.1988\n",
      "Epoch [2/5], Step [60/104], Loss: 0.2578\n",
      "Epoch [2/5], Step [70/104], Loss: 0.2167\n",
      "Epoch [2/5], Step [80/104], Loss: 0.1692\n",
      "Epoch [2/5], Step [90/104], Loss: 0.2446\n",
      "Epoch [2/5], Step [100/104], Loss: 0.2112\n",
      "Epoch [3/5], Step [10/104], Loss: 0.1885\n",
      "Epoch [3/5], Step [20/104], Loss: 0.1872\n",
      "Epoch [3/5], Step [30/104], Loss: 0.1734\n",
      "Epoch [3/5], Step [40/104], Loss: 0.1767\n",
      "Epoch [3/5], Step [50/104], Loss: 0.1110\n",
      "Epoch [3/5], Step [60/104], Loss: 0.1861\n",
      "Epoch [3/5], Step [70/104], Loss: 0.2057\n",
      "Epoch [3/5], Step [80/104], Loss: 0.1418\n",
      "Epoch [3/5], Step [90/104], Loss: 0.2550\n",
      "Epoch [3/5], Step [100/104], Loss: 0.1900\n",
      "Epoch [4/5], Step [10/104], Loss: 0.2514\n",
      "Epoch [4/5], Step [20/104], Loss: 0.0979\n",
      "Epoch [4/5], Step [30/104], Loss: 0.1836\n",
      "Epoch [4/5], Step [40/104], Loss: 0.1900\n",
      "Epoch [4/5], Step [50/104], Loss: 0.1471\n",
      "Epoch [4/5], Step [60/104], Loss: 0.1439\n",
      "Epoch [4/5], Step [70/104], Loss: 0.1118\n",
      "Epoch [4/5], Step [80/104], Loss: 0.1725\n",
      "Epoch [4/5], Step [90/104], Loss: 0.0935\n",
      "Epoch [4/5], Step [100/104], Loss: 0.1100\n",
      "Epoch [5/5], Step [10/104], Loss: 0.1901\n",
      "Epoch [5/5], Step [20/104], Loss: 0.1279\n",
      "Epoch [5/5], Step [30/104], Loss: 0.1408\n",
      "Epoch [5/5], Step [40/104], Loss: 0.1215\n",
      "Epoch [5/5], Step [50/104], Loss: 0.1816\n",
      "Epoch [5/5], Step [60/104], Loss: 0.1612\n",
      "Epoch [5/5], Step [70/104], Loss: 0.1419\n",
      "Epoch [5/5], Step [80/104], Loss: 0.0714\n",
      "Epoch [5/5], Step [90/104], Loss: 0.1658\n",
      "Epoch [5/5], Step [100/104], Loss: 0.0832\n",
      "Accuracy of the network: 96.33333333333333 %\n",
      "Accuracy of Normal: 97.35099337748345 %\n",
      "Accuracy of Tuberculosis: 95.30201342281879 %\n",
      "Batch Size:  64\n",
      "Epoch [1/5], Step [10/52], Loss: 0.6270\n",
      "Epoch [1/5], Step [20/52], Loss: 0.5383\n",
      "Epoch [1/5], Step [30/52], Loss: 0.4622\n",
      "Epoch [1/5], Step [40/52], Loss: 0.4512\n",
      "Epoch [1/5], Step [50/52], Loss: 0.4190\n",
      "Epoch [2/5], Step [10/52], Loss: 0.3587\n",
      "Epoch [2/5], Step [20/52], Loss: 0.3466\n",
      "Epoch [2/5], Step [30/52], Loss: 0.3344\n",
      "Epoch [2/5], Step [40/52], Loss: 0.2732\n",
      "Epoch [2/5], Step [50/52], Loss: 0.3742\n",
      "Epoch [3/5], Step [10/52], Loss: 0.2335\n",
      "Epoch [3/5], Step [20/52], Loss: 0.2525\n",
      "Epoch [3/5], Step [30/52], Loss: 0.2835\n",
      "Epoch [3/5], Step [40/52], Loss: 0.2011\n",
      "Epoch [3/5], Step [50/52], Loss: 0.3028\n",
      "Epoch [4/5], Step [10/52], Loss: 0.2240\n",
      "Epoch [4/5], Step [20/52], Loss: 0.3118\n",
      "Epoch [4/5], Step [30/52], Loss: 0.2313\n",
      "Epoch [4/5], Step [40/52], Loss: 0.3346\n",
      "Epoch [4/5], Step [50/52], Loss: 0.3825\n",
      "Epoch [5/5], Step [10/52], Loss: 0.2084\n",
      "Epoch [5/5], Step [20/52], Loss: 0.2026\n",
      "Epoch [5/5], Step [30/52], Loss: 0.2229\n",
      "Epoch [5/5], Step [40/52], Loss: 0.1412\n",
      "Epoch [5/5], Step [50/52], Loss: 0.2108\n",
      "Accuracy of the network: 93.66666666666667 %\n",
      "Accuracy of Normal: 93.37748344370861 %\n",
      "Accuracy of Tuberculosis: 93.95973154362416 %\n"
     ]
    }
   ],
   "source": [
    "for bs in [16, 32, 64]:\n",
    "    print(\"Batch Size: \", bs)\n",
    "    train_loader =  torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True)\n",
    "    test_loader =  torch.utils.data.DataLoader(testset, batch_size=bs, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(valset, batch_size=bs, shuffle=True)\n",
    "    model = LeNet5()\n",
    "    train_by_model(model, model_name, 5)\n",
    "    acc_of_model_batch[model_name][i] = get_acc_from_data(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d13da514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f97db2ca070>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ll = loss_data_of_model_epoch[model_name][1]\n",
    "plt.plot(all_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94a2228b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 95.66666666666667 %\n",
      "Accuracy of Normal: 96.63299663299664 %\n",
      "Accuracy of Tuberculosis: 94.71947194719472 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95.66666666666667"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_acc_from_data(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746f5887",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc_from_data(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf0de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409013f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = VGG16()\n",
    "learning_rate = 0.001\n",
    "all_loss = []\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(args.num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        all_loss.append(loss.item())\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{args.num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454e917b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085abeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc_from_data(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2363dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc_from_data(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c523b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
