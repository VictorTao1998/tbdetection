{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff1ede8c",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89309d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version 1.11.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pdb\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import argparse\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print('Using PyTorch version', torch.__version__)\n",
    "\n",
    "\n",
    "from os.path import isfile\n",
    "from os import rename\n",
    "SMOOTH=1\n",
    "import pdb\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from PIL.ImageFilter import GaussianBlur\n",
    "\n",
    "# import pdb\n",
    "from numpy import pi as PI\n",
    "from numpy import sqrt\n",
    "from scipy.special import comb\n",
    "import math\n",
    "\n",
    "import copy\n",
    "# tensorflow libraries\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5c46b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch res, res101..\n",
    "\n",
    "# Tying papers -> Take inputs from the papers and comparision\n",
    "# Implementing. LeNet\n",
    "# EDA. More about Dataset\n",
    "# Data Augmentation -> Its Benifits\n",
    "# Can use different dataset on top of this\n",
    "# Loss plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0be2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscellaneous initialization\n",
    "torch.manual_seed(1)\n",
    "start_time = time.time()\n",
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0d5de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"\"\n",
    "test_dataset_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fc58232",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/Users/harshitb/Desktop/Studies/ECE 228/TB_dataset/TB_Chest_Radiography_Database\"\n",
    "class_names = ['Normal', 'Tuberculosis']\n",
    "source_dirs = ['Normal', 'Tuberculosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "930810b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.add_argument('--num_epochs', type=int, default=5, help='Number of training epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=32, help='Batch size')\n",
    "parser.add_argument('--lr', type=float, default=5e-4, help='Learning rate')\n",
    "parser.add_argument('--l2', type=float, default=0, help='L2 regularisation')\n",
    "parser.add_argument('--aug', action='store_true', default=False, help='Use data augmentation')\n",
    "parser.add_argument('--data_path', type=str, default=root_dir,help='Path to data.')\n",
    "parser.add_argument('--bond_dim', type=int, default=5, help='MPS Bond dimension')\n",
    "parser.add_argument('--nChannel', type=int, default=1, help='Number of input channels')\n",
    "parser.add_argument('--dense_net', action='store_true', default=False, help='Using Dense Net model')\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "684a5c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = args.batch_size\n",
    "\n",
    "# LoTeNet parameters\n",
    "adaptive_mode = False \n",
    "periodic_bc   = False\n",
    "\n",
    "kernel = 2 # Stride along spatial dimensions\n",
    "output_dim = 1 # output dimension\n",
    " \n",
    "feature_dim = 2\n",
    "\n",
    "#logFile = time.strftime(\"%Y%m%d_%H_%M\")+'.txt'\n",
    "#makeLogFile(logFile)\n",
    "\n",
    "normTensor = 0.5*torch.ones(args.nChannel)\n",
    "### Data processing and loading....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc2837a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data processing and loading....\n",
    "# mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225]\n",
    "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.Resize(size=(256,256)),\n",
    "#                                       transforms.RandomVerticalFlip(),\n",
    "#                                       transforms.RandomRotation(20),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=normTensor,std=normTensor)])\n",
    "\n",
    "valid_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size=(256,256)),\n",
    "#     torchvision.transforms.RandomHorizontalFlip(),\n",
    "#     torchvision.transforms.RandomRotation(20),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=normTensor,std=normTensor)\n",
    "    #torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a87dbe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXRayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_dirs,transform):\n",
    "        def get_images(class_name):\n",
    "            images = [x for x in os.listdir(image_dirs[class_name]) if x.lower().endswith('png')]\n",
    "            print(f'Found {len(images)}{class_name}')\n",
    "            return images\n",
    "        self.images={}\n",
    "        self.class_names=['Normal', 'Tuberculosis']\n",
    "        for c in self.class_names:\n",
    "            self.images[c]=get_images(c)\n",
    "        self.image_dirs=image_dirs\n",
    "        self.transform=transform\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return sum([len(self.images[c]) for c in self.class_names])\n",
    "    def __getitem__(self, index):\n",
    "        class_name=random.choice(self.class_names)\n",
    "        index=index%len(self.images[class_name])\n",
    "        image_name=self.images[class_name][index]\n",
    "        image_path =os.path.join(self.image_dirs[class_name], image_name)\n",
    "        image=Image.open(image_path).convert('L')\n",
    "        return self.transform(image), self.class_names.index(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56fa2063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3500Normal\n",
      "Found 700Tuberculosis\n"
     ]
    }
   ],
   "source": [
    "train_dirs = {\n",
    "    'Normal': root_dir + '/Normal',\n",
    "    'Tuberculosis': root_dir + '/Tuberculosis'\n",
    "}\n",
    "dataset = ChestXRayDataset(train_dirs, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6795fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,l = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfaf2476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbe34a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset, valset = random_split(dataset, [3300, 600, 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1288b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader =  torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader =  torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "966057cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        #         xl = 1\n",
    "        #         for i in x.shape[1:]: xl *= i\n",
    "        #         self.fc1 = nn.Linear(13456, 120)\n",
    "        self.fc1 = nn.Linear(984064, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        #         x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
    "        #         x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv1(x))  # -> n, 6, 14, 14\n",
    "        x = F.relu(self.conv2(x))\n",
    "        xl = 1\n",
    "        for i in x.shape[1:]: xl *= i\n",
    "        x = x.view(-1, xl)            # \n",
    "        x = F.relu(self.fc1(x))               # -> n, 120\n",
    "        x = F.relu(self.fc2(x))               # -> n, 84\n",
    "        x = self.fc3(x)                       # -> n, 2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a40b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the convolutional neural network\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Linear(59536, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddf655a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.conv1_1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv4_1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv5_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(32768, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv5_1(x))\n",
    "        x = F.relu(self.conv5_2(x))\n",
    "        x = F.relu(self.conv5_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "#         print(\"HERE ... \", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, 0.5) #dropout was included to combat overfitting\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, 0.5)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88249028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising variable that will be used in the experiments in the project\n",
    "\n",
    "loss_data_of_model_epoch = {}\n",
    "acc_of_model_epoch = {}\n",
    "acc_of_model_batch = {}\n",
    "\n",
    "all_models = {}\n",
    "all_models['ConvNet'] = ConvNet()\n",
    "all_models['LeNet5']  = LeNet5()\n",
    "all_models['VGG16']   = VGG16()\n",
    "\n",
    "for model_name in all_models.keys():\n",
    "    loss_data_of_model_epoch[model_name] = {}\n",
    "    acc_of_model_epoch[model_name] = {}\n",
    "    acc_of_model_batch[model_name] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bd40115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_from_data(d_loader):\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        n_class_correct = [0 for i in range(2)]\n",
    "        n_class_samples = [0 for i in range(2)]\n",
    "        for images, labels in d_loader:\n",
    "            #         print(len(labels))\n",
    "            outputs = model(images)\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                pred = predicted[i]\n",
    "                if (label == pred):\n",
    "                    n_class_correct[label] += 1\n",
    "                n_class_samples[label] += 1\n",
    "\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network: {acc} %')\n",
    "        \n",
    "        all_acc = []\n",
    "        overall_accuracy = acc\n",
    "        all_acc.append(overall_accuracy)\n",
    "\n",
    "        for i in range(2):\n",
    "            acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "            print(f'Accuracy of {class_names[i]}: {acc} %')\n",
    "            all_acc.append(acc)\n",
    "                \n",
    "    #return all_acc\n",
    "    return overall_accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f864a6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet5_model_with_epoch = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b1e415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_by_model(model, model_name, epo = 3, verbose = True):\n",
    "    args.num_epochs = epo\n",
    "    learning_rate = 0.001\n",
    "    all_loss = []\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    n_total_steps = len(train_loader)\n",
    "    for epoch in range(args.num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            all_loss.append(loss.item())\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if ((i+1) % 10 == 0) and verbose:\n",
    "                print (f'Epoch [{epoch+1}/{args.num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "        LeNet5_model_with_epoch[epoch+1] = copy.deepcopy(model)\n",
    "        \n",
    "    return all_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7aa1a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting epoch as 3\n",
    "args.num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5446561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [10/104], Loss: 0.1273\n",
      "Epoch [1/3], Step [20/104], Loss: 0.2611\n",
      "Epoch [1/3], Step [30/104], Loss: 0.1776\n",
      "Epoch [1/3], Step [40/104], Loss: 0.1829\n",
      "Epoch [1/3], Step [50/104], Loss: 0.2806\n",
      "Epoch [1/3], Step [60/104], Loss: 0.2890\n",
      "Epoch [1/3], Step [70/104], Loss: 0.2611\n",
      "Epoch [1/3], Step [80/104], Loss: 0.1959\n",
      "Epoch [1/3], Step [90/104], Loss: 0.1702\n",
      "Epoch [1/3], Step [100/104], Loss: 0.2136\n",
      "Epoch [2/3], Step [10/104], Loss: 0.2019\n",
      "Epoch [2/3], Step [20/104], Loss: 0.2601\n",
      "Epoch [2/3], Step [30/104], Loss: 0.1689\n",
      "Epoch [2/3], Step [40/104], Loss: 0.2612\n",
      "Epoch [2/3], Step [50/104], Loss: 0.1429\n",
      "Epoch [2/3], Step [60/104], Loss: 0.1452\n",
      "Epoch [2/3], Step [70/104], Loss: 0.0742\n",
      "Epoch [2/3], Step [80/104], Loss: 0.1289\n",
      "Epoch [2/3], Step [90/104], Loss: 0.0888\n",
      "Epoch [2/3], Step [100/104], Loss: 0.1352\n",
      "Epoch [3/3], Step [10/104], Loss: 0.1016\n",
      "Epoch [3/3], Step [20/104], Loss: 0.1585\n",
      "Epoch [3/3], Step [30/104], Loss: 0.1447\n",
      "Epoch [3/3], Step [40/104], Loss: 0.1810\n",
      "Epoch [3/3], Step [50/104], Loss: 0.0992\n",
      "Epoch [3/3], Step [60/104], Loss: 0.0531\n",
      "Epoch [3/3], Step [70/104], Loss: 0.1251\n",
      "Epoch [3/3], Step [80/104], Loss: 0.0553\n",
      "Epoch [3/3], Step [90/104], Loss: 0.0941\n",
      "Epoch [3/3], Step [100/104], Loss: 0.0986\n",
      "Accuracy of the network: 94.5 %\n",
      "Accuracy of Normal: 96.62576687116564 %\n",
      "Accuracy of Tuberculosis: 91.97080291970804 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94.5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking various architectures above one by one with epoch = 3\n",
    "# by switching arch in below variable\n",
    "\n",
    "model_name = \"LeNet5\"\n",
    "model = all_models[model_name]\n",
    "\n",
    "train_by_model(model, model_name)\n",
    "get_acc_from_data(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75599bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Step [10/104], Loss: 0.6840\n",
      "Epoch [1/15], Step [20/104], Loss: 0.5593\n",
      "Epoch [1/15], Step [30/104], Loss: 0.5205\n",
      "Epoch [1/15], Step [40/104], Loss: 0.4747\n",
      "Epoch [1/15], Step [50/104], Loss: 0.4049\n",
      "Epoch [1/15], Step [60/104], Loss: 0.3230\n",
      "Epoch [1/15], Step [70/104], Loss: 0.3216\n",
      "Epoch [1/15], Step [80/104], Loss: 0.2939\n",
      "Epoch [1/15], Step [90/104], Loss: 0.2618\n",
      "Epoch [1/15], Step [100/104], Loss: 0.2193\n",
      "Epoch [2/15], Step [10/104], Loss: 0.2772\n",
      "Epoch [2/15], Step [20/104], Loss: 0.3232\n",
      "Epoch [2/15], Step [30/104], Loss: 0.1954\n",
      "Epoch [2/15], Step [40/104], Loss: 0.1894\n",
      "Epoch [2/15], Step [50/104], Loss: 0.2655\n",
      "Epoch [2/15], Step [60/104], Loss: 0.2520\n",
      "Epoch [2/15], Step [70/104], Loss: 0.3182\n",
      "Epoch [2/15], Step [80/104], Loss: 0.2444\n",
      "Epoch [2/15], Step [90/104], Loss: 0.2091\n",
      "Epoch [2/15], Step [100/104], Loss: 0.1380\n",
      "Epoch [3/15], Step [10/104], Loss: 0.1146\n",
      "Epoch [3/15], Step [20/104], Loss: 0.0950\n",
      "Epoch [3/15], Step [30/104], Loss: 0.1926\n",
      "Epoch [3/15], Step [40/104], Loss: 0.2145\n",
      "Epoch [3/15], Step [50/104], Loss: 0.1749\n",
      "Epoch [3/15], Step [60/104], Loss: 0.2278\n",
      "Epoch [3/15], Step [70/104], Loss: 0.1547\n",
      "Epoch [3/15], Step [80/104], Loss: 0.1300\n",
      "Epoch [3/15], Step [90/104], Loss: 0.0949\n",
      "Epoch [3/15], Step [100/104], Loss: 0.1108\n",
      "Epoch [4/15], Step [10/104], Loss: 0.2347\n",
      "Epoch [4/15], Step [20/104], Loss: 0.2153\n",
      "Epoch [4/15], Step [30/104], Loss: 0.1362\n",
      "Epoch [4/15], Step [40/104], Loss: 0.1151\n",
      "Epoch [4/15], Step [50/104], Loss: 0.1179\n",
      "Epoch [4/15], Step [60/104], Loss: 0.2462\n",
      "Epoch [4/15], Step [70/104], Loss: 0.1593\n",
      "Epoch [4/15], Step [80/104], Loss: 0.1491\n",
      "Epoch [4/15], Step [90/104], Loss: 0.2329\n",
      "Epoch [4/15], Step [100/104], Loss: 0.0779\n",
      "Epoch [5/15], Step [10/104], Loss: 0.1071\n",
      "Epoch [5/15], Step [20/104], Loss: 0.0524\n",
      "Epoch [5/15], Step [30/104], Loss: 0.1231\n",
      "Epoch [5/15], Step [40/104], Loss: 0.0246\n",
      "Epoch [5/15], Step [50/104], Loss: 0.2582\n",
      "Epoch [5/15], Step [60/104], Loss: 0.1165\n",
      "Epoch [5/15], Step [70/104], Loss: 0.1906\n",
      "Epoch [5/15], Step [80/104], Loss: 0.1293\n",
      "Epoch [5/15], Step [90/104], Loss: 0.1844\n",
      "Epoch [5/15], Step [100/104], Loss: 0.2324\n",
      "Epoch [6/15], Step [10/104], Loss: 0.0562\n",
      "Epoch [6/15], Step [20/104], Loss: 0.1092\n",
      "Epoch [6/15], Step [30/104], Loss: 0.1500\n",
      "Epoch [6/15], Step [40/104], Loss: 0.0631\n",
      "Epoch [6/15], Step [50/104], Loss: 0.1311\n",
      "Epoch [6/15], Step [60/104], Loss: 0.0584\n",
      "Epoch [6/15], Step [70/104], Loss: 0.1206\n",
      "Epoch [6/15], Step [80/104], Loss: 0.0848\n",
      "Epoch [6/15], Step [90/104], Loss: 0.1480\n",
      "Epoch [6/15], Step [100/104], Loss: 0.0968\n",
      "Epoch [7/15], Step [10/104], Loss: 0.0282\n",
      "Epoch [7/15], Step [20/104], Loss: 0.0426\n",
      "Epoch [7/15], Step [30/104], Loss: 0.1279\n",
      "Epoch [7/15], Step [40/104], Loss: 0.0408\n",
      "Epoch [7/15], Step [50/104], Loss: 0.1417\n",
      "Epoch [7/15], Step [60/104], Loss: 0.0656\n",
      "Epoch [7/15], Step [70/104], Loss: 0.0639\n",
      "Epoch [7/15], Step [80/104], Loss: 0.0885\n",
      "Epoch [7/15], Step [90/104], Loss: 0.1369\n",
      "Epoch [7/15], Step [100/104], Loss: 0.1261\n",
      "Epoch [8/15], Step [10/104], Loss: 0.0707\n",
      "Epoch [8/15], Step [20/104], Loss: 0.2303\n",
      "Epoch [8/15], Step [30/104], Loss: 0.1499\n",
      "Epoch [8/15], Step [40/104], Loss: 0.0575\n",
      "Epoch [8/15], Step [50/104], Loss: 0.0365\n",
      "Epoch [8/15], Step [60/104], Loss: 0.1387\n",
      "Epoch [8/15], Step [70/104], Loss: 0.0441\n",
      "Epoch [8/15], Step [80/104], Loss: 0.1239\n",
      "Epoch [8/15], Step [90/104], Loss: 0.1933\n",
      "Epoch [8/15], Step [100/104], Loss: 0.1098\n",
      "Epoch [9/15], Step [10/104], Loss: 0.0445\n",
      "Epoch [9/15], Step [20/104], Loss: 0.0420\n",
      "Epoch [9/15], Step [30/104], Loss: 0.0632\n",
      "Epoch [9/15], Step [40/104], Loss: 0.0777\n",
      "Epoch [9/15], Step [50/104], Loss: 0.0857\n",
      "Epoch [9/15], Step [60/104], Loss: 0.0368\n",
      "Epoch [9/15], Step [70/104], Loss: 0.0540\n",
      "Epoch [9/15], Step [80/104], Loss: 0.0434\n",
      "Epoch [9/15], Step [90/104], Loss: 0.0492\n",
      "Epoch [9/15], Step [100/104], Loss: 0.1804\n",
      "Epoch [10/15], Step [10/104], Loss: 0.0539\n",
      "Epoch [10/15], Step [20/104], Loss: 0.0862\n",
      "Epoch [10/15], Step [30/104], Loss: 0.0203\n",
      "Epoch [10/15], Step [40/104], Loss: 0.0209\n",
      "Epoch [10/15], Step [50/104], Loss: 0.1018\n",
      "Epoch [10/15], Step [60/104], Loss: 0.1548\n",
      "Epoch [10/15], Step [70/104], Loss: 0.0793\n",
      "Epoch [10/15], Step [80/104], Loss: 0.0487\n",
      "Epoch [10/15], Step [90/104], Loss: 0.0540\n",
      "Epoch [10/15], Step [100/104], Loss: 0.0318\n",
      "Epoch [11/15], Step [10/104], Loss: 0.0785\n",
      "Epoch [11/15], Step [20/104], Loss: 0.0590\n",
      "Epoch [11/15], Step [30/104], Loss: 0.1018\n",
      "Epoch [11/15], Step [40/104], Loss: 0.0362\n",
      "Epoch [11/15], Step [50/104], Loss: 0.0524\n",
      "Epoch [11/15], Step [60/104], Loss: 0.0451\n",
      "Epoch [11/15], Step [70/104], Loss: 0.0873\n",
      "Epoch [11/15], Step [80/104], Loss: 0.0448\n",
      "Epoch [11/15], Step [90/104], Loss: 0.0444\n",
      "Epoch [11/15], Step [100/104], Loss: 0.0439\n",
      "Epoch [12/15], Step [10/104], Loss: 0.0531\n",
      "Epoch [12/15], Step [20/104], Loss: 0.0316\n",
      "Epoch [12/15], Step [30/104], Loss: 0.0676\n",
      "Epoch [12/15], Step [40/104], Loss: 0.0384\n",
      "Epoch [12/15], Step [50/104], Loss: 0.0144\n",
      "Epoch [12/15], Step [60/104], Loss: 0.0516\n",
      "Epoch [12/15], Step [70/104], Loss: 0.0183\n",
      "Epoch [12/15], Step [80/104], Loss: 0.0219\n",
      "Epoch [12/15], Step [90/104], Loss: 0.0219\n",
      "Epoch [12/15], Step [100/104], Loss: 0.0405\n",
      "Epoch [13/15], Step [10/104], Loss: 0.0331\n",
      "Epoch [13/15], Step [20/104], Loss: 0.0326\n",
      "Epoch [13/15], Step [30/104], Loss: 0.1224\n",
      "Epoch [13/15], Step [40/104], Loss: 0.0356\n",
      "Epoch [13/15], Step [50/104], Loss: 0.0531\n",
      "Epoch [13/15], Step [60/104], Loss: 0.0134\n",
      "Epoch [13/15], Step [70/104], Loss: 0.0241\n",
      "Epoch [13/15], Step [80/104], Loss: 0.0278\n",
      "Epoch [13/15], Step [90/104], Loss: 0.0097\n",
      "Epoch [13/15], Step [100/104], Loss: 0.0439\n",
      "Epoch [14/15], Step [10/104], Loss: 0.0310\n",
      "Epoch [14/15], Step [20/104], Loss: 0.0400\n",
      "Epoch [14/15], Step [30/104], Loss: 0.0923\n",
      "Epoch [14/15], Step [40/104], Loss: 0.0621\n",
      "Epoch [14/15], Step [50/104], Loss: 0.0305\n",
      "Epoch [14/15], Step [60/104], Loss: 0.0381\n",
      "Epoch [14/15], Step [70/104], Loss: 0.0310\n",
      "Epoch [14/15], Step [80/104], Loss: 0.0119\n",
      "Epoch [14/15], Step [90/104], Loss: 0.0742\n",
      "Epoch [14/15], Step [100/104], Loss: 0.0155\n",
      "Epoch [15/15], Step [10/104], Loss: 0.0416\n",
      "Epoch [15/15], Step [20/104], Loss: 0.0187\n",
      "Epoch [15/15], Step [30/104], Loss: 0.0559\n",
      "Epoch [15/15], Step [40/104], Loss: 0.0103\n",
      "Epoch [15/15], Step [50/104], Loss: 0.0262\n",
      "Epoch [15/15], Step [60/104], Loss: 0.0279\n",
      "Epoch [15/15], Step [70/104], Loss: 0.0821\n",
      "Epoch [15/15], Step [80/104], Loss: 0.0907\n",
      "Epoch [15/15], Step [90/104], Loss: 0.1102\n",
      "Epoch [15/15], Step [100/104], Loss: 0.0230\n",
      "CPU times: user 26min 44s, sys: 28.6 s, total: 27min 12s\n",
      "Wall time: 22min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Accuracy for LeNet5 with various epoch\n",
    "\n",
    "# model_name = 'LeNet5'\n",
    "# model = LeNet5()\n",
    "# for i in range(1,16):\n",
    "#     model = LeNet5()\n",
    "#     losses = train_by_model(model, model_name, i)\n",
    "#     loss_data_of_model_epoch[model_name][i] = losses\n",
    "#     print(\"Epoch done: \", i, \" Calculating accuracy\")\n",
    "#     acc_of_model_epoch[model_name][i] = get_acc_from_data(test_loader)\n",
    "\n",
    "model = LeNet5()\n",
    "model_name = \"LeNet5\"\n",
    "\n",
    "losses = train_by_model(model, model_name, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d91b980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy is  99.16666666666667  with epoch as  12\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accs = {}\n",
    "for epo in LeNet5_model_with_epoch:\n",
    "    print(\"Calculating accuracy of model with epoch: \", epo)\n",
    "    model = LeNet5_model_with_epoch[epo]\n",
    "    acc = get_acc_from_data(test_loader)\n",
    "    accs[epo] = acc\n",
    "\n",
    "plt.plot(list(accs.values()))\n",
    "\n",
    "acc_of_model_epoch[model_name] = accs\n",
    "\n",
    "model_name = \"LeNet5\"\n",
    "max_acc_epo = 1\n",
    "max_acc = acc_of_model_epoch[model_name][max_acc_epo]\n",
    "for epo in acc_of_model_epoch[model_name]:\n",
    "    if max_acc < acc_of_model_epoch[model_name][epo]:\n",
    "        max_acc = acc_of_model_epoch[model_name][epo]\n",
    "        max_acc_epo = epo\n",
    "\n",
    "print(\"Maximum accuracy is \", max_acc, \" with epoch as \", max_acc_epo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec53c649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy is  95.16666666666667  with epoch as  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbea9387550>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Getting Epoch that gives highest accuracy\n",
    "\n",
    "model_name = \"LeNet5\"\n",
    "acc_of_model_epoch\n",
    "max_acc_epo = 1\n",
    "max_acc = acc_of_model_epoch[model_name][max_acc_epo]\n",
    "for epo in acc_of_model_epoch[model_name]:\n",
    "    if max_acc < acc_of_model_epoch[model_name][epo]:\n",
    "        max_acc = acc_of_model_epoch[model_name][epo]\n",
    "        max_acc_epo = epo\n",
    "\n",
    "print(\"Maximum accuracy is \", max_acc, \" with epoch as \", max_acc_epo)\n",
    "\n",
    "# loss_data_of_model_epoch\n",
    "# acc_of_model_epoch\n",
    "\n",
    "import json\n",
    "with open('loss_data_of_model_epoch_t.json', 'w') as fp:\n",
    "    json.dump(loss_data_of_model_epoch, fp)\n",
    "    \n",
    "with open('acc_of_model_epoch_t.json', 'w') as fp:\n",
    "    json.dump(acc_of_model_epoch, fp)\n",
    "\n",
    "all_accuracies = []\n",
    "for epo in acc_of_model_epoch[model_name]:\n",
    "    all_accuracies.append(acc_of_model_epoch[model_name][epo])\n",
    "\n",
    "plt.plot(all_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b2a287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ecf67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size:  16\n",
      "Epoch [1/5], Step [10/207], Loss: 0.6068\n",
      "Epoch [1/5], Step [20/207], Loss: 0.5503\n",
      "Epoch [1/5], Step [30/207], Loss: 0.6159\n",
      "Epoch [1/5], Step [40/207], Loss: 0.4328\n",
      "Epoch [1/5], Step [50/207], Loss: 0.3719\n",
      "Epoch [1/5], Step [60/207], Loss: 0.3254\n",
      "Epoch [1/5], Step [70/207], Loss: 0.3624\n",
      "Epoch [1/5], Step [80/207], Loss: 0.4185\n",
      "Epoch [1/5], Step [90/207], Loss: 0.2952\n",
      "Epoch [1/5], Step [100/207], Loss: 0.2442\n",
      "Epoch [1/5], Step [110/207], Loss: 0.2040\n",
      "Epoch [1/5], Step [120/207], Loss: 0.2007\n",
      "Epoch [1/5], Step [130/207], Loss: 0.2323\n",
      "Epoch [1/5], Step [140/207], Loss: 0.3009\n",
      "Epoch [1/5], Step [150/207], Loss: 0.3715\n",
      "Epoch [1/5], Step [160/207], Loss: 0.1898\n",
      "Epoch [1/5], Step [170/207], Loss: 0.2887\n",
      "Epoch [1/5], Step [180/207], Loss: 0.1570\n",
      "Epoch [1/5], Step [190/207], Loss: 0.3488\n",
      "Epoch [1/5], Step [200/207], Loss: 0.2307\n",
      "Epoch [2/5], Step [10/207], Loss: 0.1339\n",
      "Epoch [2/5], Step [20/207], Loss: 0.1879\n",
      "Epoch [2/5], Step [30/207], Loss: 0.1315\n",
      "Epoch [2/5], Step [40/207], Loss: 0.0613\n",
      "Epoch [2/5], Step [50/207], Loss: 0.1082\n",
      "Epoch [2/5], Step [60/207], Loss: 0.1881\n",
      "Epoch [2/5], Step [70/207], Loss: 0.1209\n",
      "Epoch [2/5], Step [80/207], Loss: 0.0543\n",
      "Epoch [2/5], Step [90/207], Loss: 0.1010\n",
      "Epoch [2/5], Step [100/207], Loss: 0.0888\n",
      "Epoch [2/5], Step [110/207], Loss: 0.1333\n",
      "Epoch [2/5], Step [120/207], Loss: 0.1323\n",
      "Epoch [2/5], Step [130/207], Loss: 0.0965\n",
      "Epoch [2/5], Step [140/207], Loss: 0.1602\n",
      "Epoch [2/5], Step [150/207], Loss: 0.1312\n",
      "Epoch [2/5], Step [160/207], Loss: 0.1061\n",
      "Epoch [2/5], Step [170/207], Loss: 0.1417\n",
      "Epoch [2/5], Step [180/207], Loss: 0.3404\n",
      "Epoch [2/5], Step [190/207], Loss: 0.4990\n",
      "Epoch [2/5], Step [200/207], Loss: 0.1840\n",
      "Epoch [3/5], Step [10/207], Loss: 0.0336\n",
      "Epoch [3/5], Step [20/207], Loss: 0.0966\n",
      "Epoch [3/5], Step [30/207], Loss: 0.0322\n",
      "Epoch [3/5], Step [40/207], Loss: 0.1244\n",
      "Epoch [3/5], Step [50/207], Loss: 0.1110\n",
      "Epoch [3/5], Step [60/207], Loss: 0.0702\n",
      "Epoch [3/5], Step [70/207], Loss: 0.1410\n",
      "Epoch [3/5], Step [80/207], Loss: 0.0781\n",
      "Epoch [3/5], Step [90/207], Loss: 0.1497\n",
      "Epoch [3/5], Step [100/207], Loss: 0.1475\n",
      "Epoch [3/5], Step [110/207], Loss: 0.0772\n",
      "Epoch [3/5], Step [120/207], Loss: 0.0586\n",
      "Epoch [3/5], Step [130/207], Loss: 0.2817\n",
      "Epoch [3/5], Step [140/207], Loss: 0.0601\n",
      "Epoch [3/5], Step [150/207], Loss: 0.0551\n",
      "Epoch [3/5], Step [160/207], Loss: 0.1900\n",
      "Epoch [3/5], Step [170/207], Loss: 0.1474\n",
      "Epoch [3/5], Step [180/207], Loss: 0.1029\n",
      "Epoch [3/5], Step [190/207], Loss: 0.1069\n",
      "Epoch [3/5], Step [200/207], Loss: 0.0386\n",
      "Epoch [4/5], Step [10/207], Loss: 0.0265\n",
      "Epoch [4/5], Step [20/207], Loss: 0.0360\n",
      "Epoch [4/5], Step [30/207], Loss: 0.1702\n",
      "Epoch [4/5], Step [40/207], Loss: 0.0435\n",
      "Epoch [4/5], Step [50/207], Loss: 0.1077\n",
      "Epoch [4/5], Step [60/207], Loss: 0.0263\n",
      "Epoch [4/5], Step [70/207], Loss: 0.0340\n",
      "Epoch [4/5], Step [80/207], Loss: 0.1041\n",
      "Epoch [4/5], Step [90/207], Loss: 0.0388\n",
      "Epoch [4/5], Step [100/207], Loss: 0.0239\n",
      "Epoch [4/5], Step [110/207], Loss: 0.1399\n",
      "Epoch [4/5], Step [120/207], Loss: 0.0134\n",
      "Epoch [4/5], Step [130/207], Loss: 0.0276\n",
      "Epoch [4/5], Step [140/207], Loss: 0.0365\n",
      "Epoch [4/5], Step [150/207], Loss: 0.2289\n",
      "Epoch [4/5], Step [160/207], Loss: 0.1260\n",
      "Epoch [4/5], Step [170/207], Loss: 0.0966\n",
      "Epoch [4/5], Step [180/207], Loss: 0.0596\n",
      "Epoch [4/5], Step [190/207], Loss: 0.0876\n",
      "Epoch [4/5], Step [200/207], Loss: 0.2628\n",
      "Epoch [5/5], Step [10/207], Loss: 0.0518\n",
      "Epoch [5/5], Step [20/207], Loss: 0.1604\n",
      "Epoch [5/5], Step [30/207], Loss: 0.0320\n",
      "Epoch [5/5], Step [40/207], Loss: 0.0286\n",
      "Epoch [5/5], Step [50/207], Loss: 0.0375\n",
      "Epoch [5/5], Step [60/207], Loss: 0.0836\n",
      "Epoch [5/5], Step [70/207], Loss: 0.0186\n",
      "Epoch [5/5], Step [80/207], Loss: 0.0526\n",
      "Epoch [5/5], Step [90/207], Loss: 0.0181\n",
      "Epoch [5/5], Step [100/207], Loss: 0.0791\n",
      "Epoch [5/5], Step [110/207], Loss: 0.0664\n",
      "Epoch [5/5], Step [120/207], Loss: 0.0566\n",
      "Epoch [5/5], Step [130/207], Loss: 0.1327\n",
      "Epoch [5/5], Step [140/207], Loss: 0.0268\n",
      "Epoch [5/5], Step [150/207], Loss: 0.0820\n",
      "Epoch [5/5], Step [160/207], Loss: 0.0361\n",
      "Epoch [5/5], Step [170/207], Loss: 0.0571\n",
      "Epoch [5/5], Step [180/207], Loss: 0.0288\n",
      "Epoch [5/5], Step [190/207], Loss: 0.2377\n",
      "Epoch [5/5], Step [200/207], Loss: 0.0281\n",
      "Accuracy of the network: 96.66666666666667 %\n",
      "Accuracy of Normal: 94.09836065573771 %\n",
      "Accuracy of Tuberculosis: 99.32203389830508 %\n",
      "Batch Size:  32\n",
      "Epoch [1/5], Step [10/104], Loss: 0.5981\n",
      "Epoch [1/5], Step [20/104], Loss: 0.5618\n",
      "Epoch [1/5], Step [30/104], Loss: 0.3991\n",
      "Epoch [1/5], Step [40/104], Loss: 0.3995\n",
      "Epoch [1/5], Step [50/104], Loss: 0.3318\n",
      "Epoch [1/5], Step [60/104], Loss: 0.3741\n",
      "Epoch [1/5], Step [70/104], Loss: 0.3887\n",
      "Epoch [1/5], Step [80/104], Loss: 0.2720\n",
      "Epoch [1/5], Step [90/104], Loss: 0.2077\n",
      "Epoch [1/5], Step [100/104], Loss: 0.3090\n",
      "Epoch [2/5], Step [10/104], Loss: 0.3317\n",
      "Epoch [2/5], Step [20/104], Loss: 0.2260\n",
      "Epoch [2/5], Step [30/104], Loss: 0.3263\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Experiment with various batch sizes for LeNet5 with epoch = 5\n",
    "\n",
    "\n",
    "for bs in [16, 32, 64]:\n",
    "    print(\"Batch Size: \", bs)\n",
    "    train_loader =  torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True)\n",
    "    test_loader =  torch.utils.data.DataLoader(testset, batch_size=bs, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(valset, batch_size=bs, shuffle=True)\n",
    "    model = LeNet5()\n",
    "    train_by_model(model, model_name, 5)\n",
    "    acc_of_model_batch[model_name][bs] = get_acc_from_data(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec8d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Batch Size that gives highest accuracy\n",
    "\n",
    "# model_name = \"LeNet5\"\n",
    "# max_acc_bat = 16\n",
    "# max_acc = acc_of_model_batch[model_name][max_acc_epo]\n",
    "# for bat in acc_of_model_batch[model_name]:\n",
    "#     if max_acc < acc_of_model_batch[model_name][bat]:\n",
    "#         max_acc = acc_of_model_batch[model_name][bat]\n",
    "#         max_acc_bat = bat \n",
    "\n",
    "# print(\"Maximum accuracy is \", max_acc, \" with epoch as \", max_acc_epo)\n",
    "\n",
    "print(\"Upon analyzing the runtime and accuracy of data we took the following parameters forward\")\n",
    "print(\"Batch Size: 32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "454e917b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/12], Step [10/104], Loss: 0.6247\n",
      "Epoch [1/12], Step [20/104], Loss: 0.5910\n",
      "Epoch [1/12], Step [30/104], Loss: 0.5032\n",
      "Epoch [1/12], Step [40/104], Loss: 0.4859\n",
      "Epoch [1/12], Step [50/104], Loss: 0.4333\n",
      "Epoch [1/12], Step [60/104], Loss: 0.3397\n",
      "Epoch [1/12], Step [70/104], Loss: 0.3642\n",
      "Epoch [1/12], Step [80/104], Loss: 0.3356\n",
      "Epoch [1/12], Step [90/104], Loss: 0.3028\n",
      "Epoch [1/12], Step [100/104], Loss: 0.2621\n",
      "Epoch [2/12], Step [10/104], Loss: 0.2415\n",
      "Epoch [2/12], Step [20/104], Loss: 0.3314\n",
      "Epoch [2/12], Step [30/104], Loss: 0.1760\n",
      "Epoch [2/12], Step [40/104], Loss: 0.1996\n",
      "Epoch [2/12], Step [50/104], Loss: 0.3239\n",
      "Epoch [2/12], Step [60/104], Loss: 0.3211\n",
      "Epoch [2/12], Step [70/104], Loss: 0.1806\n",
      "Epoch [2/12], Step [80/104], Loss: 0.1462\n",
      "Epoch [2/12], Step [90/104], Loss: 0.2373\n",
      "Epoch [2/12], Step [100/104], Loss: 0.1783\n",
      "Epoch [3/12], Step [10/104], Loss: 0.2220\n",
      "Epoch [3/12], Step [20/104], Loss: 0.1395\n",
      "Epoch [3/12], Step [30/104], Loss: 0.3350\n",
      "Epoch [3/12], Step [40/104], Loss: 0.1731\n",
      "Epoch [3/12], Step [50/104], Loss: 0.2091\n",
      "Epoch [3/12], Step [60/104], Loss: 0.0854\n",
      "Epoch [3/12], Step [70/104], Loss: 0.1784\n",
      "Epoch [3/12], Step [80/104], Loss: 0.1559\n",
      "Epoch [3/12], Step [90/104], Loss: 0.1278\n",
      "Epoch [3/12], Step [100/104], Loss: 0.1496\n",
      "Epoch [4/12], Step [10/104], Loss: 0.2017\n",
      "Epoch [4/12], Step [20/104], Loss: 0.1395\n",
      "Epoch [4/12], Step [30/104], Loss: 0.1482\n",
      "Epoch [4/12], Step [40/104], Loss: 0.2186\n",
      "Epoch [4/12], Step [50/104], Loss: 0.1894\n",
      "Epoch [4/12], Step [60/104], Loss: 0.1463\n",
      "Epoch [4/12], Step [70/104], Loss: 0.0855\n",
      "Epoch [4/12], Step [80/104], Loss: 0.1229\n",
      "Epoch [4/12], Step [90/104], Loss: 0.0950\n",
      "Epoch [4/12], Step [100/104], Loss: 0.1018\n",
      "Epoch [5/12], Step [10/104], Loss: 0.1459\n",
      "Epoch [5/12], Step [20/104], Loss: 0.0858\n",
      "Epoch [5/12], Step [30/104], Loss: 0.1777\n",
      "Epoch [5/12], Step [40/104], Loss: 0.1959\n",
      "Epoch [5/12], Step [50/104], Loss: 0.0912\n",
      "Epoch [5/12], Step [60/104], Loss: 0.0618\n",
      "Epoch [5/12], Step [70/104], Loss: 0.0796\n",
      "Epoch [5/12], Step [80/104], Loss: 0.0942\n",
      "Epoch [5/12], Step [90/104], Loss: 0.1720\n",
      "Epoch [5/12], Step [100/104], Loss: 0.2276\n",
      "Epoch [6/12], Step [10/104], Loss: 0.1324\n",
      "Epoch [6/12], Step [20/104], Loss: 0.0556\n",
      "Epoch [6/12], Step [30/104], Loss: 0.1964\n",
      "Epoch [6/12], Step [40/104], Loss: 0.0778\n",
      "Epoch [6/12], Step [50/104], Loss: 0.0818\n",
      "Epoch [6/12], Step [60/104], Loss: 0.1019\n",
      "Epoch [6/12], Step [70/104], Loss: 0.1358\n",
      "Epoch [6/12], Step [80/104], Loss: 0.1624\n",
      "Epoch [6/12], Step [90/104], Loss: 0.0865\n",
      "Epoch [6/12], Step [100/104], Loss: 0.2007\n",
      "Epoch [7/12], Step [10/104], Loss: 0.0426\n",
      "Epoch [7/12], Step [20/104], Loss: 0.0910\n",
      "Epoch [7/12], Step [30/104], Loss: 0.0555\n",
      "Epoch [7/12], Step [40/104], Loss: 0.1587\n",
      "Epoch [7/12], Step [50/104], Loss: 0.1319\n",
      "Epoch [7/12], Step [60/104], Loss: 0.1191\n",
      "Epoch [7/12], Step [70/104], Loss: 0.1314\n",
      "Epoch [7/12], Step [80/104], Loss: 0.0947\n",
      "Epoch [7/12], Step [90/104], Loss: 0.0787\n",
      "Epoch [7/12], Step [100/104], Loss: 0.0708\n",
      "Epoch [8/12], Step [10/104], Loss: 0.0671\n",
      "Epoch [8/12], Step [20/104], Loss: 0.0344\n",
      "Epoch [8/12], Step [30/104], Loss: 0.0301\n",
      "Epoch [8/12], Step [40/104], Loss: 0.0755\n",
      "Epoch [8/12], Step [50/104], Loss: 0.0620\n",
      "Epoch [8/12], Step [60/104], Loss: 0.1084\n",
      "Epoch [8/12], Step [70/104], Loss: 0.0220\n",
      "Epoch [8/12], Step [80/104], Loss: 0.0524\n",
      "Epoch [8/12], Step [90/104], Loss: 0.0521\n",
      "Epoch [8/12], Step [100/104], Loss: 0.0512\n",
      "Epoch [9/12], Step [10/104], Loss: 0.1512\n",
      "Epoch [9/12], Step [20/104], Loss: 0.0502\n",
      "Epoch [9/12], Step [30/104], Loss: 0.1146\n",
      "Epoch [9/12], Step [40/104], Loss: 0.0432\n",
      "Epoch [9/12], Step [50/104], Loss: 0.0637\n",
      "Epoch [9/12], Step [60/104], Loss: 0.0633\n",
      "Epoch [9/12], Step [70/104], Loss: 0.0228\n",
      "Epoch [9/12], Step [80/104], Loss: 0.1791\n",
      "Epoch [9/12], Step [90/104], Loss: 0.0960\n",
      "Epoch [9/12], Step [100/104], Loss: 0.0576\n",
      "Epoch [10/12], Step [10/104], Loss: 0.0534\n",
      "Epoch [10/12], Step [20/104], Loss: 0.0137\n",
      "Epoch [10/12], Step [30/104], Loss: 0.0613\n",
      "Epoch [10/12], Step [40/104], Loss: 0.0711\n",
      "Epoch [10/12], Step [50/104], Loss: 0.0682\n",
      "Epoch [10/12], Step [60/104], Loss: 0.0306\n",
      "Epoch [10/12], Step [70/104], Loss: 0.0197\n",
      "Epoch [10/12], Step [80/104], Loss: 0.0478\n",
      "Epoch [10/12], Step [90/104], Loss: 0.0237\n",
      "Epoch [10/12], Step [100/104], Loss: 0.0403\n",
      "Epoch [11/12], Step [10/104], Loss: 0.2172\n",
      "Epoch [11/12], Step [20/104], Loss: 0.0322\n",
      "Epoch [11/12], Step [30/104], Loss: 0.0419\n",
      "Epoch [11/12], Step [40/104], Loss: 0.1471\n",
      "Epoch [11/12], Step [50/104], Loss: 0.0314\n",
      "Epoch [11/12], Step [60/104], Loss: 0.0230\n",
      "Epoch [11/12], Step [70/104], Loss: 0.0234\n",
      "Epoch [11/12], Step [80/104], Loss: 0.1045\n",
      "Epoch [11/12], Step [90/104], Loss: 0.0093\n",
      "Epoch [11/12], Step [100/104], Loss: 0.0148\n",
      "Epoch [12/12], Step [10/104], Loss: 0.1242\n",
      "Epoch [12/12], Step [20/104], Loss: 0.1055\n",
      "Epoch [12/12], Step [30/104], Loss: 0.0168\n",
      "Epoch [12/12], Step [40/104], Loss: 0.0606\n",
      "Epoch [12/12], Step [50/104], Loss: 0.0147\n",
      "Epoch [12/12], Step [60/104], Loss: 0.1350\n",
      "Epoch [12/12], Step [70/104], Loss: 0.1052\n",
      "Epoch [12/12], Step [80/104], Loss: 0.0302\n",
      "Epoch [12/12], Step [90/104], Loss: 0.0228\n",
      "Epoch [12/12], Step [100/104], Loss: 0.0105\n"
     ]
    }
   ],
   "source": [
    "args.num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "train_loader =  torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader =  torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = LeNet5()\n",
    "model_name = \"LeNet5\"\n",
    "\n",
    "losses = train_by_model(model, model_name, args.num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "085abeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 97.33333333333333 %\n",
      "Accuracy of Normal: 96.78571428571429 %\n",
      "Accuracy of Tuberculosis: 97.8125 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "97.33333333333333"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_acc_from_data(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2363dbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 99.33333333333333 %\n"
     ]
    }
   ],
   "source": [
    "get_acc_from_data(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c523b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
